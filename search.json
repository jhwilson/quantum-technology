[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantum Technology",
    "section": "",
    "text": "Preface\nThe goal for this text is to be a snapshot in time of quantum technologies: the good, the bad, and the ugly. As of 2024, there has been a large amount of industry interest and progress to develop quantum technologies, and a student approaching this industry should have the basic knowledge to understand what is trying to be achieved and how they are trying to achieve it. To cut through the PR of industry, this text offers the author’s personal perspective on what has been achieved, where things need to go, and the challenges to get there. This is not meant to be an authoritative guide on any one of the technologies presented here, but a jumping off point for the interested student.\nFinally, this is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 The Quantum-Classical Arms Race\nIn 2019  [1], Google reached a significant milestone in quantum computing when they achieved “Quantum Advantage”–demonstrating for the first time that a quantum computer could surpass the capabilities of classical computers, albeit for a specific, specialized task. Using their Sycamore processor with 53 qubits, they showed that sampling from a quantum circuit a million times took only 200 seconds, while the equivalent task would take approximately 10,000 years on a classical supercomputer. This breakthrough marked a turning point in quantum computing, igniting increased interest and investment in quantum technologies. Building on this success, in December 2024, Google announced their new Willow chip  [2], representing their latest advancement in quantum hardware. Today, numerous companies and research institutions worldwide are racing to develop quantum hardware, each pursuing different technological approaches to challenge the computational limits of classical computers.\nThis text aims to give undergraduate students a comprehensive introduction to quantum technology and computation. We will begin by exploring the fundamental mathematical framework that underlies quantum computing, building from basic principles to more advanced concepts. Crucially, we will see what specific things a quantum computer can achieve that a classical computer would struggle with. With this foundation, we will examine three of the most promising current quantum computing technologies: superconducting qubits, photonic quantum computing, and ion traps. Each of these approaches offers unique advantages and faces distinct challenges, which we will analyze in detail.\nTo bridge theory with practice, we will utilize IBM’s Qiskit software platform to implement basic quantum computations, providing hands-on experience with quantum programming. As we progress, we will explore critical practical considerations in quantum computing, including error mitigation and correction strategies. Time permitting, we will venture into the cutting-edge field of topological quantum computing, which offers a potentially more robust approach to quantum computation.\nThroughout this text, we will maintain a balanced perspective, examining both the tremendous potential and significant challenges facing quantum computing technology. Our goal is to equip students with both theoretical understanding and practical insights into this rapidly evolving field.\nThe story of Google’s quantum supremacy claim illustrates a fascinating dynamic in the field of quantum computing–an ongoing arms race between quantum and classical algorithms. When Google first announced their achievement with the Sycamore processor  [1], they estimated that their quantum sampling task would take a classical supercomputer approximately 10,000 years. However, within months, IBM researchers developed improved classical algorithms that could potentially perform the same calculation in just 2.5 days  [3]. Further work even demonstrated that using tensor networks, the problem could be solved faster on a modern superconductor with ExaFLOPS performance  [4].\nThis back-and-forth highlights several important lessons. First, it demonstrates the remarkable adaptability of classical computing. As quantum computers advance, classical algorithm developers find increasingly clever ways to simulate quantum systems or solve specific problems more efficiently. This competition drives innovation in both fields–quantum hardware must continually improve to maintain its advantage, while classical algorithms become more sophisticated in response.\nSecond, it serves as a cautionary tale about interpreting quantum computing announcements, particularly those aimed at the general public. While the achievement of quantum advantage represents a genuine milestone, the initial 10,000-year estimate proved overly optimistic. This pattern has repeated with various quantum computing companies, where marketing claims sometimes outpace peer-reviewed scientific validation. For students and researchers in the field, it’s crucial to maintain a balanced perspective–acknowledging genuine breakthroughs while critically evaluating bold claims.\nThe recent announcement of Google’s Willow chip  [2] represents another step forward, but should be viewed within this context of ongoing competition and careful validation. This healthy tension between quantum and classical approaches ultimately benefits both fields, pushing the boundaries of what’s computationally possible while maintaining rigorous scientific standards.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#sec-transistors",
    "href": "intro.html#sec-transistors",
    "title": "1  Introduction",
    "section": "1.2 Early Computing: The Lesson of Transistors",
    "text": "1.2 Early Computing: The Lesson of Transistors\nIn Ref.  [5] there are a few quotes about early computing\n\n“Computers in the future may weigh no more than 1.5 tons.” –Popular Mechanics, forecasting the relentless marcho f science, 1949\n\n\n“I think there is a world market for maybe five computers.” –Thomas Watson, chairman of IBM, 1943\n\nThese quotes raise important points about early technology. While the theory of modern computing really took off with Turing in 1937  [6], the technological advancement necessary for modern computurs would not occur until later: when the transistor came about.\n\n1.2.1 The Dream: Field Effect Transistors\n\n\n\n\n\n\n\n\n\n\n\n(a) P-channel\n\n\n\n\n\n\n\n\n\n\n\n(b) N-channel\n\n\n\n\n\n\n\nFig. 1.1: Example Circuit diagrams for MOSFETs (enh)\n\n\n\nTo enable classical computing, we need something like a “switch” that can be on and off, keeping track of whether or not something like, current is flowing. This is hard to do with traditional circuit elements like resistors, capacitors, and inductors. It requires something more nonlinear: A switch that only allows current flow when a voltage is applied, a transistor.\nFig. 1.1 shows two of the types of circuit diagrams for a bipolar junction transistor (G = gate, S = source, and D = drain)1. A voltage applied at the gate enables a larger current to flow between collector and emitter. There are also bipolar junction transistors that use a smaller current to enable a larger current, in this case there is “base”, “collector”, and “emitter”.\nWith these building blocks, logical gates can be created, but how to build these? Which device can be made small and in abundance? And what challenges were encountered on the way.\nKeep in mind that the iPhone has within it 19 billion transistors (with the A17 pro).\nIt was recognized early on that semiconductors provided an ideal platform for these kinds of circuits, and much work was done to try and create the above “field effect transistors.” Schematically, these take the form:\n\n\n\n\n\n\nFig. 1.2: Schematic of Field Effect Transistor2\n\n\n\nIn Fig. 1.2, electrons flow from source to drain, but only when the “gate” has an applied voltage to it (effectively “lowering the barrier” for electrons to get through). This theory was sound and based on the recently developed quantum electron theory of metals developed by Wolfgang Pauli, Werner Heisenberg, Arnold Sommerfeld, Felix Bloch, and Rudolf Peierls  [7]. And indeed, the people at Bell labs worked on this problem theoretically and experimentally for the beginning in the 1930s (for a full history, see  [7]). Despite the strong foundations though, creating a field effect transistor turned out to be difficult, and in the process Brattain and Schockley instead created the point-contact transistor.\n\n\n1.2.2 The Point Contact Transistor\n\n\n\n\n\n\n\n\n\n\n\n(a) Schematic of the point contact transistor3.\n\n\n\n\n\n\n\n\n\n\n\n(b) Replica of first transistor\n\n\n\n\n\n\n\nFig. 1.3: The point contact transistor.\n\n\n\nThe point-contact transistor, invented in 1947, worked quite differently from the field-effect design. Instead of using a voltage at a gate to control current flow, it used two very closely spaced metal contacts pressed against a semiconductor (typically germanium). One contact, called the emitter, would inject positive charge carriers (holes) into the semiconductor. The second contact, called the collector, would collect these carriers - but crucially, the amount of current that could flow through the collector could be controlled by small changes in the emitter current4. A schematic and image of a replica of the original device are illustrated in Fig. 1.3.\nThis amplification effect, where a small current controls a larger one, was revolutionary–though the exact physics behind it wasn’t fully understood at the time. The key was that the metal contacts created special regions in the semiconductor where the positive carriers modified the barrier for current flow from the bulk material. While the detailed quantum mechanics is complex, you can think of it like creating “paths” that electrons prefer to take through the material, with the emitter current controlling how easily electrons can flow along these paths to the collector.\nWhile point-contact transistors were eventually superseded by more reliable and easier-to-manufacture designs, they represented a crucial breakthrough in electronics. They proved that solid-state devices could indeed amplify electrical signals. However, they were quite large. The original design for a field effect transistor would be needed, and they key resided in understanding and control the surface physics of semiconductors.\n\n\n1.2.3 Surface physics and transistors\nThe key challenge in creating field effect transistors lay in understanding and controlling the surface properties of semiconductors. To understand why this was so difficult, let’s break it down:\nWhen a semiconductor crystal (like silicon) ends at a surface, something interesting happens. The regular pattern of atoms is suddenly interrupted - imagine a neat stack of blocks suddenly ending in mid-air. This interruption creates what we call “surface states” - special energy levels that electrons can occupy right at the surface of the material.\nThese surface states turned out to be extremely problematic for making transistors. Remember that in a field effect transistor, we want to control the flow of electrons using an electric field from the gate (see Fig. 1.2). However, these surface states acted like tiny electron traps, capturing and holding onto electrons. When electrons got stuck in these states, they effectively “screened” or blocked the electric field from the gate, preventing it from controlling the current flow through the semiconductor.\nThis screening effect was so strong that early attempts at field effect transistors simply didn’t work–no matter how strong a voltage was applied to the gate, it couldn’t effectively control the current flow. It was like trying to control a water flow with a valve, but having something constantly blocking the valve from moving.\nThe breakthrough came in the 1950s when researchers, particularly at Bell Labs, realized they needed to chemically “passivate” the semiconductor surface–essentially finding ways to neutralize these problematic surface states. The key discovery was that growing a thin layer of silicon dioxide (SiO₂) on silicon created a much more stable interface with far fewer problematic surface states. This oxide layer also served as an excellent insulator between the gate and the semiconductor.\nThis seemingly simple solution–growing an oxide layer–was actually a remarkable achievement that required precise control of material chemistry and manufacturing processes. It finally allowed the creation of practical field effect transistors, leading to the modern MOSFET (Metal-Oxide-Semiconductor Field Effect Transistor) that forms the backbone of today’s electronics.\nThe success of this approach also highlights an important lesson in technology development: sometimes the biggest breakthroughs come not from changing the fundamental design, but from finding ways to control and manage the subtle physical effects that prevent a good design from working in practice.\n\n\n1.2.4 Where are we with quantum computing?\nImagine that this course existed back in the 1950s and we called it “Computing Technology.” Transistors were still coming online to enable computation at scale and we had both the information science and material theory to achieve it:\n\nWe knew what was needed to do universal classical computation.\nWe had the quantum theory of metals to describe how to build components (transistors) to achieve classical computation.\n\nHowever, the engineering challenges took decades to resolve. It was only when we resolved those that computation as we currently envision it took off and we could have classical computers.\nFor quantum computing, we are in a similar situation:\n\nWe know what is needed to do universal quantum computation.\nWe have the quantum theory of photons, atoms, and superconductivity to achieve quantum computation.\n\nHowever, as we will see in what follows, we have significant engineering challenges to achieve these in practice. While we will be largely concerned with the physics that make #2 possible in this course (and we’ll touch on #1 for the first part of the course), we will pay attention to the strengths and weaknesses in the physics that lead to more pressing engineering challenges.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#review-of-the-postulates-of-quantum-mechanics",
    "href": "intro.html#review-of-the-postulates-of-quantum-mechanics",
    "title": "1  Introduction",
    "section": "1.3 Review of the Postulates of Quantum Mechanics",
    "text": "1.3 Review of the Postulates of Quantum Mechanics\nQuantum mechanics is built out of some basic postulates which are crucial to understand for quantum computation. When we talk about a “system” in these postulates, we will be thinking of two-level systems which we can label 0 or 1 (for our qubit). However, we will state them generally since many applications require some basic work to reduce the complicated system down to just the qubits we are interested in.\n\n1.3.1 Postulate I: The Hilbert space\n\nA state in an isolated physical system \\(S\\) can be described by a set of normalized state vectors–\\(\\ket{\\psi}\\) and all vectors related by a phase \\(\\ket{\\psi'} = e^{i\\phi}\\ket{\\psi}\\)–belonging in the Hilbert space \\(\\mathcal H_S\\).\n\nimportantly, a Hilbert space is equipped with an inner product (much like the dot product in three-dimensions) \\(\\braket{\\alpha | \\beta}\\).\nWe also need rules for attaching Hilbert spaces to one another. Afterall, we will need to use more than one qubit to do anything interesting.\n\nThe Hilbert space of a composite system is the tensor product of the two individual systems \\(\\mathcal H_{AB} = \\mathcal H_A \\otimes \\mathcal H_B\\).\n\n\n\n1.3.2 Postulate II: Physical Observables and Measurements\nThis postulate is also sometimes called the Born rule.\nIn order to measure the system (e.g., “where is the particle?” or “Is the qubit a 0 or 1?”), we need to know what physical observables are\n\n\nEvery physical observable \\(a\\) can be described as a Hermitian operator \\(A\\) acting in the Hilbert Space.\n\n\nFormally, a Hermitian operator has \\(A = A^\\dagger\\) where \\(A^\\dagger\\) is the conjugate transpose of \\(A\\). These operators have a whole set of orthonormal eigenstates \\(A\\ket{a_n} = a_n\\ket{a_n}\\) for a real number \\(a_n\\) (orthonormal means \\(\\braket{a_n| a_m} = \\delta_{nm}\\)). These mathematical details are important for how we will perform measurements\n\n\nWhen a physical observable with operator \\(A\\) is measured on a normalized eigenstate \\(\\ket{\\psi}\\), the result is an eigenvalue \\(a_n\\) of that operator with probability \\(p_n = \\lvert \\braket{a_n |\\psi} \\rvert^2\\) (or in the case of a degeneracy \\(d\\), \\(p_n = \\sum_{i=1}^d \\lvert \\braket{a_n, i | \\psi}\\vert^2\\)).\n\n\nIf we measure \\(A\\) repeatedly, we are naturally lead to the expectation value \\(\\braket{\\psi | A |\\psi} = a = \\sum_n a_n p_n\\), the average result of repeated quantum mechanical measurements. Once a measurement is performed, however, the state is changed, for this we need an operator \\(P_n\\) which projects onto the eigenspace of \\(A\\) associated with the eigenvalue \\(a_n\\).\n\n\nWhen a measurement of the observable \\(A\\) gives a results \\(a_n\\), the state is changed to be the normalized projection of \\(\\ket{\\psi}\\) to the eigenspace associated with \\(a_n\\) \\[ \\ket{\\psi} \\quad \\implies \\quad \\frac{P_n \\ket{\\psi}}{\\sqrt{\\braket{\\psi|P_n | \\psi}}} \\]\n\n\nIf the eigenstates are not degenerate, then \\(\\ket{\\psi} \\implies \\ket{a_n}\\). However, we will find that we will often have degenerate states, and in that case \\[\n\\ket{\\psi} \\implies \\frac{\\sum_{i=1}^d \\braket{a_n, i | \\psi} \\ket{a_n, i}}{\\sqrt{\\sum_{i=1}^d \\lvert \\braket{a_n,i | \\psi}\\rvert^2}}.\n\\] One comfortable with the braket notation might notice that within this, \\(P_n = \\sum_{i=1}^d \\ket{a_n,i}\\bra{a_n,i}\\).\n\n\n1.3.3 Postulate III: Time-evolution of a system\nWhile we will talk about Hamiltonians, often in quantum computation we have gates that do not require these. In this case, we state this postulate as abstractly as possible\n\nThe time evolution of a closed system from some time \\(t_0\\) and state \\(\\ket{\\psi_0}\\) to a final time \\(t\\) and state \\(\\ket{\\psi}\\) can be described as a unitary transformation \\[ \\ket{\\psi} = U(t,t_0) \\ket{\\psi_0}.\\]\n\nThis postulate is necessary for us to maintain probabilities. Unitary operators have the property that \\(UU^\\dagger = U^\\dagger U = \\mathbb{1}\\), and so \\[1 = \\braket{\\psi_0|\\psi_0} = \\braket{\\psi_0|U^\\dagger U| \\psi_0} = \\braket{\\psi|\\psi}.\\]\nIn the case of time-independent Hamiltonian dynamics, the operator takes the form \\(U = e^{-i H t/\\hbar}\\) for a hermitian energy operator \\(H\\) called the Hamiltonian.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#quantum-technologies",
    "href": "intro.html#quantum-technologies",
    "title": "1  Introduction",
    "section": "1.4 Quantum Technologies",
    "text": "1.4 Quantum Technologies\nOne major difference between the hindsight-history we have for classical computation and the current state of quantum computers is that are many platforms vying to enable quantum computation. There are arguments for and against each platform, and even arguments for using a combination of platforms. Here we give a list of some of the technologies and highlight the ones we will be surveying in this course.\nPlatforms covered in this course\n\nSuperconducting qubits: Artificial atoms made from superconducting circuits that operate at ultra-low temperatures. Currently the most mature platform, used by companies like IBM and Google.\nTrapped ions: Individual atoms held in place by electromagnetic fields. Known for having very long coherence times and high-fidelity gates. Major players include IonQ and Quantinuum (formerly of Honeywell).\nPhotonic quantum computers: Use particles of light (photons) as qubits. Can operate at room temperature and naturally interface with quantum communication systems. Being developed by companies like PsiQuantum and Xanadu.\n\nOther platforms we will not cover\n\nSilicon quantum dots: Quantum bits made from individual electrons trapped in silicon, similar to classical semiconductor technology. Could potentially leverage existing manufacturing processes.\nNeutral atoms and Rydberg arrays: Individual neutral atoms arranged in arrays using laser beams. When excited to high-energy Rydberg states, atoms can interact strongly with their neighbors. Can create large numbers of identical qubits with programmable interactions. Companies like QuEra are pursuing this approach.\nNV centers: Quantum bits made from nitrogen-vacancy defects in diamond. Can operate at room temperature and have long coherence times, making them particularly promising for quantum sensing and networking applications.\n\nA platform we will cover if time permits\n\nTopological qubits: A theoretical approach that would use special quantum states of matter to create error-protected qubits. Still in early research stages but could offer significant advantages if realized.\n\nEach platform has its own advantages and challenges in terms of scalability, error rates, coherence times, and manufacturing complexity. The field is still evolving, and it’s possible that different platforms may be optimal for different applications.\n\n\n\n\n[1] F. Arute et al., Quantum supremacy using a programmable superconducting processor, Nature 574, 505 (2019).\n\n\n[2] Google Quantum AI and Collaborators et al., Quantum error correction below the surface code threshold, Nature (2024).\n\n\n[3] E. Pednault, J. A. Gunnels, G. Nannicini, L. Horesh, and R. Wisnieff, Leveraging Secondary Storage to Simulate Deep 54-qubit Sycamore Circuits, arXiv:1910.09534 (2019).\n\n\n[4] F. Pan, K. Chen, and P. Zhang, Solving the Sampling Problem of the Sycamore Quantum Circuits, Physical Review Letters 129, 090502 (2022).\n\n\n[5] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information: 10th Anniversary Edition, Anniversary edition (Cambridge University Press, Cambridge ; New York, 2011).\n\n\n[6] A. M. Turing, On Computable Numbers, with an Application to the Entscheidungsproblem, Proceedings of the London Mathematical Society s2-42, 230 (1937).\n\n\n[7] L. Hoddeson, The Discovery of the Point-Contact Transistor, Historical Studies in the Physical Sciences 12, 41 (1981).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "Note that P or N stands for positive or negative carriers.↩︎\nMade by VectorVoyager and licensed under Creative Commons Attribution-Share Alike 3.0 Unported↩︎\nLicensed under Creative Commons CC0 1.0 Universal Public Domain Dedication.↩︎\nFor details on how this was made, see How the first transistor worked↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "qubit.html",
    "href": "qubit.html",
    "title": "2  The Qubit",
    "section": "",
    "text": "2.1 The qubit Hilbert space\nThe fundamental building block of the classical computer was the bit: A 0 or 1 that could be manipulated by a classical computer (via transistors, see Section 1.2). In a similar manner, quantum computation has the “quantum bit” or just qubit, for short. This leads us to the linear algebra of \\(2\\times 2\\) matrices, as we will see. Despite the apparent simplicity, we can already see many of the key features of quantum mechanics in this simple system.\nA qubit will be in two-dimensional complex vector space equipped with an inner product.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Qubit</span>"
    ]
  },
  {
    "objectID": "qubit.html#the-qubit-hilbert-space",
    "href": "qubit.html#the-qubit-hilbert-space",
    "title": "2  The Qubit",
    "section": "",
    "text": "2.1.1 Qubit states\nFor the qubit, we associate two states with two different basis vectors: \\(\\ket{0}\\) and \\(\\ket{1}\\). This will be called the computational basis. The magic1 of quantum mechanics is that a state need not be just one or the other, but could be any linear superposition of these \\[\n\\ket{\\psi} = \\alpha \\ket{0} + \\beta \\ket{1}.\n\\tag{2.1}\\] In this, we have adopted the bra-ket notation due to Dirac. While it can be quite useful, we can write this in terms of matrices and vectors \\[\n\\ket{0} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}, \\quad \\ket{1} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}.\n\\] This makes it clear that these states are orthogonal \\(\\braket{0|1} = 0\\).\nIn this case we have \\[\n\\ket{\\psi} = \\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix}.\n\\] We also need the conjugate transpose, the Hermitian conjugate, of this vector, which will be a row-vector \\[\n\\bra{\\psi} = \\begin{bmatrix} \\alpha^* & \\beta^* \\end{bmatrix}.\n\\] The key feature of quantum mechanics is that these states must be normalized, meaning that the probability of finding the system in any state must sum to 1. This means that \\[\n\\braket{\\psi|\\psi} = \\begin{bmatrix} \\alpha^* & \\beta^* \\end{bmatrix} \\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix} = |\\alpha|^2 + |\\beta|^2 = 1.\n\\] In matrix notation, this is just the dot product of a vector with its complex conjugate.\nWe can also write operators that act on these states. The simplest operator is the Pauli \\(Z\\) operator, which in matrix form is \\[\nZ = \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix}.\n\\] When this operator acts on our basis states, we find \\[\nZ\\ket{0} = \\ket{0}, \\quad Z\\ket{1} = -\\ket{1}.\n\\] This means that \\(\\ket{0}\\) and \\(\\ket{1}\\) are eigenstates of \\(Z\\) with eigenvalues \\(+1\\) and \\(-1\\) respectively. For a general state \\(\\ket{\\psi}\\), measuring \\(Z\\) will yield either \\(+1\\) or \\(-1\\), with probabilities determined by \\(|\\alpha|^2\\) and \\(|\\beta|^2\\) respectively.\n\n\n2.1.2 Qubit operators\nSince this is linear algebra, we can write a general operator \\(\\mathcal O\\) as a matrix \\[\n\\mathcal O = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}.\n\\] Often, we are interested in the eigenvalues and eigenstates of these operators \\(\\mathcal O \\ket{\\psi_{i}} = \\lambda_i \\ket{\\psi_i}\\). Generically, we can find these by solving a polynomial equation \\[\n\\det(\\mathcal O - \\lambda I) = 0.\n\\]\nSolving this step-by-step \\[\n\\det(\\mathcal O - \\lambda I) = \\begin{vmatrix} a-\\lambda & b \\\\ c & d-\\lambda \\end{vmatrix} = 0,\n\\] which gives us \\[\n(a-\\lambda)(d-\\lambda) - bc = 0.\n\\] This is a quadratic equation that we can solve: \\[\n\\lambda^2 - (a+d)\\lambda + (ad-bc) = 0.\n\\]\nThe eigenvalues are therefore \\[\n\\lambda_{\\pm} = \\frac{a+d \\pm \\sqrt{(a-d)^2 + 4bc}}{2}.\n\\tag{2.2}\\]\nFor quantum mechanical observables (see Section 1.3.2), we are particularly interested in Hermitian operators where \\(\\mathcal O = \\mathcal O^\\dagger\\), \\[\n\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} = \\begin{bmatrix} a^* & c^* \\\\ b^* & d^* \\end{bmatrix}\n\\] This means that \\(a\\) and \\(d\\) must be real and \\(c = b^*\\). In this case, the eigenvalues are always real, as we can see from the Eq. 2.2.\nA particularly important class of operators are unitary operators, where \\(U^\\dagger U = UU^\\dagger = I\\). These are what we use for time-evolution, see Section 1.3.3.\nThese operators preserve the inner product between states: \\[\n\\braket{U\\psi|U\\phi} = \\braket{\\psi|\\phi}\n\\] For a \\(2\\times 2\\) matrix \\[\nU = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix},\n\\] the unitarity condition means that \\[\n\\begin{bmatrix} a^* & c^* \\\\ b^* & d^* \\end{bmatrix} \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}.\n\\]\nThis gives us several conditions:\n\n\\(|a|^2 + |c|^2 = 1\\) (normalization of first column)\n\\(|b|^2 + |d|^2 = 1\\) (normalization of second column)\n\\(ab^* + cd^* = 0\\) (orthogonality of columns)\n\nThis immediately gives us some insight into these operators. If we define, \\[\n\\ket{\\psi_1} = \\begin{bmatrix} a \\\\ b \\end{bmatrix}, \\quad \\ket{\\psi_2} = \\begin{bmatrix} c \\\\ d \\end{bmatrix},\n\\] then we have \\(\\braket{\\psi_1|\\psi_1} = 1 = \\braket{\\psi_2|\\psi_2}\\) and \\(\\braket{\\psi_1|\\psi_2} = 0\\).\nAn important property of unitary operators is that their eigenvalues always have magnitude 1, meaning they can be written as \\(e^{i\\theta}\\) for some real \\(\\theta\\). This makes them natural operators for describing quantum evolution, as we will see later.\nA particularly important set of operators are the Pauli operators. We’ve already seen the Pauli \\(Z\\) operator. The other two are \\[\nX = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}, \\quad Y = \\begin{bmatrix} 0 & -i \\\\ i & 0 \\end{bmatrix}.\n\\] These operators satisfy some important algebraic relations: \\[\nX^2 = Y^2 = Z^2 = I, \\quad XY = iZ, \\quad YZ = iX, \\quad ZX = iY.\n\\]\nThese operators form a complete basis for \\(2\\times 2\\) matrices, meaning we can write any operator as \\[\n\\mathcal O = aI + bX + cY + dZ,\n\\] where \\(a\\), \\(b\\), \\(c\\), and \\(d\\) are complex numbers (though they must satisfy certain conditions if we want \\(\\mathcal O\\) to be Hermitian).\n\n\n\n\n\n\n[1] S. Bravyi and A. Kitaev, Universal quantum computation with ideal Clifford gates and noisy ancillas, Physical Review A 71, 022316 (2005).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Qubit</span>"
    ]
  },
  {
    "objectID": "qubit.html#footnotes",
    "href": "qubit.html#footnotes",
    "title": "2  The Qubit",
    "section": "",
    "text": "Magic is a technical term in quantum computing, though we’re using it in a colloquial sense here, see  [1].↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Qubit</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "[1] F.\nArute et al., Quantum supremacy using\na programmable superconducting processor, Nature\n574, 505 (2019).\n\n\n[2] Google Quantum AI and Collaborators et al., Quantum error\ncorrection below the surface code threshold, Nature (2024).\n\n\n[3] E.\nPednault, J. A. Gunnels, G. Nannicini, L. Horesh, and R. Wisnieff, Leveraging\nSecondary Storage to Simulate Deep 54-qubit\nSycamore Circuits, arXiv:1910.09534 (2019).\n\n\n[4] F.\nPan, K. Chen, and P. Zhang, Solving the\nSampling Problem of the Sycamore Quantum\nCircuits, Physical Review Letters 129,\n090502 (2022).\n\n\n[5] M.\nA. Nielsen and I. L. Chuang, Quantum Computation and\nQuantum Information: 10th Anniversary\nEdition, Anniversary edition (Cambridge University Press,\nCambridge ; New York, 2011).\n\n\n[6] A.\nM. Turing, On\nComputable Numbers, with an Application to the\nEntscheidungsproblem, Proceedings of the London\nMathematical Society s2-42, 230 (1937).\n\n\n[7] L.\nHoddeson, The\nDiscovery of the Point-Contact Transistor,\nHistorical Studies in the Physical Sciences 12, 41\n(1981).\n\n\n[8] S.\nBravyi and A. Kitaev, Universal quantum\ncomputation with ideal Clifford gates and noisy\nancillas, Physical Review A 71, 022316\n(2005).",
    "crumbs": [
      "References"
    ]
  }
]