[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantum Technology",
    "section": "",
    "text": "Preface\nThe goal for this text is to be a snapshot in time of quantum technologies: the good, the bad, and the ugly. As of 2024, there has been a large amount of industry interest and progress to develop quantum technologies, and a student approaching this industry should have the basic knowledge to understand what is trying to be achieved and how they are trying to achieve it. To cut through the PR of industry, this text offers the author’s personal perspective on what has been achieved, where things need to go, and the challenges to get there. This is not meant to be an authoritative guide on any one of the technologies presented here, but a jumping off point for the interested student.\nFinally, this is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 The Quantum-Classical Arms Race\nIn 2019  [1], Google reached a significant milestone in quantum computing when they achieved “Quantum Advantage”–demonstrating for the first time that a quantum computer could surpass the capabilities of classical computers, albeit for a specific, specialized task. Using their Sycamore processor with 53 qubits, they showed that sampling from a quantum circuit a million times took only 200 seconds, while the equivalent task would take approximately 10,000 years on a classical supercomputer. This breakthrough marked a turning point in quantum computing, igniting increased interest and investment in quantum technologies. Building on this success, in December 2024, Google announced their new Willow chip  [2], representing their latest advancement in quantum hardware. Today, numerous companies and research institutions worldwide are racing to develop quantum hardware, each pursuing different technological approaches to challenge the computational limits of classical computers.\nThis text aims to give undergraduate students a comprehensive introduction to quantum technology and computation. We will begin by exploring the fundamental mathematical framework that underlies quantum computing, building from basic principles to more advanced concepts. Crucially, we will see what specific things a quantum computer can achieve that a classical computer would struggle with. With this foundation, we will examine three of the most promising current quantum computing technologies: superconducting qubits, photonic quantum computing, and ion traps. Each of these approaches offers unique advantages and faces distinct challenges, which we will analyze in detail.\nTo bridge theory with practice, we will utilize IBM’s Qiskit software platform to implement basic quantum computations, providing hands-on experience with quantum programming. As we progress, we will explore critical practical considerations in quantum computing, including error mitigation and correction strategies. Time permitting, we will venture into the cutting-edge field of topological quantum computing, which offers a potentially more robust approach to quantum computation.\nThroughout this text, we will maintain a balanced perspective, examining both the tremendous potential and significant challenges facing quantum computing technology. Our goal is to equip students with both theoretical understanding and practical insights into this rapidly evolving field.\nThe story of Google’s quantum supremacy claim illustrates a fascinating dynamic in the field of quantum computing–an ongoing arms race between quantum and classical algorithms. When Google first announced their achievement with the Sycamore processor  [1], they estimated that their quantum sampling task would take a classical supercomputer approximately 10,000 years. However, within months, IBM researchers developed improved classical algorithms that could potentially perform the same calculation in just 2.5 days  [3]. Further work even demonstrated that using tensor networks, the problem could be solved faster on a modern superconductor with ExaFLOPS performance  [4].\nThis back-and-forth highlights several important lessons. First, it demonstrates the remarkable adaptability of classical computing. As quantum computers advance, classical algorithm developers find increasingly clever ways to simulate quantum systems or solve specific problems more efficiently. This competition drives innovation in both fields–quantum hardware must continually improve to maintain its advantage, while classical algorithms become more sophisticated in response.\nSecond, it serves as a cautionary tale about interpreting quantum computing announcements, particularly those aimed at the general public. While the achievement of quantum advantage represents a genuine milestone, the initial 10,000-year estimate proved overly optimistic. This pattern has repeated with various quantum computing companies, where marketing claims sometimes outpace peer-reviewed scientific validation. For students and researchers in the field, it’s crucial to maintain a balanced perspective–acknowledging genuine breakthroughs while critically evaluating bold claims.\nThe recent announcement of Google’s Willow chip  [2] represents another step forward, but should be viewed within this context of ongoing competition and careful validation. This healthy tension between quantum and classical approaches ultimately benefits both fields, pushing the boundaries of what’s computationally possible while maintaining rigorous scientific standards.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#sec-transistors",
    "href": "intro.html#sec-transistors",
    "title": "1  Introduction",
    "section": "1.2 Early Computing: The Lesson of Transistors",
    "text": "1.2 Early Computing: The Lesson of Transistors\nIn Ref.  [5] there are a few quotes about early computing\n\n“Computers in the future may weigh no more than 1.5 tons.” –Popular Mechanics, forecasting the relentless march of science, 1949\n\n\n“I think there is a world market for maybe five computers.” –Thomas Watson, chairman of IBM, 1943\n\nThese quotes raise important points about early technology. While the theory of modern computing really took off with Turing in 1937  [6], the technological advancement necessary for modern computurs would not occur until later: when the transistor came about.\n\n1.2.1 The Dream: Field Effect Transistors\n\n\n\n\n\n\n\n\n\n\n\n(a) P-channel\n\n\n\n\n\n\n\n\n\n\n\n(b) N-channel\n\n\n\n\n\n\n\nFig. 1.1: Example Circuit diagrams for MOSFETs (enh)\n\n\n\nTo enable classical computing, we need something like a “switch” that can be on and off, keeping track of whether or not something like, current is flowing. This is hard to do with traditional circuit elements like resistors, capacitors, and inductors. It requires something more nonlinear: A switch that only allows current flow when a voltage is applied, a transistor.\nFig. 1.1 shows two of the types of circuit diagrams for a bipolar junction transistor (G = gate, S = source, and D = drain)1. A voltage applied at the gate enables a larger current to flow between collector and emitter. There are also bipolar junction transistors that use a smaller current to enable a larger current, in this case there is “base”, “collector”, and “emitter”.\nWith these building blocks, logical gates can be created, but how to build these? Which device can be made small and in abundance? And what challenges were encountered on the way.\n\n\n\n\n\n\nScale of Modern Computing in your pocket\n\n\n\nThe iPhone A17 Pro chip’s 19 billion transistors would cover an area of about 1 square centimeter. If each transistor were the size of a grain of rice, they would cover an area larger than 75 football fields! This incredible miniaturization is what enables modern computing.\n\n\nIt was recognized early on that semiconductors provided an ideal platform for these kinds of circuits, and much work was done to try and create the above “field effect transistors.” Schematically, these take the form:\n\n\n\n\n\n\nFig. 1.2: Schematic of Field Effect Transistor2\n\n\n\nIn Fig. 1.2, electrons flow from source to drain, but only when the “gate” has an applied voltage to it (effectively “lowering the barrier” for electrons to get through). This theory was sound and based on the recently developed quantum electron theory of metals developed by Wolfgang Pauli, Werner Heisenberg, Arnold Sommerfeld, Felix Bloch, and Rudolf Peierls  [7]. And indeed, the people at Bell labs worked on this problem theoretically and experimentally for the beginning in the 1930s (for a full history, see  [7]). Despite the strong foundations though, creating a field effect transistor turned out to be difficult, and in the process Brattain and Bardeen instead created the point-contact transistor.\n\n\n1.2.2 The Point Contact Transistor\n\n\n\n\n\n\n\n\n\n\n\n(a) Schematic of the point contact transistor3.\n\n\n\n\n\n\n\n\n\n\n\n(b) Replica of first transistor\n\n\n\n\n\n\n\nFig. 1.3: The point contact transistor.\n\n\n\nThe point-contact transistor, invented in 1947, worked quite differently from the field-effect design. Instead of using a voltage at a gate to control current flow, it used two very closely spaced metal contacts pressed against a semiconductor (typically germanium). One contact, called the emitter, would inject positive charge carriers (holes) into the semiconductor. The second contact, called the collector, would collect these carriers - but crucially, the amount of current that could flow through the collector could be controlled by small changes in the emitter current4. A schematic and image of a replica of the original device are illustrated in Fig. 1.3.\nThis amplification effect, where a small current controls a larger one, was revolutionary–though the exact physics behind it wasn’t fully understood at the time. The key was that the metal contacts created special regions in the semiconductor where the positive carriers modified the barrier for current flow from the bulk material. While the detailed quantum mechanics is complex, you can think of it like creating “paths” that electrons prefer to take through the material, with the emitter current controlling how easily electrons can flow along these paths to the collector.\nWhile point-contact transistors were eventually superseded by more reliable and easier-to-manufacture designs, they represented a crucial breakthrough in electronics. They proved that solid-state devices could indeed amplify electrical signals. However, they were quite large. The original design for a field effect transistor would be needed, and they key resided in understanding and control the surface physics of semiconductors.\n\n\n1.2.3 Surface physics and transistors\nThe key challenge in creating field effect transistors lay in understanding and controlling the surface properties of semiconductors. To understand why this was so difficult, let’s break it down:\nWhen a semiconductor crystal (like silicon) ends at a surface, something interesting happens. The regular pattern of atoms is suddenly interrupted - imagine a neat stack of blocks suddenly ending in mid-air. This interruption creates what we call “surface states” - special energy levels that electrons can occupy right at the surface of the material.\nThese surface states turned out to be extremely problematic for making transistors. Remember that in a field effect transistor, we want to control the flow of electrons using an electric field from the gate (see Fig. 1.2). However, these surface states acted like tiny electron traps, capturing and holding onto electrons. When electrons got stuck in these states, they effectively “screened” or blocked the electric field from the gate, preventing it from controlling the current flow through the semiconductor.\nThis screening effect was so strong that early attempts at field effect transistors simply didn’t work–no matter how strong a voltage was applied to the gate, it couldn’t effectively control the current flow. It was like trying to control a water flow with a valve, but having something constantly blocking the valve from moving.\nThe breakthrough came in the 1950s when researchers, particularly at Bell Labs, realized they needed to chemically “passivate” the semiconductor surface–essentially finding ways to neutralize these problematic surface states. The key discovery was that growing a thin layer of silicon dioxide (SiO₂) on silicon created a much more stable interface with far fewer problematic surface states. This oxide layer also served as an excellent insulator between the gate and the semiconductor.\nThis seemingly simple solution–growing an oxide layer–was actually a remarkable achievement that required precise control of material chemistry and manufacturing processes. It finally allowed the creation of practical field effect transistors, leading to the modern MOSFET (Metal-Oxide-Semiconductor Field Effect Transistor) that forms the backbone of today’s electronics.\nThe success of this approach also highlights an important lesson in technology development: sometimes the biggest breakthroughs come not from changing the fundamental design, but from finding ways to control and manage the subtle physical effects that prevent a good design from working in practice.\n\n\n1.2.4 Where are we with quantum computing?\nImagine that this course existed back in the 1950s and we called it “Computing Technology.” Transistors were still coming online to enable computation at scale and we had both the information science and material theory to achieve it:\n\nWe knew what was needed to do universal classical computation.\nWe had the quantum theory of metals to describe how to build components (transistors) to achieve classical computation.\n\nHowever, the engineering challenges took decades to resolve. It was only when we resolved those that computation as we currently envision it took off and we could have classical computers.\nFor quantum computing, we are in a similar situation:\n\nWe know what is needed to do universal quantum computation.\nWe have the quantum theory of photons, atoms, and superconductivity to achieve quantum computation.\n\nHowever, as we will see in what follows, we have significant engineering challenges to achieve these in practice. While we will be largely concerned with the physics that make #2 possible in this course (and we’ll touch on #1 for the first part of the course), we will pay attention to the strengths and weaknesses in the physics that lead to more pressing engineering challenges.\n\n\n\n\n\n\nHistorical Parallel\n\n\n\nJust as the theory of classical computation  [6] preceded practical computers by decades, we now have the theory of quantum computation  [5] but face significant engineering challenges. The key difference is that we’re trying to control individual quantum systems rather than classical electrical currents.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#review-of-the-postulates-of-quantum-mechanics",
    "href": "intro.html#review-of-the-postulates-of-quantum-mechanics",
    "title": "1  Introduction",
    "section": "1.3 Review of the Postulates of Quantum Mechanics",
    "text": "1.3 Review of the Postulates of Quantum Mechanics\nQuantum mechanics is built out of some basic postulates which are crucial to understand for quantum computation. When we talk about a “system” in these postulates, we will be thinking of two-level systems which we can label 0 or 1 (for our qubit). However, we will state them generally since many applications require some basic work to reduce the complicated system down to just the qubits we are interested in.\n\n\n\n\n\n\nMathematical Notation Guide\n\n\n\nThroughout this text, we’ll use:\n\n\\(\\ket{\\psi}\\) (“ket psi”): Represents a quantum state\n\\(\\bra{\\phi}\\) (“bra phi”): The dual vector to \\(\\ket{\\phi}\\)\n\\(\\braket{\\phi|\\psi}\\): The inner product between states\n\\(\\otimes\\): The tensor product operation\n\nThese notations provide a compact way to describe quantum systems.\n\n\n\n1.3.1 Postulate I: The Hilbert space\n\nA state in an isolated physical system \\(S\\) can be described by a set of normalized state vectors–\\(\\ket{\\psi}\\) and all vectors related by a phase \\(\\ket{\\psi'} = e^{i\\phi}\\ket{\\psi}\\)–belonging in the Hilbert space \\(\\mathcal H_S\\).\n\nimportantly, a Hilbert space is equipped with an inner product (much like the dot product in three-dimensions) \\(\\braket{\\alpha | \\beta}\\).\nWe also need rules for attaching Hilbert spaces to one another. Afterall, we will need to use more than one qubit to do anything interesting.\n\nThe Hilbert space of a composite system is the tensor product of the two individual systems \\(\\mathcal H_{AB} = \\mathcal H_A \\otimes \\mathcal H_B\\).\n\n\n\n1.3.2 Postulate II: Physical Observables and Measurements\nThis postulate is also sometimes called the Born rule.\nIn order to measure the system (e.g., “where is the particle?” or “Is the qubit a 0 or 1?”), we need to know what physical observables are\n\n\nEvery physical observable \\(a\\) can be described as a Hermitian operator \\(A\\) acting in the Hilbert Space.\n\n\nFormally, a Hermitian operator has \\(A = A^\\dagger\\) where \\(A^\\dagger\\) is the conjugate transpose of \\(A\\). These operators have a whole set of orthonormal eigenstates \\(A\\ket{a_n} = a_n\\ket{a_n}\\) for a real number \\(a_n\\) (orthonormal means \\(\\braket{a_n| a_m} = \\delta_{nm}\\)). These mathematical details are important for how we will perform measurements\n\n\nWhen a physical observable with operator \\(A\\) is measured on a normalized eigenstate \\(\\ket{\\psi}\\), the result is an eigenvalue \\(a_n\\) of that operator with probability \\(p_n = \\lvert \\braket{a_n |\\psi} \\rvert^2\\) (or in the case of a degeneracy \\(d\\), \\(p_n = \\sum_{i=1}^d \\lvert \\braket{a_n, i | \\psi}\\vert^2\\)).\n\n\nIf we measure \\(A\\) repeatedly, we are naturally lead to the expectation value \\(\\braket{\\psi | A |\\psi} = a = \\sum_n a_n p_n\\), the average result of repeated quantum mechanical measurements. Once a measurement is performed, however, the state is changed, for this we need an operator \\(P_n\\) which projects onto the eigenspace of \\(A\\) associated with the eigenvalue \\(a_n\\).\n\n\nWhen a measurement of the observable \\(A\\) gives a results \\(a_n\\), the state is changed to be the normalized projection of \\(\\ket{\\psi}\\) to the eigenspace associated with \\(a_n\\) \\[ \\ket{\\psi} \\quad \\implies \\quad \\frac{P_n \\ket{\\psi}}{\\sqrt{\\braket{\\psi|P_n | \\psi}}} \\]\n\n\nIf the eigenstates are not degenerate, then \\(\\ket{\\psi} \\implies \\ket{a_n}\\). However, we will find that we will often have degenerate states, and in that case \\[\n\\ket{\\psi} \\implies \\frac{\\sum_{i=1}^d \\braket{a_n, i | \\psi} \\ket{a_n, i}}{\\sqrt{\\sum_{i=1}^d \\lvert \\braket{a_n,i | \\psi}\\rvert^2}}.\n\\] One comfortable with the braket notation might notice that within this, \\(P_n = \\sum_{i=1}^d \\ket{a_n,i}\\bra{a_n,i}\\).\n\n\n1.3.3 Postulate III: Time-evolution of a system\nWhile we will talk about Hamiltonians, often in quantum computation we have gates that do not require these. In this case, we state this postulate as abstractly as possible\n\nThe time evolution of a closed system from some time \\(t_0\\) and state \\(\\ket{\\psi_0}\\) to a final time \\(t\\) and state \\(\\ket{\\psi}\\) can be described as a unitary transformation \\[ \\ket{\\psi} = U(t,t_0) \\ket{\\psi_0}.\\]\n\nThis postulate is necessary for us to maintain probabilities. Unitary operators have the property that \\(UU^\\dagger = U^\\dagger U = \\mathbb{1}\\), and so \\[1 = \\braket{\\psi_0|\\psi_0} = \\braket{\\psi_0|U^\\dagger U| \\psi_0} = \\braket{\\psi|\\psi}.\\]\nIn the case of time-independent Hamiltonian dynamics, the operator takes the form \\(U = e^{-i H t/\\hbar}\\) for a hermitian energy operator \\(H\\) called the Hamiltonian.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#a-brief-history-of-computing-from-classical-to-quantum",
    "href": "intro.html#a-brief-history-of-computing-from-classical-to-quantum",
    "title": "1  Introduction",
    "section": "1.4 A Brief History of Computing: From Classical to Quantum",
    "text": "1.4 A Brief History of Computing: From Classical to Quantum\nThe concept that information is physical underlies both classical and quantum computation. Even in the earliest systems of record-keeping, we see physical objects encoding information:\n\nKish Tablet (3500 BCE): A limestone tablet from Kish showing a record of pictographic writing.\nQuipu (2600–1900 BCE): A system of knotted ropes used by the Inca civilization for keeping records. The color, order, and number of knots all represented quantifiable or categorical data.\n\nThese examples highlight that from the very beginning, the act of storing and manipulating information has always had a physical basis—though the underlying physics often remained implicit for centuries.\n\n1.4.1 Classical Computing Foundations\nThe paradigm of classical computing rests on a few fundamental ideas:\n\nBoolean Logic & Universal Gates: All classical computers can be built from a finite set of universal logical gates (e.g., {NAND}, {NOR}, or {AND, NOT}).\n\nMost Boolean operations (AND, OR, NAND, etc.) are inherently irreversible: once a bit is erased or overwritten, the original state cannot be recovered from the output alone.\n\nExtended (Physical) Church–Turing Thesis: A probabilistic Turing machine can efficiently simulate any realistic physical model of computation with at most polynomial overhead.\n\nThis thesis, while unproven, underpins the expectation that classical computers (or at least classical models) are sufficient for simulating any physical system in principle. Quantum computation potentially challenges this with a polynomial in time algorithm (Shor’s algorithm) that is exponential in time classically.\n\n\n1.4.2 The Emergence of Quantum Information\nWhile classical computing relies on bits that are strictly 0 or 1, quantum computing introduces powerful new concepts:\n\nSuperposition: A quantum bit (qubit) can be in a linear combination of basis states (e.g., simultaneously “0” and “1” with certain complex amplitudes).\nEntanglement: Two or more qubits can become correlated in such a way that measuring one affects the outcomes for the others, even across vast distances.\n\nThe key question that launched the field of quantum information was whether these uniquely quantum properties—superposition and entanglement—could be exploited to perform computations more efficiently than any classical device.\nIn his seminal work, Simulating Physics with Computers  [8], Richard Feynman observed that simulating quantum many-body systems on classical computers seems to require exponential resources. He posed the idea of harnessing genuine quantum systems themselves for simulation, planting the seeds for quantum computation as a research field.\nThen, in a series of groundbreaking results between the 1980s and 1990s, researchers demonstrated that quantum computers could, in principle, outperform classical computers for certain tasks:\n\nDeutsch (1985)  [9]: Showed that it is possible to carry out a simple computational task on a quantum computer faster than any classical algorithm.\nDeutsch–Jozsa (1992)  [10]: Introduced a deterministic quantum algorithm that is exponentially faster (in the worst case) than any deterministic classical algorithm.\nBernstein–Vazirani (1992)  [11]: Demonstrated a probabilistic quantum algorithm faster than any probabilistic classical algorithm.\nSimon (1994)  [12]: Provided a probabilistic quantum algorithm that is exponentially faster than any probabilistic classical algorithm for a specific promise problem.\nShor (1994)  [13]: Showed how to factor integers efficiently, providing an exponential speedup over the best known classical methods. This result was particularly striking for cryptography, as factoring large numbers underpins many encryption schemes.\n\nAlongside these algorithmic milestones, researchers began to delineate the limitations: not every problem can be exponentially sped up by quantum methods. For instance, Grover’s algorithm (1996)  [14] for unstructured search yields a quadratic speedup (from \\(N\\) to \\(\\sqrt{N}\\))—still better than classical, but not the exponential leap that Shor’s algorithm provides for factoring.\n\n\n1.4.3 Analog vs. Digital Quantum Simulation\nAs the field grew, quantum simulation branched into two approaches:\n\nAnalog Quantum Simulation: Uses a controllable quantum system to mimic a target quantum system. The interactions in the simulator closely resemble the interactions in the system of interest.\nDigital Quantum Simulation: Decomposes a quantum evolution into a sequence of discrete gates (a “universal” set of quantum gates), akin to how classical digital computers function using logical gate operations.\n\nBoth approaches aim to exploit quantum mechanics to tackle problems in mathematics, physics, chemistry, and materials science that remain intractable for classical supercomputers.\nAmid ongoing research, the interplay between classical and quantum paradigms remains a vibrant area of exploration. While classical computing infrastructure continues to be indispensable, quantum computing offers the promise of qualitatively new capabilities—provided we can tame the noise, errors, and fragilities inherent to quantum states.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#quantum-technologies",
    "href": "intro.html#quantum-technologies",
    "title": "1  Introduction",
    "section": "1.5 Quantum Technologies",
    "text": "1.5 Quantum Technologies\nOne major difference between the hindsight-history we have for classical computation and the current state of quantum computers is that are many platforms vying to enable quantum computation. There are arguments for and against each platform, and even arguments for using a combination of platforms. Here we give a list of some of the technologies and highlight the ones we will be surveying in this course.\nPlatforms covered in this course\n\nSuperconducting qubits: Artificial atoms made from superconducting circuits that operate at ultra-low temperatures. Currently the most mature platform, used by companies like IBM and Google.\nTrapped ions: Individual atoms held in place by electromagnetic fields. Known for having very long coherence times and high-fidelity gates. Major players include IonQ and Quantinuum (formerly of Honeywell).\nPhotonic quantum computers: Use particles of light (photons) as qubits. Can operate at room temperature and naturally interface with quantum communication systems. Being developed by companies like PsiQuantum and Xanadu.\n\nOther platforms we will not cover\n\nSilicon quantum dots: Quantum bits made from individual electrons trapped in silicon, similar to classical semiconductor technology. Could potentially leverage existing manufacturing processes.\nNeutral atoms and Rydberg arrays: Individual neutral atoms arranged in arrays using laser beams. When excited to high-energy Rydberg states, atoms can interact strongly with their neighbors. Can create large numbers of identical qubits with programmable interactions. Companies like QuEra are pursuing this approach.\nNV centers: Quantum bits made from nitrogen-vacancy defects in diamond. Can operate at room temperature and have long coherence times, making them particularly promising for quantum sensing and networking applications.\n\nA platform we will cover if time permits\n\nTopological qubits: A theoretical approach that would use special quantum states of matter to create error-protected qubits. Still in early research stages but could offer significant advantages if realized.\n\n\n\n\n\n\n\nCurrent State of Quantum Computing\n\n\n\nAs of 2024, the largest quantum computers have around 50-100 physical qubits optimistically, but these are noisy and require error correction. For comparison, your smartphone has billions of classical bits. This highlights the early stage of quantum computing development and the engineering challenges ahead.\n\n\nEach platform has its own advantages and challenges in terms of scalability, error rates, coherence times, and manufacturing complexity. The field is still evolving, and it’s possible that different platforms may be optimal for different applications.\n\n\n\n\n[1] F. Arute et al., Quantum supremacy using a programmable superconducting processor, Nature 574, 505 (2019).\n\n\n[2] Google Quantum AI and Collaborators et al., Quantum error correction below the surface code threshold, Nature (2024).\n\n\n[3] E. Pednault, J. A. Gunnels, G. Nannicini, L. Horesh, and R. Wisnieff, Leveraging Secondary Storage to Simulate Deep 54-qubit Sycamore Circuits, arXiv:1910.09534 (2019).\n\n\n[4] F. Pan, K. Chen, and P. Zhang, Solving the Sampling Problem of the Sycamore Quantum Circuits, Physical Review Letters 129, 090502 (2022).\n\n\n[5] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information: 10th Anniversary Edition, Anniversary edition (Cambridge University Press, Cambridge ; New York, 2011).\n\n\n[6] A. M. Turing, On Computable Numbers, with an Application to the Entscheidungsproblem, Proceedings of the London Mathematical Society s2-42, 230 (1937).\n\n\n[7] L. Hoddeson, The Discovery of the Point-Contact Transistor, Historical Studies in the Physical Sciences 12, 41 (1981).\n\n\n[8] R. P. Feynman, Simulating physics with computers, International Journal of Theoretical Physics 21, 467 (1982).\n\n\n[9] D. Deutsch, Quantum theory, the Church–Turing principle and the universal quantum computer, Proceedings of the Royal Society of London. A. Mathematical and Physical Sciences 400, 97 (1985).\n\n\n[10] D. Deutsch and R. Jozsa, Rapid solution of problems by quantum computation, Proceedings of the Royal Society of London. Series A: Mathematical and Physical Sciences 439, 553 (1992).\n\n\n[11] E. Bernstein and U. Vazirani, Quantum Complexity Theory, SIAM Journal on Computing 26, 1411 (1997).\n\n\n[12] D. R. Simon, On the Power of Quantum Computation, SIAM Journal on Computing 26, 1474 (1997).\n\n\n[13] P. W. Shor, Algorithms for Quantum Computation: Discrete Logarithms and Factoring, in Proceedings 35th Annual Symposium on Foundations of Computer Science (IEEE Comput. Soc. Press, Santa Fe, NM, USA, 1994), pp. 124–134.\n\n\n[14] L. K. Grover, A Fast Quantum Mechanical Algorithm for Database Search, in Proceedings of the Twenty-Eighth Annual ACM Symposium on Theory of Computing - STOC ’96 (ACM Press, Philadelphia, Pennsylvania, United States, 1996), pp. 212–219.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "Note that P or N stands for positive or negative carriers.↩︎\nMade by VectorVoyager and licensed under Creative Commons Attribution-Share Alike 3.0 Unported↩︎\nLicensed under Creative Commons CC0 1.0 Universal Public Domain Dedication.↩︎\nFor details on how this was made, see How the first transistor worked↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "qubit.html",
    "href": "qubit.html",
    "title": "2  The Qubit",
    "section": "",
    "text": "2.1 The Qubit Hilbert space\nThe fundamental building block of the classical computer was the bit: A 0 or 1 that could be manipulated by a classical computer (via transistors, see Section 1.2). In a similar manner, quantum computation has the “quantum bit” or just qubit, for short. This leads us to the linear algebra of \\(2\\times 2\\) matrices, as we will see. Despite the apparent simplicity, we can already see many of the key features of quantum mechanics in this simple system.\nA qubit will be in two-dimensional complex vector space equipped with an inner product.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Qubit</span>"
    ]
  },
  {
    "objectID": "qubit.html#the-qubit-hilbert-space",
    "href": "qubit.html#the-qubit-hilbert-space",
    "title": "2  The Qubit",
    "section": "",
    "text": "2.1.1 Qubit states\nFor the qubit, we associate two states with two different basis vectors: \\(\\ket{0}\\) and \\(\\ket{1}\\). This will be called the computational basis. The magic1 of quantum mechanics is that a state need not be just one or the other, but could be any linear superposition of these \\[\n\\ket{\\psi} = \\alpha \\ket{0} + \\beta \\ket{1}.\n\\tag{2.1}\\] In this, we have adopted the bra-ket notation due to Dirac. While it can be quite useful, we can write this in terms of matrices and vectors \\[\n\\ket{0} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}, \\quad \\ket{1} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}.\n\\] This makes it clear that these states are orthogonal \\(\\braket{0|1} = 0\\).\nIn this case we have \\[\n\\ket{\\psi} = \\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix}.\n\\] We also need the conjugate transpose, the Hermitian conjugate, of this vector, which will be a row-vector \\[\n\\bra{\\psi} = \\begin{bmatrix} \\alpha^* & \\beta^* \\end{bmatrix}.\n\\] The key feature of quantum mechanics is that these states must be normalized, meaning that the probability of finding the system in any state must sum to 1. This means that \\[\n\\braket{\\psi|\\psi} = \\begin{bmatrix} \\alpha^* & \\beta^* \\end{bmatrix} \\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix} = |\\alpha|^2 + |\\beta|^2 = 1.\n\\] In matrix notation, this is just the dot product of a vector with its complex conjugate.\n\n\n\n\n\n\nWhy Normalization Matters\n\n\n\nThe normalization condition \\(|\\alpha|^2 + |\\beta|^2 = 1\\) isn’t just mathematical convenience - it ensures probabilities add up to 100%! For example:\n\n\\(\\ket{\\psi} = \\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1})\\) gives 50-50 chance of measuring 0 or 1\n\\(\\ket{\\psi} = \\frac{\\sqrt{3}}{2}\\ket{0} + \\frac{1}{2}\\ket{1}\\) gives 75% chance of 0 and 25% chance of 1\n\n\n\nWe can also write operators that act on these states. The simplest operator is the Pauli \\(Z\\) operator, which in matrix form is \\[\nZ = \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix}.\n\\] When this operator acts on our basis states, we find \\[\nZ\\ket{0} = \\ket{0}, \\quad Z\\ket{1} = -\\ket{1}.\n\\] This means that \\(\\ket{0}\\) and \\(\\ket{1}\\) are eigenstates of \\(Z\\) with eigenvalues \\(+1\\) and \\(-1\\) respectively. For a general state \\(\\ket{\\psi}\\), measuring \\(Z\\) will yield either \\(+1\\) or \\(-1\\), with probabilities determined by \\(|\\alpha|^2\\) and \\(|\\beta|^2\\) respectively.\n\n\n\n\n\n\nExample: Measuring a superposition state\n\n\n\nConsider the state \\(\\ket{\\psi} = \\frac35\\ket{0} + \\frac45\\ket{1}\\). When we measure this state in the \\(Z\\) basis:\nNotice that this state is normalized since \\((\\frac{3}{5})^2 + (\\frac{4}{5})^2 = 1\\). If we measure this state in the computational basis:\n\nWe’ll get outcome \\(\\ket{0}\\) with probability \\(|\\frac{3}{5}|^2 = 0.36\\) (36%)\nWe’ll get outcome \\(\\ket{1}\\) with probability \\(|\\frac{4}{5}|^2 = 0.64\\) (64%)\n\nAfter measurement, the state will collapse to either \\(\\ket{0}\\) or \\(\\ket{1}\\) with the above probabilities\n\n\n\n\n\n\n\n\nMeasurement Collapse in Practice\n\n\n\nWhen we say a quantum state “collapses” upon measurement, what actually happens in the lab?\n\nFor a superconducting qubit: We measure a voltage or current\nFor an ion trap: We detect scattered photons\nFor a photonic qubit: We count photons with a detector\n\nEach technology has its own way of converting quantum information into classical signals!\n\n\n\n\n2.1.2 Qubit operators\nSince this is linear algebra, we can write a general operator \\(\\mathcal O\\) as a matrix \\[\n\\mathcal O = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}.\n\\] Often, we are interested in the eigenvalues and eigenstates of these operators \\(\\mathcal O \\ket{\\psi_{i}} = \\lambda_i \\ket{\\psi_i}\\). Generically, we can find these by solving a polynomial equation \\[\n\\det(\\mathcal O - \\lambda I) = 0.\n\\]\nSolving this step-by-step \\[\n\\det(\\mathcal O - \\lambda I) = \\begin{vmatrix} a-\\lambda & b \\\\ c & d-\\lambda \\end{vmatrix} = 0,\n\\] which gives us \\[\n(a-\\lambda)(d-\\lambda) - bc = 0.\n\\] This is a quadratic equation that we can solve: \\[\n\\lambda^2 - (a+d)\\lambda + (ad-bc) = 0.\n\\]\nThe eigenvalues are therefore \\[\n\\lambda_{\\pm} = \\frac{a+d \\pm \\sqrt{(a-d)^2 + 4bc}}{2}.\n\\tag{2.2}\\]\nFor quantum mechanical observables (see Section 1.3.2), we are particularly interested in Hermitian operators where \\(\\mathcal O = \\mathcal O^\\dagger\\), \\[\n\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} = \\begin{bmatrix} a^* & c^* \\\\ b^* & d^* \\end{bmatrix}\n\\] This means that \\(a\\) and \\(d\\) must be real and \\(c = b^*\\). In this case, the eigenvalues are always real, as we can see from the Eq. 2.2.\nA particularly important class of operators are unitary operators, where \\(U^\\dagger U = UU^\\dagger = I\\). These are what we use for time-evolution, see Section 1.3.3.\nThese operators preserve the inner product between states: \\[\n\\braket{U\\psi|U\\phi} = \\braket{\\psi|\\phi}\n\\] For a \\(2\\times 2\\) matrix \\[\nU = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix},\n\\] the unitarity condition means that \\[\n\\begin{bmatrix} a^* & c^* \\\\ b^* & d^* \\end{bmatrix} \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}.\n\\]\nThis gives us several conditions:\n\n\\(|a|^2 + |c|^2 = 1\\) (normalization of first column)\n\\(|b|^2 + |d|^2 = 1\\) (normalization of second column)\n\\(ab^* + cd^* = 0\\) (orthogonality of columns)\n\nThis immediately gives us some insight into these operators. If we define, \\[\n\\ket{\\psi_1} = \\begin{bmatrix} a \\\\ c \\end{bmatrix}, \\quad \\ket{\\psi_2} = \\begin{bmatrix} b \\\\ d \\end{bmatrix},\n\\] then we have \\(\\braket{\\psi_1|\\psi_1} = 1 = \\braket{\\psi_2|\\psi_2}\\) and \\(\\braket{\\psi_1|\\psi_2} = 0\\).\nAn important property of unitary operators is that their eigenvalues always have magnitude 1, meaning they can be written as \\(e^{i\\theta}\\) for some real \\(\\theta\\). This makes them natural operators for describing quantum evolution.\n\n\n\n\n\n\nWhy Unitary?\n\n\n\nUnitary operators are special because they:\n\nPreserve the normalization of quantum states\nAre reversible (have an inverse)\nRepresent physical operations that conserve probability\n\nThis is why quantum gates must be unitary - they represent real physical processes that can be undone!\n\n\n\n\n2.1.3 The Pauli operators\nA particularly important set of operators are the Pauli operators. We’ve already seen the Pauli \\(Z\\) operator. The other two are2 \\[\nX = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}, \\quad Y = \\begin{bmatrix} 0 & -i \\\\ i & 0 \\end{bmatrix}.\n\\] These operators satisfy some important algebraic relations: \\[\nX^2 = Y^2 = Z^2 = I, \\quad XY = iZ, \\quad YZ = iX, \\quad ZX = iY.\n\\] We can additionally start to see some logical operations begin to appear; \\(X\\) operates on the computational basis as a NOT gate \\[\nX \\ket{0} = \\ket{1}, \\quad X \\ket{1} = \\ket{0}.\n\\]\n\n\n\n\n\n\nPauli Operators in Action\n\n\n\nThe Pauli operators represent quantum operations:\n\n\\(X\\) is like the classical NOT gate: flips between \\(\\ket{0}\\) and \\(\\ket{1}\\)\n\\(Z\\) adds a phase: leaves \\(\\ket{0}\\) alone but negates \\(\\ket{1}\\)\n\\(Y = iXZ\\) combines both operations.\n\nThese simple operations are building blocks for more complex quantum algorithms!\n\n\n\n\n\n\n\n\nExample: Applying operators\n\n\n\nLet’s apply the X (NOT) gate to our state \\(\\ket{\\psi} = (\\tfrac{3}{5}\\ket{0} + \\tfrac{4}{5}\\ket{1})\\): \\[\n\\begin{aligned}\nX\\ket{\\psi} &= X(\\tfrac{3}{5}\\ket{0} + \\tfrac{4}{5}\\ket{1}) \\\\\n&= \\tfrac{3}{5}X\\ket{0} + \\tfrac{4}{5}X\\ket{1} \\\\\n&= \\tfrac{3}{5}\\ket{1} + \\tfrac{4}{5}\\ket{0} \\\\\n&= \\tfrac{4}{5}\\ket{0} + \\tfrac{3}{5}\\ket{1}\n\\end{aligned}\n\\]\n\n\nThe full set of Pauli operators, along with the identity, form a complete basis for \\(2\\times 2\\) matrices, meaning we can write any operator as \\[\n\\mathcal O = aI + bX + cY + dZ,\n\\] where \\(a\\), \\(b\\), \\(c\\), and \\(d\\) are complex numbers. We can extract each of these numbers, mathematically, with a trace operation \\[\n\\tr \\mathcal O = 2a, \\quad \\tr \\mathcal O X = 2b, \\quad \\tr \\mathcal O Y = 2c, \\quad \\tr \\mathcal O Z = 2d.\n\\] Note that separately, \\(X\\), \\(Y\\), and \\(Z\\) are Hermitian (and thus, observables). If \\(\\mathcal O\\) is an observable, then \\(\\mathcal O = \\mathcal O^\\dagger\\) immediately leads us to \\(a\\), \\(b\\), \\(c\\), and \\(d\\) being all real.\nWe can put constraints on these coefficients for unitary operators as well, and we leave this as an exercise for the reader.\nFinally, these operators have eigenstates as well, and we can define them as \\(X\\ket{\\pm} = \\pm \\ket{\\pm}\\) and \\(Y\\ket{\\pm i} = \\pm \\ket{\\pm i}\\), and they have the forms \\[\n\\begin{aligned}\n    \\ket{\\pm} & = \\tfrac1{\\sqrt2}(\\ket 0 \\pm \\ket 1), \\\\\n    \\ket{\\pm i} & = \\tfrac1{\\sqrt2}(\\ket 0 \\pm i \\ket 1).\n\\end{aligned}\n\\]\nWe will often want to change our basis from \\(\\ket{0}\\) and \\(\\ket{1}\\) to \\(\\ket{+}\\) and \\(\\ket{-}\\). This is accomplished with something called the Hadamard gate (we’ll call it \\(H\\), not to be confused with a Hamiltonian) and it is created specifically to change from computational basis to the \\(X\\) basis: \\(H \\ket{0} = \\ket{+}\\) and \\(H \\ket{1} = \\ket{-}\\). As a matrix it takes the form \\[\nH = \\frac1{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}.\n\\]\n\n\n\n\n\n\nThe Power of Hadamard\n\n\n\nThe Hadamard gate is one of the most important gates in quantum computing with useful properties:\n\nIt creates equal superpositions from computational basis states.\nIt’s its own inverse (\\(H^2 = I\\))\nIt’s used in nearly every quantum algorithm\nWhen applied to \\(n\\) qubits, it creates a superposition of all \\(2^n\\) possible bit strings!\n\n\n\n\n\n\n\n\n\nExample 3: The Hadamard Transform\n\n\n\nThe Hadamard gate is particularly important because it creates superposition states. Let’s see what happens when we apply it to \\(\\ket{0}\\): \\[\n\\begin{aligned}\nH\\ket{0} &= \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\\\\n&= \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} \\\\\n&= \\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1}) \\\\\n&= \\ket{+}\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Qubit</span>"
    ]
  },
  {
    "objectID": "qubit.html#sec-bloch-sphere",
    "href": "qubit.html#sec-bloch-sphere",
    "title": "2  The Qubit",
    "section": "2.2 The Bloch sphere",
    "text": "2.2 The Bloch sphere\nThe qubit itself is more than just a probability of being a 1 or a 0. A crucial bit of quantum information is the relative phase between the two states for instance \\[\n\\ket{\\psi} = \\tfrac1{\\sqrt2}( \\ket 0 + e^{i\\phi} \\ket 1),\n\\] and since all states are equivalent up to a total phase, we can write the amplitude of each state with a real number. In this case, if we set \\(\\ket{\\psi} = x \\ket{0} + y e^{i\\phi} \\ket 1\\), then we have \\(\\braket{\\psi|\\psi} = x^2 + y^2 = 1\\) for normalization. This is the equation for a circle, and writing out \\(x = \\cos(\\theta/2)\\) and \\(y = \\sin(\\theta/2)\\)3, we are lead to an angular representation of our state. \\[\n\\ket{\\psi} = \\cos(\\theta/2) \\ket{0} + \\sin(\\theta/2)e^{i\\phi} \\ket{1}.\n\\tag{2.3}\\] Let’s see how this state relates to our Pauli operators. If we calculate the expectation values of each operator:\n\\[\n\\begin{aligned}\n\\langle X \\rangle &= \\bra{\\psi}X\\ket{\\psi} \\\\\n&= (\\cos(\\theta/2) \\bra{0} + \\sin(\\theta/2)e^{-i\\phi} \\bra{1})\n   X\n   (\\cos(\\theta/2) \\ket{0} + \\sin(\\theta/2)e^{i\\phi} \\ket{1}) \\\\\n&= (\\cos(\\theta/2) \\bra{0} + \\sin(\\theta/2)e^{-i\\phi} \\bra{1})\n   (\\cos(\\theta/2) \\ket{1} + \\sin(\\theta/2)e^{i\\phi} \\ket{0}) \\\\\n&= \\sin(\\theta/2)\\cos(\\theta/2) e^{i\\phi} + \\cos(\\theta/2)\\sin(\\theta/2)e^{-i\\phi} \\\\\n&= \\sin(\\theta/2)\\cos(\\theta/2) (e^{i\\phi} + e^{-i\\phi}) \\\\\n&= 2\\sin(\\theta/2)\\cos(\\theta/2) \\cos\\phi \\\\\n&= \\sin \\theta \\cos\\phi.\n\\end{aligned}\n\\] We can carry out a similar calculation for \\(Y\\) and \\(Z\\) to obtain \\[\n\\begin{aligned}\n\\langle X \\rangle &= \\bra{\\psi}X\\ket{\\psi} = \\sin\\theta\\cos\\phi \\\\\n\\langle Y \\rangle &= \\bra{\\psi}Y\\ket{\\psi} = \\sin\\theta\\sin\\phi \\\\\n\\langle Z \\rangle &= \\bra{\\psi}Z\\ket{\\psi} = \\cos\\theta\n\\end{aligned}\n\\]\nThese expectation values give us coordinates , which are precisely the coordinates of a point on a unit sphere! This is why we call it the Bloch sphere. The angles \\(\\theta\\) and \\(\\phi\\) are the usual spherical coordinates.\n\n\n\n\n\n\nThe Bloch Sphere Geometry\n\n\n\n\nThe north pole (\\(\\theta=0\\)) corresponds to \\(\\ket{0}\\)\nThe south pole (\\(\\theta=\\pi\\)) corresponds to \\(\\ket{1}\\)\nThe equator (\\(\\theta=\\pi/2\\)) contains equal superposition of computational basis states:\n\n\\(\\phi=0\\) gives \\(\\ket{+}\\) (positive x-axis)\n\\(\\phi=\\pi\\) gives \\(\\ket{-}\\) (negative x-axis)\n\\(\\phi=\\pi/2\\) gives \\(\\ket{+i}\\) (positive y-axis)\n\\(\\phi=3\\pi/2\\) gives \\(\\ket{-i}\\) (negative y-axis)\n\n\n\n\n\n\n\n\n\n\n\nFig. 2.1: The Bloch sphere showing eigenstates of X, Y, and Z Pauli operators\n\n\n\n\n\n\n\n\n\nExample: Hadamard Gate on \\(\\ket{0}\\)\n\n\n\nThe Hadamard gate \\(H\\) takes the state \\(\\ket{0}\\) (north pole) to \\(\\ket{+}\\) (on the equator at \\(\\phi=0\\)). In terms of the Bloch sphere coordinates, this means:\n\nStarting point: \\(\\theta=0\\) (north pole)\nEnding point: \\(\\theta=\\pi/2\\), \\(\\phi=0\\) (positive x-axis)\n\nThe gate effectively rotates the state by 90° around the y-axis. Similarly, \\(H\\ket{1}\\) takes the south pole to \\(\\ket{-}\\) on the negative x-axis.\n\n\n\n2.2.1 General Unitary Rotations\nThe Hadamard example shows how unitary gates can rotate states on the Bloch sphere. More generally, any single-qubit unitary operation can be thought of as a rotation of the Bloch sphere. Let’s see how this works.\nA general rotation around a unit vector \\(\\vec{n} = (n_x, n_y, n_z)\\) by angle \\(\\theta\\) is given by \\[\nR_{\\vec{n}}(\\theta) = \\cos(\\theta/2)I - i\\sin(\\theta/2)(n_xX + n_yY + n_zZ).\n\\]\nFor example:\n\nRotation around z-axis: \\[ R_z(\\theta) = e^{-i\\theta Z/2} = \\begin{bmatrix} e^{-i\\theta/2} & 0 \\\\ 0 & e^{i\\theta/2} \\end{bmatrix} \\]\nRotation around x-axis: \\[ R_x(\\theta) = e^{-i\\theta X/2} = \\begin{bmatrix} \\cos(\\theta/2) & -i\\sin(\\theta/2) \\\\ -i\\sin(\\theta/2) & \\cos(\\theta/2) \\end{bmatrix} \\]\nRotation around y-axis: \\[R_y(\\theta) = e^{-i\\theta Y/2} = \\begin{bmatrix} \\cos(\\theta/2) & -\\sin(\\theta/2) \\\\ \\sin(\\theta/2) & \\cos(\\theta/2) \\end{bmatrix}\\]\n\nA remarkable fact is that any single-qubit unitary operation can be decomposed into three rotations around two different axes. This is known as the Euler angle decomposition: \\[\nU = e^{i\\alpha}R_z(\\phi)R_y(\\theta)R_z(\\psi)\n\\] where \\(\\alpha\\), \\(\\phi\\), \\(\\theta\\), and \\(\\psi\\) are real numbers. The global phase \\(e^{i\\alpha}\\) is often unimportant for quantum computing purposes.\n\n\n\n\n\n\nVisualizing Rotations\n\n\n\nThe Euler angle decomposition has a nice geometric interpretation:\n\nFirst rotation (\\(R_z(\\psi)\\)): Rotate around z-axis\nSecond rotation (\\(R_y(\\theta)\\)): Tilt to new latitude\nThird rotation (\\(R_z(\\phi)\\)): Rotate to final longitude\nGlobal phase (\\(e^{i\\alpha}\\)): Invisible in measurements\n\nThis is similar to how we specify points on Earth using latitude and longitude!\n\n\n\n\n2.2.2 The Phase Gate\nThe phase gate (often denoted as \\(S\\)) is another important single-qubit gate that adds a phase of \\(i\\) to the \\(\\ket{1}\\) state while leaving \\(\\ket{0}\\) unchanged:\n\\[\nS = \\begin{bmatrix} 1 & 0 \\\\ 0 & i \\end{bmatrix}\n\\]\nWhen acting on basis states: \\[\nS\\ket{0} = \\ket{0}, \\quad S\\ket{1} = i\\ket{1}\n\\]\nThe phase gate is equivalent to a \\(\\pi/2\\) rotation around the z-axis: \\(S = R_z(\\pi/2)\\). On the Bloch sphere, this corresponds to rotating a state by 90° around the z-axis.\n\n\n\n\n\n\nExample: Phase Gate on Superposition\n\n\n\nLet’s see what happens when we apply \\(S\\) to an equal superposition state:\n\\[\n\\begin{aligned}\nS\\ket{+} &= S\\left(\\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1})\\right) \\\\\n&= \\frac{1}{\\sqrt{2}}(S\\ket{0} + S\\ket{1}) \\\\\n&= \\frac{1}{\\sqrt{2}}(\\ket{0} + i\\ket{1})\n\\end{aligned}\n\\]\nThis transforms \\(\\ket{+}\\) into \\(\\ket{+i}\\), rotating it from the positive x-axis to the positive y-axis on the Bloch sphere.\n\n\nThe phase gate is particularly important in quantum error correction and quantum algorithms where controlled phase operations are needed.\nMore generically, we can create any \\(R_z(\\phi)\\) gate to perform rotations about the \\(z\\)-axis (this is very useful for Shor’s algorithm). However, a common variant is the \\(T\\) gate, which is simply \\(R_z(\\pi/4)\\) and is one of the minimal components needed to achieve universal quantum computation.\n\n\n\n\n\n\nPhase gate leaves computational basis states alone\n\n\n\nNote that these gates only change superposition of computational basis states, so \\(S \\ket{0} = \\ket{0}\\) and \\(S\\ket{1} = i \\ket{1}\\). (Similarly for any gate made from rotations about the z-axis.)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Qubit</span>"
    ]
  },
  {
    "objectID": "qubit.html#quantum-circuits",
    "href": "qubit.html#quantum-circuits",
    "title": "2  The Qubit",
    "section": "2.3 Quantum Circuits",
    "text": "2.3 Quantum Circuits\nNow that we’ve covered the key single-qubit operations, we can start to think about how to represent sequences of these operations graphically using quantum circuits. In quantum circuits:\n\nQubits are represented as horizontal lines (called “wires”, see Fig. 2.2).\nGates are boxes or symbols placed on these wires (see Fig. 2.3 and Fig. 2.4).\nTime flows from left to right.\nMeasurements are represented by meters (see Fig. 2.5).\n\nOften, unless we are preparing a specific state for an algorithm, we may leave off the states from the ends of the “wire.” This wire, Fig. 2.2, you can think of as the identity.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Identity on \\(\\ket{0}\\)\n\n\n\n\n\n\n\n\n\n\n\n(b) Identity on \\(\\ket{1}\\)\n\n\n\n\n\n\n\n\n\n\n\n(c) Identity on \\(\\ket{\\psi}\\)\n\n\n\n\n\n\n\nFig. 2.2: Lines representing the evolution of a qubit (no gates applied)\n\n\n\nWhile in quantum state evolution we apply operators right-to-left, the two operations \\(X \\ket{0} = \\ket{1}\\) and \\(Z \\ket{+} = \\ket{-}\\) are represented in Fig. 2.3.\n\n\n\n\n\n\nImportant\n\n\n\nThe Pauli operators are both unitary and Hermitian, so they perform as quantum gates (which require unitary as Section 1.3.3 stipulates) and as observables (as Section 1.3.2 stipulates).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Application of the \\(X\\) gate.\n\n\n\n\n\n\n\n\n\n\n\n(b) Application of the \\(Z\\) gate.\n\n\n\n\n\n\n\nFig. 2.3: Examples of the Pauli operators as gates.\n\n\n\nThe Hadamard and phase gates can also be mixed in, Fig. 2.4, and we can even introduce the meter symbol for measurements, Fig. 2.5.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Application of the Hadamard gate.\n\n\n\n\n\n\n\n\n\n\n\n(b) Application of the phase gate\n\n\n\n\n\n\n\nFig. 2.4: Examples of the Hadamard and phase gates.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Will measure 1 with 100% probability\n\n\n\n\n\n\n\n\n\n\n\n(b) Will measure 1 with 50% probability\n\n\n\n\n\n\n\nFig. 2.5: Examples of measurements. The meter is assumed to be measuring in the computational basis unless otherwise noted (i.e., measuring the \\(Z\\) operator).\n\n\n\nWhenever measurements are performed, we will often transform to the computational basis \\(\\ket{0}\\) and \\(\\ket{1}\\) to perform a measurement. By playing tricks with unitary transformations, we can measure other observables by mixing unitaries and measurements of the computational basis; dependent on the platform, this may or may not be necessary. In terms of diagrams, you should assume meters are measurements in the computational basis unless it is noted otherwise.\n\n\n\n\n\n\nReading Quantum Circuits\n\n\n\nQuantum circuits are read from left to right, just like reading text. Each horizontal line represents a qubit’s journey through time, and the boxes show what operations happen and when.\nThe measurement symbol at the end indicates when we extract classical information from our quantum system.\n\n\nThese diagrams give us a powerful visual language for describing quantum computations. Even complex algorithms can be broken down into sequences of these basic operations.\n\n\n\n\n\n\nExample: Gate Sequences\n\n\n\nConsider applying \\(H\\) then \\(Z\\) then \\(H\\) to \\(\\ket{0}\\):\n\n\n\n\n\n\n\nFig. 2.6: Implementing an \\(X\\) gate with \\(Z\\) and \\(H\\).\n\n\n\n\n\\(H\\ket{0} = \\ket{+}\\) (move to +x axis)\n\\(Z\\ket{+} = \\frac{1}{\\sqrt{2}}(\\ket{0} - \\ket{1})\\) (rotate around z by 90°)\n\\(H(\\frac{1}{\\sqrt{2}}(\\ket{0} - \\ket{1})) = \\ket{1}\\) (move to -z axis)\n\nThis sequence effectively implements the \\(X\\) gate!",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Qubit</span>"
    ]
  },
  {
    "objectID": "qubit.html#noise-and-decoherence",
    "href": "qubit.html#noise-and-decoherence",
    "title": "2  The Qubit",
    "section": "2.4 Noise and decoherence",
    "text": "2.4 Noise and decoherence\nA large part of the course will consist of finding physical systems where we can identify certain states as \\(\\ket{0}\\) and \\(\\ket{1}\\), and then proceed to figure out how to perform the gates we need for quantum algorithms. In this way, this course could be called “two-level systems and where to find them.” However, these states are not pristine and so we need a way to talk about states that subject to noisy environments and loss of information.\nIn fact, environmental interactions can cause, amongst other issues:\n\nLoss of phase information (dephasing)\nLoss of energy (amplitude damping)\nRandom bit flips\n\nTo properly describe these noise processes, we need to move beyond pure state descriptions and introduce the density matrix formalism.\n\n2.4.1 The Density Matrix\nFor a pure quantum state \\(\\ket{\\psi}\\), the density matrix is defined as \\[\n\\rho = \\ket{\\psi}\\bra{\\psi}\n\\] For example, the computational basis states have density matrices: \\[\n\\ket{0}\\bra{0} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix}, \\quad\n\\ket{1}\\bra{1} = \\begin{bmatrix} 0 & 0 \\\\ 0 & 1 \\end{bmatrix}\n\\]\nThe density matrix also provides a convenient way to calculate expectation values of observables. For any observable \\(A\\), the expectation value is given by: \\[\n\\langle A \\rangle = \\tr(A\\rho)\n\\] For a pure state \\(\\ket{\\psi}\\), this reduces to our familiar expression: \\[\n\\tr(A\\ket{\\psi}\\bra{\\psi}) = \\bra{\\psi}A\\ket{\\psi}\n\\]\n\n\n\n\n\n\nExample: Measuring \\(Z\\) with the Density Matrix\n\n\n\nConsider measuring \\(Z\\) for the state \\(\\ket{+} = \\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1})\\):\nThe density matrix is: \\[\n\\rho_+ = \\frac{1}{2}\\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}\n\\]\nUsing the formula for expecation values with \\(Z = \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix}\\): \\[\n\\langle Z \\rangle = \\tr(Z\\rho_+) = \\tr\\left(\\frac{1}{2}\\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix}\\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}\\right) = 0\n\\]\nThis matches what we expect: \\(\\ket{+}\\) has equal probability of measuring \\(\\pm 1\\) for \\(Z\\).\n\n\nThe real power of density matrices comes from describing mixed states, which are statistical mixtures of pure states: \\[\n\\rho = \\sum_i p_i \\ket{\\psi_i}\\bra{\\psi_i}\n\\] where \\(p_i\\) are classical probabilities (\\(p_i \\geq 0\\), \\(\\sum_i p_i = 1\\)).\n\n\n\n\n\n\nProperties of Density Matrices\n\n\n\nAny valid density matrix must satisfy:\n\nHermiticity: \\(\\rho = \\rho^\\dagger\\)\nPositive semidefinite: \\(\\bra{\\phi}\\rho\\ket{\\phi} \\geq 0\\) for all \\(\\ket{\\phi}\\)\nUnit trace: \\(\\tr(\\rho) = 1\\)\nFor pure states: \\(\\tr(\\rho^2) = 1\\)\nFor mixed states: \\(\\tr(\\rho^2) &lt; 1\\)\n\n\n\n\nQuantum Operations with Density Matrices\nJust as we can evolve pure states with unitary operators, we can evolve density matrices. For a unitary operation \\(U\\), the density matrix transforms as: \\[\n\\rho \\rightarrow U\\rho U^\\dagger\n\\] This preserves all the properties of the density matrix we discussed above.\nWhen we make a measurement, we use projection operators \\(\\{P_m\\}\\) (like \\(\\ket{0}\\bra{0}\\) and \\(\\ket{1}\\bra{1}\\) for measuring in the computational basis). The probability of getting outcome \\(m\\) is: \\[\np(m) = \\tr(P_m \\rho)\n\\] After measuring and getting outcome \\(m\\), the state “collapses” to: \\[\n\\rho_m = \\frac{P_m \\rho P_m}{\\tr(P_m \\rho)}\n\\] where the denominator ensures the trace remains 1.\n\n\n\n\n\n\nQuantum Channels\n\n\n\nThe density matrix formalism really shines when describing general quantum evolution, including noise. Any physical process (unitary or not) can be described by a quantum channel \\(\\mathcal{E}\\): \\[\n\\rho \\rightarrow \\mathcal{E}(\\rho) = \\sum_k E_k \\rho E_k^\\dagger\n\\] The operators \\(E_k\\) (called Kraus operators) satisfy \\(\\sum_k E_k^\\dagger E_k = I\\) to preserve probability. This includes both ideal unitary evolution (one \\(E_k = U\\)) and noise processes (multiple \\(E_k\\)), as we’ll see in the next section.\n\n\n\n\nDensity Matrices and the Bloch Sphere\nThe density matrix formalism provides a beautiful geometric picture when combined with the Bloch sphere representation in Section 2.2. While pure states live on the surface of the Bloch sphere, mixed states live inside it. Any density matrix for a single qubit can be written as: \\[\n\\rho = \\frac{1}{2}(I + \\vec{r}\\cdot\\vec{\\sigma})\n\\] where \\(\\vec{r} = (r_x, r_y, r_z)\\) is called the Bloch vector and \\(\\vec{\\sigma} = (X,Y,Z)\\) are the Pauli matrices.\nThe length of \\(\\vec{r}\\) determines how mixed the state is:\n\nFor pure states, \\(|\\vec{r}| = 1\\) (surface of sphere)\nFor mixed states, \\(|\\vec{r}| &lt; 1\\) (inside sphere)\nFor the maximally mixed state, \\(\\vec{r} = 0\\) (center of sphere)\n\nThis gives us an intuitive picture of decoherence: noise processes like dephasing and bit flips move the Bloch vector inward from the surface, representing the loss of quantum information. The maximally mixed state at the center represents complete loss of information–equal probabilities for all measurement outcomes.\n\n\n\n\n\n\nConnection to Purity\n\n\n\nThe length of the Bloch vector is directly related to the purity \\(\\tr(\\rho^2)\\) we discussed earlier: \\[\n\\tr(\\rho^2) = \\frac{1 + |\\vec{r}|^2}{2}\n\\] This confirms that pure states (\\(|\\vec{r}| = 1\\)) have purity 1, while mixed states have purity less than 1.\n\n\n\n\n\n2.4.2 Modeling Noise\nA full discussion of different quantum channels can be found in  [3]. Here, we discuss some of the ones relevant for loss of quantum information.\nThe language of density matrices allows us to describe some of the errors that can occur in a precise manner\n\nRandom bit-flips\nIf there is probability \\(p\\) that a bit is flipped, we can encode this within a change of the density matrix: \\[\n\\rho \\rightarrow (1-p)\\rho + p X\\rho X,\n\\] where the first term describes the probability that the density matrix remains unchanged and the second describe the process of randomly flipping a bit.\n\n\nDephasing\nAs we’ve already mentioned the phase between \\(\\ket{0}\\) and \\(\\ket{1}\\) is useful information that we will take advantage of. However, some physical processes can scramble this phase in a way that could be inherently difficult to parse, in that case we can describe these processes with “dephasing” \\[\n\\rho \\rightarrow (1-p)\\rho + p Z \\rho Z.\n\\] This process has a clear action on \\(\\rho\\) when \\(p=1/2\\). To illustrate this, consider \\(\\ket{\\psi} = \\alpha \\ket{0} + \\beta \\ket{1}\\), this has a probability of measuring \\(0\\) of \\(|\\alpha|^2\\) and a probabilty of measuring \\(1\\) of \\(|\\beta|^2\\), but there is also phase information between \\(\\alpha\\) and \\(\\beta\\) that tells us where on the Bloch sphere the state is located. Dephasing will eliminate this phase information.\nTo see this, the full density matrix before we apply dephasing is \\[\n\\rho = \\begin{bmatrix} |\\alpha|^2 & \\alpha\\beta^* \\\\ \\alpha^*\\beta & |\\beta|^2 \\end{bmatrix},\n\\] and after dephasing we will have the density matrix \\[\n\\frac12 \\rho + \\frac12 Z \\rho Z = \\begin{bmatrix} |\\alpha|^2 & 0 \\\\ 0 & |\\beta|^2 \\end{bmatrix}.\n\\] The off-diagonal components carried the relative phase information and it is now entirely lost, leaving us with a classical mixture of \\(\\ket{0}\\) and \\(\\ket{1}\\)\n\n\n\n\n\n\nMeasurement as Dephasing\n\n\n\nThis process of losing phase information is exactly what happens when we measure a quantum state in a particular basis! When we measure in the computational basis (\\(\\{\\ket{0}, \\ket{1}\\}\\)), we are effectively performing complete dephasing - we destroy all phase information between the basis states and are left with only the classical probabilities. This is why measurement is often described as “collapsing” the quantum state into classical information.\nThis connection between measurement and dephasing illustrates a fundamental aspect of quantum mechanics: the act of gaining classical information about a quantum system necessarily destroys some of its quantum properties, as formalized in the measurement postulates we discussed earlier.\n\n\n\n\n\n\n\n\nExample: Dephasing of a Superposition State\n\n\n\nConsider the state \\(\\ket{+} = \\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1})\\) under dephasing:\nInitial density matrix: \\[\n\\rho_0 = \\frac{1}{2}\\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}\n\\]\nAfter dephasing with probability \\(p\\): \\[\n\\rho(p) = \\frac{1}{2}\\begin{bmatrix} 1 & (1-2p) \\\\ (1-2p) & 1 \\end{bmatrix}\n\\]\nComplete dephasing (\\(p=\\frac{1}{2}\\)) yields the maximally mixed state: \\[\n\\rho(\\tfrac{1}{2}) = \\frac{1}{2}\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}\n\\]\n\n\n\n\nDepolarizing\nThe depolarizing channel represents one of the most severe forms of noise in quantum systems, often considered the “worst-case scenario” for quantum information. This channel transforms any input state into a mixture of itself and the maximally mixed state: \\[\n\\rho \\rightarrow (1-p)\\rho + p \\frac{I}{2},\n\\] where \\(p\\) represents the probability of depolarization. When \\(p=1\\), the state becomes completely mixed regardless of the input: \\[\n\\rho \\rightarrow \\frac{1}{2}I.\n\\]\nNote that this has eliminated any information about \\(\\ket{\\psi}\\)!\n\n\n\n\n\n\nExample: The Pauli Twirl\n\n\n\nAn interesting way to understand the depolarizing channel is through what’s called the “Pauli twirl”. The depolarizing channel can be written as a random application of Pauli operators: \\[\n\\rho \\rightarrow (1-p)\\rho + \\frac{p}{3}(X\\rho X + Y\\rho Y + Z\\rho Z).\n\\]\nThis means we can implement depolarizing noise by randomly applying X, Y, or Z gates with probability \\(p/3\\) each. This is particularly useful in quantum error correction, where we often want to simulate noise in a way that’s easy to analyze.\n\n\n\n\nAmplitude Damping\nIn many physical systems, one can lose information by having emission of energy. Physically, this could be an atom in some energy level and it emits a photon, falling to a lower energy level. One can imagine a process like this occuring with an operator \\[\nE_0 = \\sqrt{\\gamma} \\ket{0} \\bra{1},\n\\] which describes the process of taking an occupied state \\(\\ket{1}\\) and transforming it to \\(\\ket{0}\\) with probability \\(\\gamma\\). To fully encode this into a change in the density matrix, we need one other operator: the chance that nothing happens. A natural guess would be \\[\nE_1 = \\ket{0}\\bra{0} + \\sqrt{1-\\gamma} \\ket{1}\\bra{1},\n\\] which describes that there is unit probability of remaining \\(\\ket{0}\\) and probaiblity \\(1-\\gamma\\) of remaining in \\(\\ket{1}\\) if you start there.\nThe full operation on the density matrix is then \\[\n\\rho \\rightarrow E_1 \\rho E_1^\\dagger + E_0 \\rho E_0^\\dagger\n\\]\n\n\n\n\n\n\nExample: Amplitude Damping in Action\n\n\n\nLet’s see how amplitude damping affects a simple superposition state. Consider the initial state \\[\n\\ket{\\psi} = \\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1}),\n\\] which has density matrix \\[\n\\rho = \\frac{1}{2}\\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}.\n\\]\nAfter applying amplitude damping with probability \\(\\gamma\\), the state becomes \\[\n\\begin{aligned}\n\\rho' &= E_1 \\rho E_1^\\dagger + E_0 \\rho E_0^\\dagger \\\\\n&= \\frac{1}{2}\\begin{bmatrix} 1+\\gamma & \\sqrt{1-\\gamma} \\\\ \\sqrt{1-\\gamma} & 1-\\gamma \\end{bmatrix}.\n\\end{aligned}\n\\]\nWe can see that:\n\nThe probability of being in \\(\\ket{1}\\) decreases by \\(\\gamma\\)\nThe probability of being in \\(\\ket{0}\\) increases by \\(\\gamma\\)\nThe off-diagonal coherence terms decay by \\(\\sqrt{1-\\gamma}\\)\n\nWhen \\(\\gamma = 1\\) (complete damping), the state becomes \\[\n\\rho' = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix} = \\ket{0}\\bra{0},\n\\] representing complete relaxation to the ground state.\n\n\n\n\nErasure Channel\nAnother important quantum channel is the erasure channel, which models the loss of a qubit to other accessible states. Unlike amplitude damping, where information leaks gradually, the erasure channel represents a complete loss of the qubit with probability \\(\\epsilon\\). When this happens, the qubit is replaced by an “error state” that we denote as \\(\\ket{e}\\). Importantly, \\(\\ket{e}\\) exists in a different part of the Hilbert space than our qubit states - it’s an additional state that flags that erasure has occurred.\n\n\n\n\n\n\nOrthogonality of Error State\n\n\n\nThe error state \\(\\ket{e}\\) is orthogonal to both \\(\\ket{0}\\) and \\(\\ket{1}\\), meaning \\(\\braket{e|0} = \\braket{e|1} = 0\\). This is crucial as it represents a state completely outside our original qubit space but still within the system itself.\n\n\nThe erasure can then be represented by \\[\n\\rho \\mapsto (1 - \\epsilon)\\rho + \\epsilon \\ket{e}\\bra{e}.\n\\]\nIn particular, this process\n\nPreserves the state with probability \\(1-\\epsilon\\)\nErases it completely with probability \\(\\epsilon\\), replacing it with the error state \\(\\ket{e}\\)\n\n\n\n\n\n\n\nExample: Erasure Channel in Action\n\n\n\nSince the erasure channel operates in an enlarged Hilbert space that includes the error state (in this case, making it 3-dimensional), let’s consider our superposition state embedded in this expanded space: \\[\n\\ket{\\psi} = \\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1}) = \\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1}) = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix}.\n\\] After the erasure channel acts, the state becomes a mixed state: \\[\n\\rho' = (1-\\epsilon)\\begin{bmatrix}\n1/2 & 1/2 & 0 \\\\\n1/2 & 1/2 & 0 \\\\\n0 & 0 & 0\n\\end{bmatrix} + \\epsilon\\begin{bmatrix}\n0 & 0 & 0 \\\\\n0 & 0 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n= \\begin{bmatrix}\n\\frac{1-\\epsilon}{2} & \\frac{1-\\epsilon}{2} & 0 \\\\\n\\frac{1-\\epsilon}{2} & \\frac{1-\\epsilon}{2} & 0 \\\\\n0 & 0 & \\epsilon\n\\end{bmatrix}\n\\] This represents that with probability \\(1-\\epsilon\\) we still have our original state in the upper-left \\(2\\times2\\) block, but with probability \\(\\epsilon\\) we have completely lost it to the error state, represented by the 1 in the bottom-right corner.\n\n\nThe erasure channel is particularly important in quantum communication and error correction because the error state exists within the system Hilbert space itself (not the environment). This additional state in the system allows us to track and flag when errors occur–making it especially useful for quantum error correction protocols, unlike other noise channels where the errors are unknown and harder to detect.\n\n\n\n2.4.3 Physical Qubit Implementations\nThe quest for building practical quantum computers has led to several different approaches for implementing qubits. Each implementation aims to create a physical system that can reliably represent quantum states and allow for precise control and manipulation. We will explore in detail later what is needed for a good quantum device, but give a brief overview here of what the devices are.\n\nSuperconducting Qubits\n\nQubit are energy levels of charge or flux within a superconducting circuit.\nBased on superconducting circuits using Josephson junctions.\nOperate at extremely low temperatures (~20 mK).\nUsed by: IBM, Google, Rigetti.\n\n\n\nTrapped Ion Qubits\n\nQubits are electronic or nuclear states of individual ions\nIons held in electromagnetic traps, manipulated by lasers\nUsed by: IonQ, Honeywell-Quantinuum\n\n\n\nPhotonic Qubits\n\nQubits are properites of light (e.g., polarization)\nCan operate at room temperature\nUsed by: PsiQuantum, Xanadu\n\n\n\nSemiconductor Quantum Dots\n\nQubits can be encoded using either:\n\ncharge states (electron occupying different quantum dots)\nspin states (up/down spin states of an electron)\n\nCreated by confining electrons in semiconductor nanostructures\nOften called “artificial atoms” due to their discrete energy levels\nActive research at: Intel, TU Delft, Princeton, UNSW, CEA-Leti\n\n\n\nNV Centers in Diamond\n\nThe nitrogen vacancy defects in diamond provide energy levels accessible with light.\nCan operate at room temperature\nApplications in quantum sensing and networking\n\n\n\nTopological Qubits\n\nQubits are non-local and topologically protected states within an exotic (topological) state of matter.\nMost promising candidate: Majorana zero modes\nCurrent Status:\n\nActive research at Microsoft and Delft\nRecent progress in identifying Majorana signatures in nanowires\nDebate continues over experimental evidence\n\n\nAs we’ll discuss, the “perfect” qubit would combine long coherence times, fast gates, high fidelity, easy coupling to other qubits, and straightforward scalability. While each implementation has made significant progress, achieving all these properties simultaneously remains a major challenge in the field.\n\n\n\n\n[1] W. K. Wootters and W. H. Zurek, A single quantum cannot be cloned, Nature 299, 802 (1982).\n\n\n[2] S. Bravyi and A. Kitaev, Universal quantum computation with ideal Clifford gates and noisy ancillas, Physical Review A 71, 022316 (2005).\n\n\n[3] M. M. Wilde, Quantum Information Theory, 2nd ed (Cambridge university press, Cambridge, 2017).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Qubit</span>"
    ]
  },
  {
    "objectID": "qubit.html#footnotes",
    "href": "qubit.html#footnotes",
    "title": "2  The Qubit",
    "section": "",
    "text": "Magic is a technical term in quantum computing, though we’re using it in a colloquial sense here, see  [2].↩︎\nIn some literature, these are matrices are denoted by \\(\\sigma_{x}\\), \\(\\sigma_y\\), and \\(\\sigma_z\\) and related to spin operators via \\(S_i =\\frac12 \\sigma_i\\). This insight can help bridge the idea of these operators and the Bloch sphere.↩︎\nThe divide-by-two for the angles will become clear as we go through this section.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Qubit</span>"
    ]
  },
  {
    "objectID": "multiple_qubits.html",
    "href": "multiple_qubits.html",
    "title": "3  Multiple Qubits",
    "section": "",
    "text": "3.1 Tensor Products and the multi-qubit Hilbert space\nPreviously in Chapter 2 we discussed in detail how to understand a single qubit. While we saw some basic features, such as superposition and relative phase, it has not been apparent yet what we can do with these features. The power of these will really be unlocked by putting multiple qubits together. We will also begin to see hints of quantum entanglement.\nHowever, there is just a practical concern: How much information can we store in a single qubit? With precise control, we have our answer in Section 2.2: the angles \\(\\theta\\) and \\(\\phi\\) on the Bloch sphere. Since algorithms are bit more greedy than that, we need to extend our space and the natural way to do that is to add more qubits. Of course, classically, we operate with many bits: Floats (real numbers) on most computers use 64 bits, and we often add, substract, multiply a lot of these numbers. But classically, when we have, for instance, two bits, there are four discrete states 00, 01, 10, and 11. As we will analyze in detail, quantum mechanically these will be four basis states that can make up a general quantum wave function \\[\n\\ket{\\psi} = \\alpha \\ket{00} + \\beta \\ket{01} + \\gamma \\ket{10} + \\delta \\ket{11}.\n\\tag{3.1}\\]\nThe equation above gives us an idea for how we ought to combine qubits. The tensor product will formalize this, but we will build it up “intuitively.”\nImagine we have one big operator called “read-out” or \\(\\mathcal R\\); this operator will measure all of the qubits in the system, and its value will tell us exactly what the state of the system is in terms of the computational basis.\nHowever, this operator \\(\\mathcal R\\) must be Hermitian to be a physical observable, and as a result its eigenstates span our Hilbert space. Well, upon readout, we know that each qubit can be in one of two states \\(b_i = 0\\) or \\(1\\), and if we have \\(i = 1, \\ldots, N\\) qubits, there are \\(2^N\\) possibilities.\nWe will return to this, but let us linger on two qubits. Notice that we can obtain the above states with an operation called the tensor product.\nThis multiplication table is how we go from basis sets of single qubits to the basis set of two qubits. Very often, we will drop the \\(\\otimes\\) and simply write \\[\n\\ket{b_1 b_2} \\equiv \\ket{b_1} \\otimes \\ket{b_2}.\n\\]\nSimilarly, we can build up three qubit states by taking the tensor product of two-qubit states with a single qubit:\nagain we can define \\[\n\\ket{b_1 b_2 b_3} = \\ket{b_1 b_2} \\otimes \\ket{b_3},\n\\] and we proceed once more\nAs we can see, every time we add a new qubit, the dimension of the space is multiplied by two. In general, we can can break \\(N\\)-qubits in the computational basis as \\[\n\\ket{b_1 b_2 \\cdots b_N} = \\ket{b_1} \\otimes \\ket{b_2} \\otimes \\cdots \\otimes \\ket{b_N}\n\\] where \\(b_j = 0\\) or \\(1\\). Since this is a basis, we can “count” the number of basis states to determine the dimension of the space to obtain for the Hilbert space of \\(N\\)-qubits \\(\\mathcal H_N\\), \\[\n\\dim \\mathcal H_N = 2^N.\n\\] Therefore, a general quantum state of \\(N\\) qubits can be written as a superposition of all possible computational basis states: \\[\n\\ket{\\psi} = \\sum_{b_1,\\ldots,b_N = 0,1} \\psi_{b_1\\cdots b_N} \\ket{b_1\\cdots b_N}\n\\] where \\(\\psi_{b_1\\cdots b_N}\\) are complex coefficients satisfying the normalization condition \\[\n\\sum_{b_1,\\ldots,b_N = 0,1} |\\psi_{b_1\\cdots b_N}|^2 = 1.\n\\] This means that to fully specify a quantum state of \\(N\\) qubits, we need \\(2^N\\) complex numbers (subject to normalization), which illustrates both the power and challenge of quantum computing - the exponential growth in the state space allows for massive parallel processing but also makes classical simulation difficult.\nThe exponential growth in the state space has important implications for simulating quantum systems on classical computers. While we need \\(2^N\\) complex numbers to specify an arbitrary quantum state, the situation becomes even more demanding when we consider operations on these states:\nThis exponential scaling is why classical computers struggle to simulate large quantum systems - the memory and computational requirements become overwhelming. For example:\nHowever, it’s important to note that not all quantum computations require storing and manipulating the full state space. Many practical quantum algorithms and simulations exploit special properties:\nNevertheless, the ability to access and manipulate this exponentially large state space can help us perform computations that classical computers would struggle with.\nBefore we run head first into entanglement, let’s take a minute to just do some counting to see that we are going to run into some trouble. For a single qubit, we have two complex numbers \\(\\ket{\\psi} = \\alpha\\ket0 + \\beta \\ket1\\), but we need to normalize them \\(|\\alpha|^2 + |\\beta|^2=1\\) and remove a phase. Thus, we have reduced our 2 complex numbers (= 4 real numbers) down to 4-1-1=2 real numbers. This is made explicit with the Bloch sphere where two real numbers \\((\\theta,\\phi)\\) completely characterize the state. Therefore, do we only need \\(2\\times 2=4\\) real numbers to describe a 4 qubit state? Well, let’s count, we can see from Eq. 3.1 that we have 4 complex numbers (= 8 real numbers). But we must also impose normalization and remove an overall phase, reducing us down to 8-1-1 = 6 real numbers. But \\(6&gt;4\\); this is our first hint of something happening in our quantum system, we need more numbers to describe all of the states in a two qubit system than simply what we needed for two separate qubits.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multiple Qubits</span>"
    ]
  },
  {
    "objectID": "multiple_qubits.html#tensor-products-and-the-multi-qubit-hilbert-space",
    "href": "multiple_qubits.html#tensor-products-and-the-multi-qubit-hilbert-space",
    "title": "3  Multiple Qubits",
    "section": "",
    "text": "Two-Qubit Readout\n\n\n\nThe readout operator \\(\\mathcal{R}\\) maps the two-qubit basis states to unique numbers:\n\n\\(\\mathcal{R}\\ket{00} = 0 \\ket{00}\\)\n\\(\\mathcal{R}\\ket{01} = 1 \\ket{01}\\)\n\\(\\mathcal{R}\\ket{10} = 2 \\ket{10}\\)\n\\(\\mathcal{R}\\ket{11} = 3 \\ket{11}\\)\n\nThis binary-to-decimal conversion helps us uniquely identify each computational basis state.\n\n\n\n\n\n\n\n\\(\\otimes\\)\n\\(\\ket{0}\\)\n\\(\\ket{1}\\)\n\n\n\n\n\\(\\ket{0}\\)\n\\(\\ket{0} \\otimes \\ket{0}\\)\n\\(\\ket{0} \\otimes \\ket{1}\\)\n\n\n\\(\\ket{1}\\)\n\\(\\ket{1}\\otimes \\ket{0}\\)\n\\(\\ket{1}\\otimes \\ket{0}\\)\n\n\n\n\n\n\n\n\n\\(\\otimes\\)\n\\(\\ket{0}\\)\n\\(\\ket{1}\\)\n\n\n\n\n\\(\\ket{00}\\)\n\\(\\ket{00} \\otimes \\ket{0}\\)\n\\(\\ket{00} \\otimes \\ket{1}\\)\n\n\n\\(\\ket{01}\\)\n\\(\\ket{01} \\otimes \\ket{0}\\)\n\\(\\ket{01} \\otimes \\ket{1}\\)\n\n\n\\(\\ket{10}\\)\n\\(\\ket{10} \\otimes \\ket{0}\\)\n\\(\\ket{10} \\otimes \\ket{1}\\)\n\n\n\\(\\ket{11}\\)\n\\(\\ket{11} \\otimes \\ket{0}\\)\n\\(\\ket{11} \\otimes \\ket{1}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\otimes\\)\n\\(\\ket{0}\\)\n\\(\\ket{1}\\)\n\n\n\n\n\\(\\ket{000}\\)\n\\(\\ket{000} \\otimes \\ket{0}\\)\n\\(\\ket{000} \\otimes \\ket{1}\\)\n\n\n\\(\\ket{001}\\)\n\\(\\ket{001} \\otimes \\ket{0}\\)\n\\(\\ket{001} \\otimes \\ket{1}\\)\n\n\n\\(\\ket{010}\\)\n\\(\\ket{010} \\otimes \\ket{0}\\)\n\\(\\ket{010} \\otimes \\ket{1}\\)\n\n\n\\(\\ket{011}\\)\n\\(\\ket{011} \\otimes \\ket{0}\\)\n\\(\\ket{011} \\otimes \\ket{1}\\)\n\n\n\\(\\ket{100}\\)\n\\(\\ket{100} \\otimes \\ket{0}\\)\n\\(\\ket{100} \\otimes \\ket{1}\\)\n\n\n\\(\\ket{101}\\)\n\\(\\ket{101} \\otimes \\ket{0}\\)\n\\(\\ket{101} \\otimes \\ket{1}\\)\n\n\n\\(\\ket{110}\\)\n\\(\\ket{110} \\otimes \\ket{0}\\)\n\\(\\ket{110} \\otimes \\ket{1}\\)\n\n\n\\(\\ket{111}\\)\n\\(\\ket{111} \\otimes \\ket{0}\\)\n\\(\\ket{111} \\otimes \\ket{1}\\)\n\n\n\n\n\n\n\n\n\n\nTwo-qubit wave functions and entanglement\n\n\n\nA general two-qubit wave function can be written as \\[\n\\ket{\\psi} = \\psi_{00}\\ket{00} + \\psi_{01}\\ket{01} + \\psi_{10}\\ket{10} + \\psi_{11}\\ket{11}\n\\] where \\(|\\psi_{00}|^2 + |\\psi_{01}|^2 + |\\psi_{10}|^2 + |\\psi_{11}|^2 = 1\\). When the two qubits are independent (a product state), we can write this as a tensor product of individual qubit states: \\[\n\\begin{aligned}\n\\ket{\\psi} & = (\\alpha_1\\ket{0} + \\beta_1\\ket{1}) \\otimes (\\alpha_2\\ket{0} + \\beta_2\\ket{1}) \\\\ & = \\alpha_1\\alpha_2\\ket{00} + \\alpha_1\\beta_2\\ket{01} + \\beta_1\\alpha_2\\ket{10} + \\beta_1\\beta_2\\ket{11}\n\\end{aligned}\n\\]\nHowever, not all two-qubit states can be written as such a product! States that cannot be factored into a tensor product of individual qubit states are called entangled states - a crucial quantum resource we’ll explore later.\n\n\n\n\nTo represent an arbitrary quantum operation (unitary evolution) on \\(N\\) qubits, we need a \\(2^N \\times 2^N\\) unitary matrix. This requires storing and manipulating \\(2^{2N}\\) complex numbers.\nEven to compute the probability of a measurement outcome, we need to perform operations involving all \\(2^N\\) amplitudes.\n\n\n\n10 qubits: \\(2^{10} = 1,024\\) amplitudes, \\(2^{20} \\approx 1\\) million matrix elements\n30 qubits: \\(2^{30} \\approx 1\\) billion amplitudes, \\(2^{60} \\approx 10^{18}\\) matrix elements\n50 qubits: \\(2^{50} \\approx 10^{15}\\) amplitudes, \\(2^{100} \\approx 10^{30}\\) matrix elements\n\n\n\nSome quantum states have special structure (like product states) that allow more efficient representations\nMany quantum operations act locally or have special symmetries that reduce the computational complexity\nSome quantum algorithms can be simulated using specialized techniques that avoid storing the full state vector\n\n\n\n\n\n\n\n\nClassical simulation vs. quantum measurement\n\n\n\nWhen simulating quantum systems on classical computers, we have direct access to the full state vector - all the complex amplitudes \\(\\psi_{b_1\\cdots b_N}\\). This gives us complete information about the quantum state, allowing us to calculate any property without performing repeated measurements.\nIn contrast, real quantum computers are bound by the measurement postulates of quantum mechanics (Postulate II, Section 1.3.2). Each measurement:\n\nCollapses the quantum state\nOnly returns eigenvalues of the measured observable\nMust be repeated many times to estimate expectation values and state properties\n\nThis limitation of quantum hardware is why techniques like quantum state tomography are necessary - reconstructing the full quantum state requires performing many different measurements on multiple copies of the same state. Classical simulation sidesteps this fundamental quantum constraint, though at the cost of exponential classical resources.\n\n\n\n\n\n\n\n\nExample: Building up three-qubit states\n\n\n\nConsider how we build up the state \\(\\ket{101}\\):\n\nStart with first two qubits: \\(\\ket{10}\\)\nTensor with third qubit: \\(\\ket{10} \\otimes \\ket{1}\\)\nThis gives: \\(\\ket{101}\\)\n\nWe can verify this matches our counting:\n\nFirst qubit: \\(\\ket{1}\\) (second basis state)\nSecond qubit: \\(\\ket{0}\\) (first basis state)\nThird qubit: \\(\\ket{1}\\) (second basis state)\n\nTherefore in binary: 101, which is state number 5 in our computational basis (counting from 0).\n\n\n\n\n\n\n\n\n\nMathematical Note: State Space Geometry\n\n\n\nFor the mathematically inclined: The physical state space of an N-qubit system is complex projective space \\(\\mathbb{CP}^{2^N-1}\\). For two qubits, this means \\(\\mathbb{CP}^3\\), which is fundamentally different from \\(\\mathbb{CP}^1 \\times \\mathbb{CP}^1\\) (the space of two separate qubits). This geometric fact underlies why we need more parameters to describe entangled states - the state space has a richer structure than just the product of individual qubit spaces.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multiple Qubits</span>"
    ]
  },
  {
    "objectID": "multiple_qubits.html#entanglement",
    "href": "multiple_qubits.html#entanglement",
    "title": "3  Multiple Qubits",
    "section": "3.2 Entanglement",
    "text": "3.2 Entanglement\nEntanglement is one of the most important phenomena in quantum mechanics without a clear classical antecedent. The term was first coined by Schrödinger in 1935  [1] in response to a famous paper by Einstein, Podolsky, and Rosen (EPR)  [2]. It represents quantum correlations between particles that cannot be explained by a simple “lack of knowledge” by the observer. To get around this, it was thought there must be “hidden variables” to make quantum mechanics complete; thus, EPR used these quantum correlations to argue that quantum mechanics must be incomplete. Quantum mechanics appeared to allow “spooky action at a distance” that violated their ideas of locality and reality.\nHowever, in 1964, John Stewart Bell  [3] showed that quantum mechanics predicts correlations between entangled particles that are mathematically impossible to explain with any local hidden variable theory. Subsequent experiments have repeatedly confirmed these “Bell inequality violations,” demonstrating that entanglement represents a fundamentally new kind of physical relationship not reducible to classical correlations (early experiments include  [4] and  [5]).\nThe existence of entanglement suggests that the quantum wave function represents more than just our knowledge about measurement probabilities - it appears to be a real physical object. More recent work by Matthew Pusey, Jonathan Barrett, and Terry Rudolph  [6] has strengthened this view through their “PBR theorem,” which shows that if quantum predictions are correct, then quantum states must be physically real rather than merely statistical.\n\n\n\n\n\n\nReality of the Wave Function\n\n\n\nThe PBR theorem (2012)  [6] tells us something deep about quantum mechanics. To quote the paper,\n\nIn conclusion, we have presented a no-go theorem, which—modulo assumptions—shows that models in which the quantum state is interpreted as mere information about an objective physical state of a system cannot reproduce the predictions of quantum theory. The result is in the same spirit as Bell’s theorem, which states that no local theory can reproduce the predictions of quantum theory.\n\nThis provides strong support for viewing entanglement as a genuine physical phenomenon rather than just a limitation of our knowledge.\n\n\nLet’s explore what entanglement means mathematically and physically.\n\n3.2.1 Bell States and Non-local Correlations\nOne of the simplest cases of quantum entanglement is the Bell state \\[\n|\\Phi^+\\rangle = \\frac{|00\\rangle + |11\\rangle}{\\sqrt{2}}\n\\tag{3.2}\\]\nThis state exhibits perfect correlations that persist regardless of the physical separation between the qubits. When we measure the first qubit:\n\nIf we get \\(|0\\rangle\\), the state collapses to \\(|00\\rangle\\)\nIf we get \\(|1\\rangle\\), the state collapses to \\(|11\\rangle\\)\n\nThe remarkable feature is that measuring either qubit instantly determines the state of the other qubit, even if they are separated by vast distances. For example:\n\nCreate \\(|\\Phi^+\\rangle\\) and separate the qubits by sending one to Earth and one to Mars\nMeasure the Earth qubit → get result 0 or 1 with 50% probability\nWe know with 100% certainty that the Mars qubit will be measured to give the same result.\nThis happens faster than light could travel between the qubits.\n\n\n\n\n\n\n\nNo faster-than-light communication\n\n\n\nWhile entanglement appears to create “spooky action at a distance,” it cannot be used to transmit information faster than light. This is because:\n\nThe measurement results are random\nThe person with the second qubit needs classical information about the first measurement to interpret their results\nThis classical information is still limited by the speed of light\n\n\n\n\n\n\n\n\n\nBell state properties are basis independence\n\n\n\nA remarkable property of the Bell state \\(|\\Phi^+\\rangle\\) is that these perfect correlations persist no matter what basis we measure in. If we measure the first qubit in any basis and get some state \\(|\\psi\\rangle\\), the second qubit will always be found in state \\(|\\psi\\rangle\\) when measured in the same basis.\nFor example, if we measure the first qubit in the \\(X\\) basis: - If we get \\(|+\\rangle\\), the state collapses to \\(|{+}{+}\\rangle\\) - If we get \\(|-\\rangle\\), the state collapses to \\(|{-}{-}\\rangle\\)\nThis is because we can rewrite \\(|\\Phi^+\\rangle\\) in any basis and it maintains the same form: \\[\n|\\Phi^+\\rangle = \\frac{|00\\rangle + |11\\rangle}{\\sqrt{2}} = \\frac{|{+}{+}\\rangle + |{-}{-}\\rangle}{\\sqrt{2}}\n\\]\nThis is true for any basis, not just \\(Z\\) and \\(X\\).\n\n\nThese non-local correlations are fundamentally different from classical correlations, but how can we see that? The key ends up being: measurements that show quantum correlations and was Bell’s central insight  [3]. Instead of just looking at measurements of \\(Z\\) which are easily explained by a classical hidden variable, also perform measurements at other angles of the Bloch sphere.\n\n\n\n\n\n\nMermin’s Example\n\n\n\nTo see a simple example, read  [7]. The essence of the idea presented there is to measure three different observables with the Bell state in Eq. 3.2, \\[\nZ, \\quad -\\frac12 Z + \\frac{\\sqrt3}{2}X, \\quad -\\frac12 Z - \\frac{\\sqrt{3}}{2}X,\n\\] with the results from these three measurements, there is no way to use classical probabilities of measurement outcomes to account for the distribution of results.\n\n\n\n\n\n3.2.2 Mathematical definition and separability\nA multi-qubit quantum state is entangled if and only if it cannot be written as a tensor product of individual qubit states1. For a two-qubit pure state \\(|\\psi\\rangle\\), this means there do not exist single-qubit states \\(|\\phi_1\\rangle\\) and \\(|\\phi_2\\rangle\\) such that:\n\\[\n|\\psi\\rangle = |\\phi_1\\rangle \\otimes |\\phi_2\\rangle\n\\]\nFor a general two-qubit state \\(|\\psi\\rangle = \\alpha|00\\rangle + \\beta|01\\rangle + \\gamma|10\\rangle + \\delta|11\\rangle\\), there is a simple condition for separability: the state is separable if and only if the determinant of its coefficient matrix is zero:\n\\[\n\\begin{vmatrix}\n\\alpha & \\beta \\\\\n\\gamma & \\delta\n\\end{vmatrix} = \\alpha\\delta - \\beta\\gamma = 0\n\\]\nThis can be proven by writing out the general form of a tensor product and matching coefficients. The classic examples of maximally entangled states are the Bell states:\n\\[\n|\\Phi^+\\rangle = \\frac{|00\\rangle + |11\\rangle}{\\sqrt{2}} \\qquad |\\Phi^-\\rangle = \\frac{|00\\rangle - |11\\rangle}{\\sqrt{2}}\n\\] \\[\n|\\Psi^+\\rangle = \\frac{|01\\rangle + |10\\rangle}{\\sqrt{2}} \\qquad |\\Psi^-\\rangle = \\frac{|01\\rangle - |10\\rangle}{\\sqrt{2}}\n\\]\nFor mixed states, the situation is more complex and requires measures like concurrence to fully characterize entanglement.\n\n\n\n\n\n\nExample: Separable state condition\n\n\n\nConsider a separable two-qubit state formed by the tensor product of two arbitrary single-qubit states:\n\\[\n|\\phi_1\\rangle = a|0\\rangle + b|1\\rangle \\qquad |\\phi_2\\rangle = c|0\\rangle + d|1\\rangle\n\\]\nTheir tensor product gives:\n\\[\n\\begin{aligned}\n|\\phi_1\\rangle \\otimes |\\phi_2\\rangle &= (a|0\\rangle + b|1\\rangle) \\otimes (c|0\\rangle + d|1\\rangle) \\\\\n&= ac|00\\rangle + ad|01\\rangle + bc|10\\rangle + bd|11\\rangle\n\\end{aligned}\n\\]\nThe coefficient matrix determinant is: \\[\n\\begin{vmatrix}\nac & ad \\\\\nbc & bd\n\\end{vmatrix} = (ac)(bd) - (ad)(bc) = abcd - abcd = 0\n\\]\nThis confirms that any separable state satisfies the zero determinant condition. Conversely, if a state’s coefficient matrix has non-zero determinant, it must be entangled.\n\n\n\n\n\n\n\n\nExample: Checking for Entanglement\n\n\n\nLet’s examine two states to see if they’re entangled:\n\nConsider the state \\(|\\psi_1\\rangle = \\frac{1}{\\sqrt{2}}(|00\\rangle + |11\\rangle)\\) The coefficient matrix is: \\[\n\\begin{pmatrix}\n1/\\sqrt{2} & 0 \\\\\n0 & 1/\\sqrt{2}\n\\end{pmatrix}\n\\] The determinant is \\((1/\\sqrt{2})(1/\\sqrt{2}) - (0)(0) = 1/2 \\neq 0\\), so this state is entangled.\nConsider the state \\(|\\psi_2\\rangle = \\frac{1}{\\sqrt{2}}(|00\\rangle + |01\\rangle)\\) The coefficient matrix is: \\[\n\\begin{pmatrix}\n1/\\sqrt{2} & 1/\\sqrt{2} \\\\\n0 & 0\n\\end{pmatrix}\n\\] The determinant is \\((1/\\sqrt{2})(0) - (1/\\sqrt{2})(0) = 0\\), so this state is separable. Indeed, we can write it as \\(|\\psi_2\\rangle = |0\\rangle \\otimes \\frac{1}{\\sqrt{2}}(|0\\rangle + |1\\rangle)\\).\nConsider the state \\(|\\psi_3\\rangle = \\frac{1}{2}(|00\\rangle + |01\\rangle + |10\\rangle + |11\\rangle)\\) The coefficient matrix is: \\[\n\\begin{pmatrix}\n1/2 & 1/2 \\\\\n1/2 & 1/2\n\\end{pmatrix}\n\\] The determinant is \\((1/2)(1/2) - (1/2)(1/2) = 0\\), so this state is separable. We can verify this by rewriting it as: \\(|\\psi_3\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle + |1\\rangle) \\otimes \\frac{1}{\\sqrt{2}}(|0\\rangle + |1\\rangle)\\)\n\n\n\n\n\n3.2.3 Reduced density matrices\nFor entangled states, we often want to describe the state of a single qubit within the two-qubit system. This is done using the reduced density matrix, obtained by “tracing out” the other qubit. The process, called the partial trace, gives us a density matrix that describes all measurable properties of the subsystem we’re interested in.\nFor a two-qubit system in state \\(|\\psi\\rangle\\), the density matrix is \\(\\rho = |\\psi\\rangle\\langle\\psi|\\). To get the reduced density matrix for the first qubit (\\(\\rho_A\\)), we take the partial trace over the second qubit (B):\n\\[\n\\rho_A = \\text{Tr}_B(\\rho) = \\sum_{b=0}^1 \\langle b_B|\\rho|b_B\\rangle\n\\]\nFor a single term \\(\\langle b_B|\\rho|b_B\\rangle\\), this gives a \\(2\\times2\\) matrix acting on the first qubit:\n\\[\n\\begin{aligned}\n\\langle b_B|\\rho|b_B\\rangle & = \\begin{pmatrix}\n\\langle 0 b|\\rho|0 b\\rangle & \\langle 0 b|\\rho|1 b\\rangle \\\\\n\\langle 1 b|\\rho|0 b\\rangle & \\langle 1 b|\\rho|1 b\\rangle\n\\end{pmatrix} \\\\\n& = \\begin{pmatrix}\n|\\braket{0 b | \\psi}|^2 & \\braket{0 b |\\psi} \\braket{1b| \\psi}^* \\\\\n\\braket{1b|\\psi}\\braket{0b|\\psi}^* & |\\braket{1b|\\psi}|^2\n\\end{pmatrix}\n\\end{aligned}\n\\]\nwhere \\(|b_B\\rangle\\) are the basis states of qubit B. Each element of \\(\\rho_A\\) is a sum of two elements from the original density matrix, corresponding to tracing out qubit B in the computational basis.\n\n\n\n\n\n\nTensor notation for density matrices\n\n\n\nIn tensor notation, a two-qubit state \\(|\\psi\\rangle\\) has components \\(\\psi_{ij}\\) where \\(i,j\\) label the basis states of the first and second qubit. The density matrix elements are then \\(\\rho_{ij,kl} = \\psi_{ij}\\psi_{kl}^*\\), where the first pair of indices \\((i,j)\\) corresponds to the ket and \\((k,l)\\) to the bra.\nThe partial trace over qubit B corresponds to summing over matching indices for qubit B:\n\\[\n(\\rho_A)_{ik} = \\sum_j \\rho_{ij,kj}\n\\] This tensor notation makes it clear why this operation is called a “trace” - we’re summing over diagonal elements where the indices for system B match (j=j), just like in the usual matrix trace, while keeping the indices for system A (i,k) free.\n\n\n\n\n\n\n\n\nExample: Reduced density matrix of a Bell state\n\n\n\nConsider the Bell state \\(|\\Phi^+\\rangle = \\frac{|00\\rangle + |11\\rangle}{\\sqrt{2}}\\). Its density matrix is:\n\\[\n\\rho = |\\Phi^+\\rangle\\langle\\Phi^+| = \\frac{1}{2}(|00\\rangle\\langle00| + |00\\rangle\\langle11| + |11\\rangle\\langle00| + |11\\rangle\\langle11|)\n\\]\nLet’s find \\(\\rho_A\\) step by step:\n\nFirst, we compute the partial trace: \\[\n\\begin{aligned}\n\\rho_A &= \\langle0_B|\\rho|0_B\\rangle + \\langle1_B|\\rho|1_B\\rangle \\\\\n&= \\frac{1}{2}|0\\rangle\\langle0| + \\frac{1}{2}|1\\rangle\\langle1| \\\\\n&= \\frac{1}{2}I\n\\end{aligned}\n\\]\nThis shows that when we look at just one qubit of a maximally entangled pair:\n\nIt appears to be in a completely mixed state\nWe have equal probability of measuring 0 or 1\nAll quantum information is stored in the correlations between qubits\n\n\n\n\nThe reduced density matrix reveals a key feature of entanglement: while the total state is pure (\\(\\rho^2 = \\rho\\)), the subsystem state can be mixed (\\(\\rho_A^2 \\neq \\rho_A\\)). This is a signature of entanglement - if we can only access one qubit of an entangled pair, we see a statistical mixture rather than a pure state.\n\n\n\n\n\n\nExample: Partial Trace for a General Two-Qubit State\n\n\n\nSuppose we have a general two-qubit pure state: \\[\n|\\psi\\rangle = \\alpha|00\\rangle + \\beta|01\\rangle + \\gamma|10\\rangle + \\delta|11\\rangle.\n\\] The full density matrix is: \\[\n\\rho = |\\psi\\rangle \\langle \\psi|\n= \\begin{pmatrix}\n\\alpha \\\\ \\beta \\\\ \\gamma \\\\ \\delta\n\\end{pmatrix}\n\\begin{pmatrix}\n\\alpha^* & \\beta^* & \\gamma^* & \\delta^*\n\\end{pmatrix}.\n\\]\nTo find the reduced density matrix of the first qubit, \\(\\rho_A = \\mathrm{Tr}_B(\\rho)\\), group the basis states so that qubit B’s index is traced out:\n\\[\n\\rho_A =\n\\begin{pmatrix}\n|\\alpha|^2 + |\\beta|^2 & \\alpha\\gamma^*+\\beta\\delta^* \\\\\n\\gamma\\alpha^* + \\delta\\beta^* & |\\gamma|^2 + |\\delta|^2\n\\end{pmatrix}.\n\\]\nThis \\(2\\times2\\) matrix captures all local measurements and observables on qubit A, regardless of the state of qubit B.\n\n\n\n\n\n\n\n\nWhy Care About Reduced Density Matrices?\n\n\n\nReduced density matrices are crucial because they tell us what we can observe when we only have access to part of an entangled system. They help answer questions like:\n\nLocal Measurements: What results will we get if we only measure one qubit of an entangled pair?\nQuantum Information: How much information is accessible locally vs. stored in correlations?\nDecoherence: How does interaction with the environment affect our quantum system?\n\nFor example, in quantum teleportation, while the total state remains pure, the reduced density matrix of the transmitted qubit appears completely mixed until the classical information is received. This explains why teleportation cannot transmit information faster than light!\n\n\n\n\n3.2.4 Quantifying entanglement\nSeveral measures exist to quantify entanglement, each capturing different aspects:\n\nVon Neumann entropy: For a pure bipartite state \\(|\\psi\\rangle\\), the entanglement entropy is \\(S(\\rho_A) = -\\text{Tr}(\\rho_A \\log_2 \\rho_A)\\) where \\(\\rho_A\\) is the reduced density matrix of subsystem A. For two qubits, this ranges from 0 for separable states to 1 for maximally entangled states.\nConcurrence  [9]: For a two-qubit state \\(\\rho\\), defined as \\(C(\\rho) = \\max(0, \\lambda_1 - \\lambda_2 - \\lambda_3 - \\lambda_4)\\) where \\(\\lambda_i\\) are the square roots of eigenvalues of \\(\\rho(Y \\otimes Y)\\rho^*(Y \\otimes Y)\\) in decreasing order (this reduces to \\(2|\\alpha\\delta - \\beta\\gamma|\\) for a pure state \\(|\\psi\\rangle = \\alpha|00\\rangle + \\beta|01\\rangle + \\gamma|10\\rangle + \\delta|11\\rangle\\)).\nNegativity: Based on the partial transpose of the density matrix, providing a computable measure that captures the degree of entanglement. However, while negativity is zero for separable states, a zero negativity does not guarantee separability for some higher-dimensional systems - there exist entangled states with zero negativity.\n\nThese measures help quantify the “quantum-ness” of correlations and their potential utility in quantum information protocols. All of these are discussed in detail in  [8].\nWe will find that many protocols of usefulness will produce entanglement in the system, though often only when in a particular basis. We will see that in the next section when we introduce operators on this Hilbert space\n\n\n\n\n\n\nEntanglement depends on the partition\n\n\n\nWhen we talk about entanglement between subsystems A and B, it’s crucial to understand that this depends entirely on how we choose to divide our total system into these subsystems. The same quantum state can appear entangled or unentangled depending on this choice of partition.\nFor example, consider the state: \\[\n|\\psi\\rangle = \\frac{1}{\\sqrt{2}}(|00\\rangle + |11\\rangle),\n\\]\nthis is clearly an entangled Bell state, but our Hilbert space exists as (complex) four-dimensional space. I could “relabel” my states into a new basis (which we can define with a tilde), such that \\[\n\\begin{aligned}\n\\ket{00} & = \\frac1{\\sqrt{2}}( \\ket{\\tilde 0 \\tilde 0} + \\ket{\\tilde 1 \\tilde 1}), \\\\\n\\ket{11} & = \\frac1{\\sqrt{2}}( \\ket{\\tilde 0 \\tilde 0} - \\ket{\\tilde 1 \\tilde 1}), \\\\\n\\ket{01} & = \\frac1{\\sqrt{2}}( \\ket{\\tilde 0 \\tilde 1} + \\ket{\\tilde 1 \\tilde 0}), \\\\\n\\ket{10} & = \\frac1{\\sqrt{2}}( \\ket{\\tilde 0 \\tilde 1} - \\ket{\\tilde 1 \\tilde 0}), \\\\\n\\end{aligned}\n\\] and if we do that, we see that\n\\[\n\\ket\\psi = \\ket{\\tilde 0 \\tilde 0},\n\\]\na completely disentangled state! This is not to say that \\(\\ket{\\psi}\\) is not entangled, it is. It is merely important to remember that entanglement is defined with respect to a certain partitioning of your Hilbert space. The space represented by \\(\\tilde 0\\) and \\(\\tilde 1\\) is a complex combination of 00, 01, 10, and 11.\nIt is usually the physical situation which dictates how we partition our system (systems that are physically isolated from each other or for which we have single degrees of freedom which admit simple tensor products when considered with other systems).\n\n\n\n\n\n\n\n\nWhen to Use Different Entanglement Measures\n\n\n\nEach entanglement measure has its strengths:\n\nVon Neumann Entropy\n\nBest for: Pure bipartite states\nAdvantages: Clear physical interpretation, easy to calculate\nUse when: You want to quantify how much quantum information is shared between subsystems\n\nConcurrence\n\nBest for: Two-qubit mixed states\nAdvantages: Can be directly calculated from density matrix\nUse when: Working with noisy or mixed two-qubit states\n\nNegativity\n\nBest for: Higher-dimensional systems\nAdvantages: Easy to compute, works for mixed states\nUse when: Dealing with larger systems or when you need a quick estimate of entanglement\n\n\nExample: For the Bell state \\(\\ket{\\Phi^+} = \\frac{1}{\\sqrt{2}}(\\ket{00} + \\ket{11})\\):\n\nVon Neumann Entropy = 1 (maximally entangled)\nConcurrence = 1 (maximally entangled)\nNegativity = 0.5 (maximum value for two qubits)\n\n\n\n\n\n\n\n\n\nThree qubits can be entangled in two inequivalent ways\n\n\n\nThree-qubit entanglement introduces fundamentally new features not present in two-qubit systems  [10]. The most famous example is the GHZ state (named after Greenberger, Horne, and Zeilinger  [11]):\n\\[\n|\\text{GHZ}\\rangle = \\frac{1}{\\sqrt{2}}(|000\\rangle + |111\\rangle)\n\\]\nUnlike two-qubit entanglement, which has only one type of maximal entanglement (equivalent to Bell states), three-qubit systems can exhibit qualitatively different kinds of entanglement. The GHZ state above has the special property that measuring any one qubit immediately determines the state of the other two, but if you lose (trace out) any one qubit, the remaining two qubits are completely unentangled. This is fundamentally different from another type of three-qubit entanglement called the W state:\n\\[\n|W\\rangle = \\frac{1}{\\sqrt{3}}(|001\\rangle + |010\\rangle + |100\\rangle)\n\\]\nwhich maintains some two-qubit entanglement even after losing one qubit. These distinct classes of entanglement cannot be converted into each other using local operations and classical communication (LOCC).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multiple Qubits</span>"
    ]
  },
  {
    "objectID": "multiple_qubits.html#multi-qubit-operations",
    "href": "multiple_qubits.html#multi-qubit-operations",
    "title": "3  Multiple Qubits",
    "section": "3.3 Multi-qubit operations",
    "text": "3.3 Multi-qubit operations\nWith our exponentially big state space created and entanglement characterized, we can begin to think about how to translate our single qubit operations to multiple qubits and then how to build up operations that use multiple qubits. We will focus on two qubit gates since these will help us build up a set of universal gates for quantum computation.\n\n3.3.1 Single-qubit gates\nWhen we want to apply a single-qubit gate to one qubit in a multi-qubit system, we need to use tensor products to construct the appropriate operator. For a two-qubit system, if we want to apply a gate \\(U\\) to the first qubit, the full operator is:\n\\[\nU \\otimes I\n\\]\nwhere \\(I\\) is the \\(2\\times 2\\) identity matrix. Similarly, to apply \\(U\\) to the second qubit, we use:\n\\[\nI \\otimes U\n\\]\nFor example, applying the Pauli-X gate to the first qubit of a two-qubit system gives:\n\\[\nX \\otimes I = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} \\otimes \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\end{pmatrix}\n\\]\nwhere the rows and columns correspond to the basis states in order \\(|00\\rangle\\), \\(|01\\rangle\\), \\(|10\\rangle\\), \\(|11\\rangle\\). For example, the 1 in the third row, first column means \\(X \\otimes I\\) transforms \\(|00\\rangle\\) to \\(|10\\rangle\\), which flips the first qubit as expected.\nSimilarly, applying it to the second qubit gives:\n\\[\nI \\otimes X = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\otimes \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 & 0 & 0 \\\\ 1 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0 \\end{pmatrix}\n\\]\nHere, the 1 in the second row, first column shows \\(I \\otimes X\\) transforms \\(|00\\rangle\\) to \\(|01\\rangle\\), flipping only the second qubit as expected.\nThis pattern extends to more qubits. For an \\(N\\)-qubit system, to apply \\(U\\) to the \\(k\\)th qubit, we use:\n\\[\n\\underbrace{I \\otimes \\cdots \\otimes I}_{k-1} \\otimes U \\otimes \\underbrace{I \\otimes \\cdots \\otimes I}_{N-k}\n\\]\nwhere \\(U\\) appears in the \\(k\\)th position and \\(I\\) appears in all other positions. This construction ensures we affect only the target qubit while leaving all other qubits unchanged.\n\n\n\n\n\n\nExample: H gate on second qubit of three-qubit system\n\n\n\nLet’s see how applying \\(H\\) to the second qubit of a three-qubit system works. The operator is:\n\\[\nI \\otimes H \\otimes I\n\\]\nActing on the state \\(|000\\rangle\\):\n\\[\n\\begin{aligned}\n(I \\otimes H \\otimes I)|000\\rangle &= (I \\otimes H \\otimes I)(|0\\rangle \\otimes |0\\rangle \\otimes |0\\rangle) \\\\\n&= (I|0\\rangle) \\otimes (H|0\\rangle) \\otimes (I|0\\rangle) \\\\\n&= |0\\rangle \\otimes \\frac{|0\\rangle + |1\\rangle}{\\sqrt{2}} \\otimes |0\\rangle \\\\\n&= \\frac{|000\\rangle + |010\\rangle}{\\sqrt{2}}\n\\end{aligned}\n\\]\nAs expected, only the middle qubit is put into an equal superposition of 0 and 1.\n\n\n\n\n\n\n\n\nNotational convenience for single-qubit operations\n\n\n\nTo avoid writing long chains of tensor products, we often use a subscript to indicate which qubit an operator acts on. For example, instead of writing\n\\[\nI \\otimes X \\otimes I \\otimes I \\otimes X\n\\]\nfor a five-qubit system where we apply \\(X\\) to qubits 2 and 5, we can write this more compactly as\n\\[\nX_2 X_5\n\\]\nSimilarly, applying the Hadamard gate to the third qubit of a four-qubit system would be written as\n\\[\nH_3\n\\]\nrather than \\(I \\otimes I \\otimes H \\otimes I\\). This notation is particularly helpful when describing quantum circuits involving many qubits.\n\n\n\n\n3.3.2 Two-qubit gates\nTo begin to build up a full set of logical gates, we start with “controlled” gates. These are gates that will act as single qubit gates on one qubit (the target), but only if another qubit (the control) is in the \\(\\ket{1}\\) state.\nWe first introduce the two-qubit gate called the controlled-NOT (CNOT) gate, which flips the second qubit (target) when the first qubit (control) is in state \\(|1\\rangle\\)2.\nThe CNOT gate can be written as a \\(4 \\times 4\\) matrix acting on the two-qubit basis states \\(|00\\rangle\\), \\(|01\\rangle\\), \\(|10\\rangle\\), and \\(|11\\rangle\\):\n\\[\n\\text{CNOT} = \\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n0 & 0 & 1 & 0\n\\end{pmatrix}\n\\]\nWe can understand this matrix by seeing how it acts on each basis state:\n\\[\n\\begin{aligned}\n\\text{CNOT}|00\\rangle &= |00\\rangle \\\\\n\\text{CNOT}|01\\rangle &= |01\\rangle \\\\\n\\text{CNOT}|10\\rangle &= |11\\rangle \\\\\n\\text{CNOT}|11\\rangle &= |10\\rangle\n\\end{aligned}\n\\]\nWhen the first (control) qubit is \\(|0\\rangle\\), the target qubit is unchanged. When the control qubit is \\(|1\\rangle\\), the target qubit is flipped (X gate applied). This has a circuit representation which we show below in Fig. 3.1.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) CNOT gate with control in \\(|0\\rangle\\)\n\n\n\n\n\n\n\n\n\n\n\n(b) CNOT gate with control in \\(|1\\rangle\\)\n\n\n\n\n\n\n\nFig. 3.1: The CNOT gate behavior depends on the control qubit state. When the control is \\(|0\\rangle\\) (left), the target is unchanged. When the control is \\(|1\\rangle\\) (right), the target is flipped.\n\n\n\nThe CNOT gate’s action on computational basis states appears simple - it either leaves them unchanged (when control is |0⟩) or flips the target (when control is |1⟩). However, when applied to superposition states, the CNOT can create entanglement.\nFor example, consider applying CNOT to a superposition state created by applying a Hadamard gate to the first qubit (circuit diagram in Fig. 3.2).\n\n\n\n\n\n\n\nFig. 3.2: The application of \\(H\\) followed by a CNOT gate can create the Bell state \\(\\frac1{\\sqrt2}(\\ket{00}+\\ket{11})\\).\n\n\n\nWe can verify this mathematically: \\[\n\\begin{aligned}\n|00\\rangle &\\xrightarrow{H \\otimes I} \\frac{|0\\rangle + |1\\rangle}{\\sqrt{2}} \\otimes |0\\rangle = \\frac{|00\\rangle + |10\\rangle}{\\sqrt{2}} \\\\\n&\\xrightarrow{\\text{CNOT}} \\frac{|00\\rangle + |11\\rangle}{\\sqrt{2}}\n\\end{aligned}\n\\]\nThe resulting state is the Bell state \\(|\\Phi^+\\rangle\\) which we saw earlier - a maximally entangled state that cannot be written as a product of individual qubit states.\nThe CNOT gate is just one example of a controlled operation. More generally, we can create controlled versions of any single-qubit gate, where the target operation is applied only when the control qubit is \\(\\ket{1}\\). The most common controlled gates are:\n\nControlled-X (CNOT): Flips the target qubit if control is \\(\\ket{1}\\), Fig. 3.3 (a)\nControlled-Z (CZ): Adds -1 phase if both qubits are \\(\\ket{1}\\), Fig. 3.3 (c)\nControlled-Y (CY): Applies Y rotation if control is \\(\\ket{1}\\), Fig. 3.3 (b)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) CX\n\n\n\n\n\n\n\n\n\n\n\n(b) CY\n\n\n\n\n\n\n\n\n\n\n\n(c) CZ\n\n\n\n\n\n\n\nFig. 3.3: Circuit Notation for controlled-X (CX), controlled-Y (CY), and controlled-Z (CZ) gates. Note that CX=CNOT, so this is just an alternative circuit notation.\n\n\n\nAny controlled gate can be constructed using CNOT gates and single-qubit operations. For example, the CZ gate can be implemented as:\n\n\n\n\n\n\n\nFig. 3.4: The CZ gate can be decomposed into two Hadamards sandwiching a CNOT (CX) gate.\n\n\n\nThis notation is flexible as well, we can begin to apply any unitary matrix \\(U\\) onto a target qubit and have a control qubit for it. This generically will look like\n\n\n\n\n\n\n\nFig. 3.5: An arbitrary controlled gate\n\n\n\nMathematically, we can write this out in a four-by-four matrix \\[\n\\text{CU} = \\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & U_{11} & U_{12} \\\\\n0 & 0 & U_{21} & U_{22}\n\\end{pmatrix}\n\\]\nwhere \\(U_{ij}\\) are the matrix elements of the single-qubit unitary \\(U = \\begin{pmatrix} U_{11} & U_{12} \\\\ U_{21} & U_{22} \\end{pmatrix}\\).\nAnother important two-qubit gate is the SWAP gate, which exchanges the states of two qubits. The SWAP gate can be written as a four-by-four matrix:\n\\[\n\\text{SWAP} = \\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n\\]\nUnlike controlled gates, the SWAP gate cannot create entanglement - it simply swaps the quantum states between the qubits. The circuit notation for a SWAP gate is:\n\n\n\n\n\n\n\nFig. 3.6: SWAP gate circuit notation\n\n\n\nWe’ve seen how this can already create entanglement even though one qubit is merely acting as “control,” and how we can “SWAP” two qubits. However, we can also write down more general four-by-four matrices on two qubits and if we have a generic four-by-four matrix \\(U_4\\), we will write that circuit element as\n\n\n\n\n\n\n\nFig. 3.7: A generic unitary on two qubits can be represented by a block spanning the two qubits\n\n\n\nThese two-qubit gates form the foundation for quantum computation with multiple qubits. The controlled operations, particularly the CNOT gate, are essential building blocks for quantum algorithms, while general two-qubit unitaries give us the full power to manipulate quantum states in ways impossible with just single-qubit operations. Understanding how these gates create and manipulate entanglement is crucial.\n\n\n\n\n\n\nExample: Creating different entangled states\n\n\n\nLet’s see how different combinations of gates create distinct entangled states:\n\nBell state \\(\\ket{\\Phi^+}\\):\n|0⟩ --H--•--|\n         |\n|0⟩ -----X--|\n\\(\\ket{00} \\xrightarrow{H \\otimes I} \\frac{\\ket{00} + \\ket{10}}{\\sqrt{2}} \\xrightarrow{CNOT} \\frac{\\ket{00} + \\ket{11}}{\\sqrt{2}}\\)\nBell state \\(\\ket{\\Psi^+}\\):\n|0⟩ --H--•--|\n         |\n|0⟩ --X--X--|\n\\(\\ket{00} \\xrightarrow{I \\otimes X} \\ket{01} \\xrightarrow{H \\otimes I} \\frac{\\ket{01} + \\ket{11}}{\\sqrt{2}} \\xrightarrow{CNOT} \\frac{\\ket{01} + \\ket{10}}{\\sqrt{2}}\\)\n\nThis shows how different gate sequences can create different types of entanglement. Note: We have used the fixed-width font notation for circuit diagrams here.\n\n\n\n3.3.2.1 Universal gate sets\nJust as classical computation can be performed using a small set of universal gates (like NAND or NOR), quantum computation can be achieved using a finite set of quantum gates that can approximate any unitary operation to arbitrary precision. This is known as a universal gate set.\nA common universal gate set consists of:\n\nThe CNOT gate\nSingle-qubit rotations (or equivalently, any set of gates that can approximate any single-qubit rotation)\n\nRemarkably, these are sufficient to construct any unitary operation on any number of qubits, though the construction may require many gates. This is analogous to how NAND gates can be used to build any classical logic circuit.\nThere are several alternative universal gate sets. Some common ones include:\n\nCZ (or CY) + single-qubit rotations\nCNOT + Hadamard + Phase (S) gate + T gate\nToffoli + Hadamard\n\nThe choice of which universal gate set to use often depends on the physical implementation of the quantum computer. For example, some quantum computing architectures might naturally implement CZ gates rather than CNOT gates, making the CZ-based universal set more practical.\nIt’s worth noting that while we can approximate any unitary to arbitrary precision with these gate sets, the number of gates required might grow exponentially with the desired precision. This is known as the Solovay-Kitaev theorem, which provides an algorithm for finding such approximations.\n\n\n\n\n\n\nExample: Creating a GHZ State\n\n\n\nA three-qubit GHZ state is \\[\n| \\text{GHZ} \\rangle = \\frac{|000\\rangle + |111\\rangle}{\\sqrt{2}}.\n\\]\nWe can create this state using the following sequence of gates:\n\nStart from \\(|000\\rangle\\)\nApply a Hadamard gate to the first qubit: \\[\n|000\\rangle \\xrightarrow{H \\otimes I \\otimes I} \\frac{|000\\rangle + |100\\rangle}{\\sqrt{2}}\n\\]\nApply two consecutive CNOTs, using the first qubit as the control: \\[\n\\begin{aligned}\n&\\frac{|000\\rangle + |100\\rangle}{\\sqrt{2}}\n\\xrightarrow{\\text{CNOT on qubits 1→2}}\n\\frac{|000\\rangle + |110\\rangle}{\\sqrt{2}} \\\\\n&\\quad \\xrightarrow{\\text{CNOT on qubits 1→3}}\n\\frac{|000\\rangle + |111\\rangle}{\\sqrt{2}}\n\\end{aligned}\n\\]\n\nMeasuring any qubit in the computational basis will instantly project the entire system into either \\(|000\\rangle\\) or \\(|111\\rangle\\), illustrating the strong correlations present in multipartite entanglement.\n\n\n\n\n\n3.3.3 Measurement\nWhen measuring multiple qubits, we need to extend our understanding of single-qubit measurements. For a single qubit, measuring in the computational basis was straightforward - we would get either \\(\\ket{0}\\) or \\(\\ket{1}\\). However, in a multi-qubit system, measuring just one qubit introduces an important concept: partial measurements and degeneracy.\nConsider measuring the first qubit of a two-qubit state in the computational basis. The measurement operators are:\n\\[\nP_0 = |0\\rangle\\langle 0| \\otimes I = \\begin{pmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\end{pmatrix}\n\\]\n\\[\nP_1 = |1\\rangle\\langle 1| \\otimes I = \\begin{pmatrix} 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{pmatrix}\n\\]\nThese operators are degenerate - for example, \\(P_0\\) projects onto both \\(|00\\rangle\\) and \\(|01\\rangle\\) states. This means when we measure the first qubit and get 0, the second qubit remains in a quantum state.\n\n\n\n\n\n\nExample: Partial Measurement\n\n\n\nConsider the state: \\[\n|\\psi\\rangle = \\frac{1}{2}(|00\\rangle + |01\\rangle + |10\\rangle + |11\\rangle)\n\\]\nIf we measure the first qubit and get 0, the state collapses to: \\[\n|\\psi'\\rangle = \\frac{1}{\\sqrt{2}}(|00\\rangle + |01\\rangle)\n\\]\nThe second qubit remains in a superposition!\n\n\nWhen measuring multiple qubits, we need to be careful about how we calculate probabilities. For a single qubit, the probability of measuring \\(\\ket{0}\\) was simply \\(\\lvert\\braket{0|\\psi}\\rvert^2\\). However, with multiple qubits, we need to sum over all possible configurations of the unmeasured qubits.\nFor example, if we have a two-qubit state \\(|\\psi\\rangle\\) and measure only the first qubit, the probability of getting 0 is:\n\\[\np(0) = \\sum_i |\\langle 0i|\\psi\\rangle|^2\n\\]\nwhere \\(i\\) runs over all possible states of the second qubit (0 and 1). This sum accounts for all ways we could get outcome 0 on the first qubit, regardless of what state the second qubit is in.\n\n\n\n\n\n\nExample: Calculating Measurement Probabilities\n\n\n\nConsider again the state: \\[\n|\\psi\\rangle = \\frac{1}{2}(|00\\rangle + |01\\rangle + |10\\rangle + |11\\rangle)\n\\]\nThe probability of measuring 0 on the first qubit is: \\[\n\\begin{aligned}\np(0) &= |\\langle 00|\\psi\\rangle|^2 + |\\langle 01|\\psi\\rangle|^2 \\\\\n&= \\left|\\frac{1}{2}\\right|^2 + \\left|\\frac{1}{2}\\right|^2 \\\\\n&= \\frac{1}{2}\n\\end{aligned}\n\\]\nThis matches our intuition - the first qubit is equally likely to be 0 or 1.\n\n\n\n3.3.3.1 Measuring General Observables\nIn practice, we may be restricted in what we can measure on a quantum computer, such as only in the computational (\\(Z\\)) basis. However, we often need to measure other observables. For example, we might want to measure the parity of two qubits (\\(Z_1Z_2\\)) or their correlation (\\(X_1X_2\\)).\nTo measure these observables, we need to transform our state before measurement. This is done by applying appropriate unitary operations that map our desired measurement basis to the computational basis.\nFor example, as we saw in the single qubit section, to measure in the X basis, we first apply \\(H\\) before measuring in the computational basis.\nFor two-qubit observables like \\(Z_1 Z_2\\), we can use controlled operations to map the eigenspaces to computational basis states. Here’s how we might measure \\(Z_1 Z_2\\).\nFirst, let’s write out how \\(Z_1 Z_2\\) acts on the computational basis, separting out the +1 eigenvalues from the -1 eigenvalues\n\n\n\nState\n\\(Z_1Z_2\\)\n\\(Z_2\\)\n\n\n\n\n\\(\\ket{00}\\)\n\\(+1\\)\n\\(+1\\)\n\n\n\\(\\ket{01}\\)\n\\(-1\\)\n\\(-1\\)\n\n\n\\(\\ket{10}\\)\n\\(-1\\)\n\\(+1\\)\n\n\n\\(\\ket{11}\\)\n\\(+1\\)\n\\(-1\\)\n\n\n\nNotice that these operators have the same number of +1 and -1 eigenvalues. On top of that, the states \\(\\ket{00}\\) and \\(\\ket{01}\\) have the same eigenvalue, and \\(\\ket{10}\\) and \\(\\ket{11}\\) flips. This sounds like a CNOT gate, in fact if we have a unitary that takes \\(\\ket{10} \\mapsto \\ket{11}\\) and \\(\\ket{11} \\mapsto \\ket{10}\\), while leaving \\(\\ket{00}\\) and \\(\\ket{01}\\) alone, these operators match.\nLet’s build out a way to relate these operators which we will then use to measure any string Pauli matrices. With the above, we note that \\[\n\\begin{aligned}\n\\ket{00} & \\mapsto \\ket{00},\\\\\n\\ket{01} & \\mapsto \\ket{01}, \\\\\n\\ket{10} & \\mapsto \\ket{11}, \\\\\n\\ket{11} & \\mapsto \\ket{10}\n\\end{aligned}\n\\] will let us map \\(Z_1 Z_2 \\mapsto Z_2\\). This has a simple matrix form \\[\n\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n0 & 0 & 1 & 0\n\\end{pmatrix}.\n\\] In other words, the CNOT gate. Formally, this means that \\[\n\\text{CNOT}\\, Z_1 Z_2\\, \\text{CNOT} = Z_2,\n\\tag{3.3}\\] which can be verified with matrix mulitplation. However, we can also note that if we apply \\(\\ket{b_1 b_2}\\) to both sides, \\[\nZ_1 Z_2 \\text{CNOT} \\ket{b_1 b_2} = \\mathrm{CNOT} (-1)^{b_2} \\ket{b_1 b_2} = (-1)^{b_2} \\mathrm{CNOT} \\ket{b_1 b_2},\n\\] which verifies that \\(\\mathrm{CNOT}\\ket{b_1 b_2}\\) is an eigenvector of \\(Z_1 Z_2\\) with eigenvalue \\((-1)^{b_2}\\) (this assume Eq. 3.3 is correct).\nTherefore, to measure \\(Z_1 Z_2\\), we perform CNOT, then measure the target qubit (number two). The circuit diagram looks like this\n\n\n\n\n\n\n\nFig. 3.8: Circuit to measure \\(Z_1Z_2\\)\n\n\n\nand if we want to not only measure \\(Z_1 Z_2\\) but ensure the system goes into an eigenstate of \\(Z_1 Z_2\\), we need to perform CNOT again\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Circuit to measure \\(Z_1Z_2\\) with a single symbol\n\n\n\n\n\n\n\n\n\n\n\n(b) Circuit to measure \\(Z_1Z_2\\) with explicit gates\n\n\n\n\n\n\n\nFig. 3.9: Circuit diagrams for the \\(Z_1 Z_2\\) measurement. These two circuits are equivalent to each other.\n\n\n\nBut what about measuring other Pauli strings? We can use the fact that \\(X = H Z H\\) and \\(Y = S X S^\\dagger\\) to convert any Pauli string measurement into a \\(Z\\)-type measurement. For example, to measure \\(X_1 X_2\\), we can apply Hadamard gates to both qubits, measure \\(Z_1 Z_2\\), and then apply Hadamard gates again:\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Circuit to measure \\(X_1X_2\\) with a single symbol\n\n\n\n\n\n\n\n\n\n\n\n(b) Circuit to measure \\(X_1X_2\\) with explicit gates\n\n\n\n\n\n\n\nFig. 3.10: Circuit diagrams for the \\(X_1 X_2\\) measurement. These two circuits are equivalent to each other.\n\n\n\nThis gives us a way to measure any Pauli string\n\nPerform single-particle unitaries to convert it to only \\(Z\\) and \\(I\\) operators.\nFind the permutation matrix that relates +1 and -1 eigenvalues of your \\(Z\\)-Pauli string to a single \\(Z_n\\) and apply that unitary matrix (this could be a complicated combination of CNOT gates)\nMeasure \\(Z_n\\).\nIf the correct measured state is needed, undo the unitary in #2 followed by the single-particle unitaries in #1.\n\nPauli strings are particularly “simple.” Measuring more complicated observables requires more thought and sometimes ancillary systems to assist in that measurement.\n\n\n\n\n\n\nExample: Measuring X on One Qubit of a Two-Qubit System\n\n\n\nSuppose we have a two-qubit state: \\[\n|\\phi\\rangle = \\alpha|00\\rangle + \\beta|01\\rangle + \\gamma|10\\rangle + \\delta|11\\rangle,\n\\] and we want to measure the first qubit in the \\(X\\) basis while leaving the second qubit unmeasured.\n\nRecall \\(H X H = Z\\). So to measure \\(X\\) on the first qubit, apply a Hadamard on that qubit to map the \\(X\\) basis to the \\(Z\\) basis: \\[\n(H \\otimes I)|\\phi\\rangle.\n\\]\nMeasure the first qubit in the computational basis (effectively measuring \\(Z\\) on the transformed state).\nAfter the measurement, unapply the \\(H\\) if you want to restore the original basis of the first qubit.\n\nThis procedure effectively measures \\(X_1\\) while leaving qubit 2 untouched (can it still be entangled?).\n\n\n\n\n\n\n\n\nExample: Creating entanglement through measurement\n\n\n\nLet’s see how we can create entanglement through measurement. We’ll start with the product state \\(|{+}{+}\\rangle\\) and use a \\(Z_1Z_2\\) measurement to create a maximally entangled state.\n\nInitial state: \\[\n|{+}{+}\\rangle = \\frac{1}{2}(|00\\rangle + |01\\rangle + |10\\rangle + |11\\rangle)\n\\]\nMeasuring \\(Z_1Z_2\\) projects onto the +1 or -1 eigenspaces:\n\n+1 eigenspace: span{\\(|00\\rangle\\), \\(|11\\rangle\\)}\n-1 eigenspace: span{\\(|01\\rangle\\), \\(|10\\rangle\\)}\n\nAfter measurement:\n\nIf outcome = +1: \\[\n|\\Phi^+\\rangle = \\frac{|00\\rangle + |11\\rangle}{\\sqrt{2}}\n\\]\nIf outcome = -1: \\[\n|\\Psi^+\\rangle = \\frac{|01\\rangle + |10\\rangle}{\\sqrt{2}}\n\\]\n\nIf we get -1, we can apply \\(X\\) to the second qubit to transform to \\(|\\Psi^{+}\\rangle\\): \\[\n(I \\otimes X)\\frac{|01\\rangle + |10\\rangle}{\\sqrt{2}} = \\frac{|00\\rangle + |11\\rangle}{\\sqrt{2}}\n\\]\n\nThis procedure creates the Bell state \\(|\\Phi^+\\rangle\\) regardless of measurement outcome, demonstrating how measurement plus conditional corrections can generate entanglement from separable states.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multiple Qubits</span>"
    ]
  },
  {
    "objectID": "multiple_qubits.html#decoherence-in-multi-qubit-systems",
    "href": "multiple_qubits.html#decoherence-in-multi-qubit-systems",
    "title": "3  Multiple Qubits",
    "section": "3.4 Decoherence in multi-qubit systems",
    "text": "3.4 Decoherence in multi-qubit systems\nWhen dealing with multiple qubits, decoherence becomes even more challenging than in single-qubit systems. Not only can each qubit experience individual decoherence, but the interactions between qubits can create new pathways for errors. The main types of multi-qubit decoherence are:\n\nIndependent decoherence: Each qubit experiences its own local noise\nCorrelated decoherence: Environmental effects that simultaneously affect multiple qubits\nCross-talk: Unwanted interactions between qubits that should be isolated\n\nFor example, consider a two-qubit state that starts in a Bell state: \\[\n|\\Phi^+\\rangle = \\frac{1}{\\sqrt{2}}(|00\\rangle + |11\\rangle)\n\\] The density matrix for this pure state is: \\[\n|\\Phi^+\\rangle\\langle\\Phi^+| = \\frac{1}{2}\\begin{pmatrix}\n1 & 0 & 0 & 1 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n1 & 0 & 0 & 1\n\\end{pmatrix}\n\\]\nUnder independent dephasing, each qubit loses phase coherence separately: \\[\n\\rho(t) = \\frac{1}{2}\\begin{pmatrix}\n1 & 0 & 0 & e^{-2\\gamma t} \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\ne^{-2\\gamma t} & 0 & 0 & 1\n\\end{pmatrix}\n\\]\nwhich would represent exponential decay in entanglement over time; this could occur even with pure local noise. This highlights a crucial feature of quantum systems: even when noise acts independently on each qubit (i.e., local noise), it can destroy global quantum properties like entanglement. In other words, we don’t need correlated noise to degrade entanglement - local noise channels are sufficient to compromise the quantum advantages that entanglement provides.\n\n\n\n\n\n\nExample: Impact of different noise types\n\n\n\nConsider a Bell state under different noise channels:\n\nAmplitude damping on first qubit only: \\[\n\\rho(t) = \\begin{pmatrix}\n1-\\frac{e^{-\\gamma t}}{2} & 0 & 0 & \\frac{e^{-\\gamma t/2}}{\\sqrt{2}} \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n\\frac{e^{-\\gamma t/2}}{\\sqrt{2}} & 0 & 0 & \\frac{e^{-\\gamma t}}{2}\n\\end{pmatrix}\n\\]\nDephasing on both qubits: \\[\n\\rho(t) = \\frac{1}{2}\\begin{pmatrix}\n1 & 0 & 0 & e^{-2\\gamma t} \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\ne^{-2\\gamma t} & 0 & 0 & 1\n\\end{pmatrix}\n\\]\n\nThis shows how different noise channels affect the quantum correlations in distinct ways.\n\n\n\n3.4.1 Gate Errors\nIn addition to decoherence during idle times, errors can occur during gate operations. These gate errors come in several forms:\n\nSystematic errors: Consistent over/under-rotation of gates\nRandom errors: Fluctuations in gate parameters\nCross-talk errors: Gates affecting neighboring qubits\nLeakage errors: System leaving the computational basis\n\nFor two-qubit gates like CNOT, errors are typically higher than single-qubit gates because:\n\nThey require stronger interactions between qubits\nTake longer to implement\nAre more sensitive to timing and control errors (e.g.,some qubits have to wait while single-qubit operations “catch up”).\n\n\n\n\n\n\n\nCurrent State of Gate Fidelities\n\n\n\nAs of 2021, record error rates are:\n\nSingle-qubit gates: 0.03%\nTwo-qubit gates: 0.5%\nMeasurement: 0.2%\n\nThese numbers are representative of state-of-the-art superconducting qubit platforms, as reported in  [12].\n\n\n\n\n\n\n[1] E. Schrödinger, Discussion of Probability Relations between Separated Systems, Mathematical Proceedings of the Cambridge Philosophical Society 31, 555 (1935).\n\n\n[2] A. Einstein, B. Podolsky, and N. Rosen, Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?, Physical Review 47, 777 (1935).\n\n\n[3] J. S. Bell, On the Einstein Podolsky Rosen paradox, Physics Physique Fizika 1, 195 (1964).\n\n\n[4] S. J. Freedman and J. F. Clauser, Experimental Test of Local Hidden-Variable Theories, Physical Review Letters 28, 938 (1972).\n\n\n[5] A. Aspect, J. Dalibard, and G. Roger, Experimental Test of Bell’s Inequalities Using Time- Varying Analyzers, Physical Review Letters 49, 1804 (1982).\n\n\n[6] M. F. Pusey, J. Barrett, and T. Rudolph, On the reality of the quantum state, Nature Physics 8, 475 (2012).\n\n\n[7] N. D. Mermin, Bringing home the atomic world: Quantum mysteries for anybody, American Journal of Physics 49, 940 (1981).\n\n\n[8] R. Horodecki, M. Horodecki, and K. Horodecki, Quantum entanglement, Reviews of Modern Physics 81, 865 (2009).\n\n\n[9] W. Wootters, Entanglement of formation and concurrence, Quantum Information and Computation 1, 27 (2001).\n\n\n[10] W. Dür, G. Vidal, and J. I. Cirac, Three qubits can be entangled in two inequivalent ways, Physical Review A 62, 62314 (2000).\n\n\n[11] D. M. Greenberger, M. A. Horne, A. Shimony, and A. Zeilinger, Bell’s theorem without inequalities, American Journal of Physics 58, 1131 (1990).\n\n\n[12] N. P. De Leon, K. M. Itoh, D. Kim, K. K. Mehta, T. E. Northup, H. Paik, B. S. Palmer, N. Samarth, S. Sangtawesin, and D. W. Steuerman, Materials challenges and opportunities for quantum computing hardware, Science 372, eabb2823 (2021).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multiple Qubits</span>"
    ]
  },
  {
    "objectID": "multiple_qubits.html#footnotes",
    "href": "multiple_qubits.html#footnotes",
    "title": "3  Multiple Qubits",
    "section": "",
    "text": "This is true for pure states, but can be easily generalized to mixed states, see  [8].↩︎\nThis is also known as the CX-gate (the controlled-\\(X\\) gate).↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Multiple Qubits</span>"
    ]
  },
  {
    "objectID": "basic_algorithms.html",
    "href": "basic_algorithms.html",
    "title": "4  Quantum Computing Algorithms",
    "section": "",
    "text": "4.1 Deutsch’s Algorithm\nWe now have a solid foundation in the building blocks of quantum computing. We understand how individual qubits work - their quantum states, how they evolve under unitary operations, and how we measure them. We’ve also explored how multiple qubits interact and become entangled, creating quantum correlations that have no classical analog.\nWith these fundamental tools in hand, we can now explore what makes quantum computing truly powerful - the algorithms that harness quantum mechanics to solve problems more efficiently than classical computers. These algorithms cleverly combine quantum superposition, interference, and entanglement to achieve computational speedups that would be impossible using classical bits alone.\nThe key insight is that quantum algorithms can process multiple computational paths simultaneously through superposition, while entanglement allows us to correlate these paths in useful ways. When we finally measure the system, quantum interference helps guide us toward the solution we seek. In the following sections, we’ll examine several landmark quantum algorithms that demonstrate these principles and show how quantum computers can tackle important practical problems.\nDeutsch’s algorithm, published in 1985  [1], represents the first quantum algorithm to demonstrate a speedup over classical computation. While the problem it solves is quite simple, it beautifully illustrates the key principles of quantum computation: superposition, interference, and parallelism.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quantum Computing Algorithms</span>"
    ]
  },
  {
    "objectID": "basic_algorithms.html#deutschs-algorithm",
    "href": "basic_algorithms.html#deutschs-algorithm",
    "title": "4  Quantum Computing Algorithms",
    "section": "",
    "text": "4.1.1 The Problem Statement\nConsider a black box (oracle) function \\(f: \\{0,1\\} \\rightarrow \\{0,1\\}\\) that takes a single bit as input and returns a single bit as output. There are only four possible such functions:\n\n\\(f_1(x) = 0\\) for all \\(x\\) (constant function)\n\\(f_2(x) = 1\\) for all \\(x\\) (constant function)\n\\(f_3(x) = x\\) (balanced function)\n\\(f_4(x) = \\text{NOT}(x)\\) (balanced function)\n\nThe task is to determine whether \\(f\\) is constant (same output for all inputs) or balanced (equal number of 0s and 1s in output). Classically, this requires evaluating \\(f(0)\\) and \\(f(1)\\) - two function calls. Deutsch’s algorithm solves this problem with a single quantum query.\n\n\n\n\n\n\nWhat is an Oracle?\n\n\n\nAn oracle is a black box function that implements a specific operation without revealing its internal workings. In quantum computing, an oracle is typically provided as a unitary transformation that can be queried but whose implementation details are hidden. Oracles are crucial in algorithm analysis because they let us:\n\nFocus on the number of queries needed rather than implementation details\nProve lower bounds on algorithmic complexity\nCompare classical and quantum approaches on an equal footing\n\nFor example, in Deutsch’s algorithm, we don’t care how \\(f(x)\\) is computed internally - we just care that we can access it as a quantum operation \\(U_f\\) that preserves quantum superposition.\n\n\n\n\n4.1.2 Quantum Implementation\n\n\n\n\n\n\nThe Power of Hadamard Gates\n\n\n\nThe Hadamard transform is crucial in this algorithm because:\n\nInitial H-gates create a superposition of all possible bit strings: \\[H^{\\otimes n}\\ket{0}^{\\otimes n} = \\frac{1}{\\sqrt{2^n}}\\sum_{x\\in\\{0,1\\}^n}\\ket{x}\\]\nFinal H-gates convert phase differences into bit values:\n\nIf a bit in s is 0: H maps \\(\\ket{0} \\rightarrow \\ket{0}\\)\nIf a bit in s is 1: H maps \\(-\\ket{0} \\rightarrow \\ket{1}\\)\n\n\nThis is why measuring after the final Hadamard gates directly reveals the hidden string s!\n\n\nThe quantum circuit requires two qubits:\n\nAn input qubit initialized to \\(\\ket{0}\\)\nAn auxiliary qubit initialized to \\(\\ket{1}\\)\n\n\n\n\n\nCircuit for Deutsch algorithm\n\n\nThe algorithm proceeds as follows:\n\nApply Hadamard gates to both qubits: \\[\\ket{0}\\ket{1} \\xrightarrow{H \\otimes H} \\frac{1}{\\sqrt{2}}(\\ket{0}+\\ket{1})\\otimes\\frac{1}{\\sqrt{2}}(\\ket{0}-\\ket{1})\\]\nApply the quantum oracle \\(U_f\\), which implements: \\[\\ket{x}\\ket{y} \\rightarrow \\ket{x}\\ket{y \\oplus f(x)}\\] where \\(\\oplus\\) denotes addition modulo 2.\nApply another Hadamard gate to the first qubit.\nMeasure the first qubit.\n\nThe interference in Deutsch’s algorithm occurs in the final Hadamard transformation. To see this explicitly, let’s track how the phases accumulate:\n\n\n\n\n\n\nPhase Kickback\n\n\n\nPhase kickback is a phenomenon in quantum computing where the phase shift caused by an operation on one qubit (often called the target qubit) is “kicked back” onto another qubit (often called the control qubit). This happens particularly in controlled operations when the target qubit is in an eigenstate of the operation.\nIn Deutsch’s algorithm, we have four possibilities in the code basis\n\n\\(\\ket{0}\\ket{y} \\mapsto \\ket{0}\\ket{y+0}\\) and \\(\\ket{1}\\ket{y}\\mapsto\\ket{1}\\ket{y+0}\\). In this case, nothing changes and \\[\n\\ket{+}\\ket{-} \\mapsto \\ket{+}\\ket{-}.\n\\]\n\\(\\ket{0}\\ket{y} \\mapsto \\ket{0}\\ket{y+1}\\) and \\(\\ket{1}\\ket{y}\\mapsto\\ket{1}\\ket{y+1}\\). In this case, both basis states get a phase kickback, and \\[\n\\ket{+}\\ket{-} \\mapsto -\\ket{+}\\ket{-}.\n\\] Yet an overall phase does not affect the state.\n\\(\\ket{0}\\ket{y} \\mapsto \\ket{0}\\ket{y+0}\\) and \\(\\ket{1}\\ket{y}\\mapsto\\ket{1}\\ket{y+1}\\). In this case, only the \\(\\ket{1}\\) basis state gets a phase kickback, and \\[\n\\ket{+}\\ket{-} \\mapsto \\ket{0}\\ket{-} - \\ket{1}\\ket{-} = \\ket{-}\\ket{-}.\n\\]\n\\(\\ket{0}\\ket{y} \\mapsto \\ket{0}\\ket{y+1}\\) and \\(\\ket{1}\\ket{y}\\mapsto\\ket{1}\\ket{y+0}\\). In this case, only the \\(\\ket{0}\\) basis state gets a phase kickback, and \\[\n\\ket{+}\\ket{-} \\mapsto -\\ket{0}\\ket{-} + \\ket{1}\\ket{-} = -\\ket{-}\\ket{-}.\n\\]\n\nEven though the extra qubit is not changed by the oracle, it provides an important function with its \\(-1\\) phase, allowing it to change the phase of other qubits from \\(\\ket{+}\\) to \\(\\ket{-}\\) in a strategic way to allow interference.\nGenerically, when \\(U_f\\) acts on \\(\\ket{x}\\ket{-}\\), it transforms the state as follows:\n\\[\nU_f \\ket{x}\\ket{-} = (-1)^{f(x)} \\ket{x} \\ket{-}\n\\]\nThe phase factor \\((-1)^{f(x)}\\) appears on the input qubit \\(\\ket{x}\\). This phase encodes whether \\(f(x)\\) is 0 or 1. This is how the global properties of f are transferred to the first qubit.\n\n\nAfter the oracle \\(U_f\\) acts on the state \\(\\frac{1}{\\sqrt{2}}(\\ket{0}+\\ket{1})\\otimes\\frac{1}{\\sqrt{2}}(\\ket{0}-\\ket{1})\\), the first qubit (ignoring the auxiliary qubit, which remains in the state \\(\\ket{-} = \\frac{1}{\\sqrt{2}}(\\ket{0}-\\ket{1})\\)), becomes:\n\\[\n\\frac{1}{\\sqrt{2}} \\left[ (-1)^{f(0)}\\ket{0} + (-1)^{f(1)}\\ket{1} \\right]\n\\]\nThe key here is that the function values \\(f(0)\\) and \\(f(1)\\) are now encoded as phases in front of the basis states \\(\\ket{0}\\) and \\(\\ket{1}\\) (this is phase kickback, see above callout box). Let’s consider the two possibilities for \\(f(x)\\): constant or balanced.\n\nConstant Functions: If \\(f(x)\\) is constant, then \\(f(0) = f(1)\\). The state is then either \\(\\pm \\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1})\\), depending on whether \\(f(x) = 0\\) or \\(f(x) = 1\\).\nBalanced Functions: If \\(f(x)\\) is balanced, then \\(f(0) \\neq f(1)\\). This means one of the function values is 0 and the other is 1. The state is then either \\(\\pm \\frac{1}{\\sqrt{2}}(\\ket{0} - \\ket{1})\\).\n\nNow we apply the final Hadamard gate to the first qubit. Recall that \\(H\\) transforms the basis states as:\n\\[\nH\\ket{0} = \\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1})\n\\]\n\\[\nH\\ket{1} = \\frac{1}{\\sqrt{2}}(\\ket{0} - \\ket{1})\n\\]\nApplying the Hadamard gate \\(H\\) to the first qubit transforms the state based on whether \\(f(x)\\) is constant or balanced:\n\nConstant Functions: If \\(f(0) = f(1) = c\\), the state before the Hadamard gate is \\(\\frac{(-1)^c}{\\sqrt{2}}(\\ket{0} + \\ket{1})\\). Applying \\(H\\) yields:\n\\[\nH\\left[\\frac{(-1)^c}{\\sqrt{2}}(\\ket{0} + \\ket{1})\\right] = (-1)^c\\ket{0}\n\\] Therefore, we always measure \\(\\ket{0}\\).\nBalanced Functions: If \\(f(0) \\neq f(1)\\), the state before the Hadamard gate is \\(\\pm\\frac{1}{\\sqrt{2}}(\\ket{0} - \\ket{1})\\). Applying \\(H\\) yields:\n\\[\nH\\left[\\pm\\frac{1}{\\sqrt{2}}(\\ket{0} - \\ket{1})\\right] = \\pm\\ket{1}\n\\] Therefore, we always measure \\(\\ket{1}\\).\n\nThe final Hadamard gate creates an interference effect, channeling the global property of \\(f\\) (constant or balanced) into a single, easily measurable property of the first qubit.\nIn summary, if \\(f\\) is constant, the final state of the first qubit will be \\(\\ket{0}\\). If \\(f\\) is balanced, the final state will be \\(\\ket{1}\\).\n\n\n\n\n\n\nExample: Walking through Deutsch’s Algorithm\n\n\n\nLet’s analyze how the algorithm behaves for each possible function, focusing on the state of the first qubit after the oracle and after the final Hadamard gate.\n\nFor \\(f_1(x) = 0\\) (constant):\n\nInitial state (first qubit): \\(\\ket{+}\\)\nState after oracle (first qubit): \\(\\frac{1}{\\sqrt{2}} [(-1)^{f_1(0)}\\ket{0} + (-1)^{f_1(1)}\\ket{1}] = \\ket{+}\\)\nApply final H gate: \\(H\\ket{+} = \\ket{0}\\)\nMeasurement: Always \\(\\ket{0}\\) ✓ Constant\n\nFor \\(f_2(x) = 1\\) (constant):\n\nInitial state (first qubit): \\(\\ket{+}\\)\nState after oracle (first qubit): \\(\\frac{1}{\\sqrt{2}} [(-1)^{f_2(0)}\\ket{0} + (-1)^{f_2(1)}\\ket{1}] = -\\ket{+}\\)\nApply final H gate: \\(H(-\\ket{+}) = -\\ket{0}\\)\nMeasurement: Always \\(\\ket{0}\\) ✓ Constant\n\nFor \\(f_3(x) = x\\) (balanced):\n\nInitial state (first qubit): \\(\\ket{+}\\)\nState after oracle (first qubit): \\(\\frac{1}{\\sqrt{2}} [(-1)^{f_3(0)}\\ket{0} + (-1)^{f_3(1)}\\ket{1}] = \\ket{-}\\)\nApply final H gate: \\(H\\ket{-} = \\ket{1}\\)\nMeasurement: Always \\(\\ket{1}\\) ✓ Balanced\n\n\n\n\n\n\n\n4.1.3 Key Insights\nSeveral quantum principles make this speedup possible:\n\nSuperposition: The initial Hadamard transforms create a superposition that allows us to evaluate \\(f(0)\\) and \\(f(1)\\) simultaneously.\nPhase Kickback: The auxiliary qubit, initialized to \\(\\ket{1}\\) and transformed by Hadamard, enables the function’s output to be encoded in the phase of the first qubit.\nInterference: The final Hadamard transform converts the phase difference into a measurable bit value.\n\n\n\n\n\n\n\nHistorical Context\n\n\n\nDeutsch’s algorithm was the first to demonstrate that quantum computers could solve certain problems faster than classical computers. While the problem itself is artificial, the techniques it introduced - particularly the use of quantum parallelism and interference - became fundamental building blocks for more practical quantum algorithms.\n\n\n\n\n\n\n\n\nUnderstanding Balanced vs Constant Functions\n\n\n\nConsider a single-bit function \\(f(x)\\). There are only four possible functions:\nConstant Functions:\n\n\\(f_1(x) = 0\\) for all \\(x\\)\n\\(f_2(x) = 1\\) for all \\(x\\)\n\nBalanced Functions:\n\n\\(f_3(x) = x\\) (identity)\n\\(f_4(x) = \\text{NOT}(x)\\)\n\nThe quantum algorithm can distinguish between these cases with just one query, while classically we need two queries to be certain!\n\n\n\n\n4.1.4 Mathematical Details\nLet’s examine how the state evolves through the circuit. After the initial Hadamard gates, we have:\n\\[\\frac{1}{2}(\\ket{0}+\\ket{1})(\\ket{0}-\\ket{1})\\]\nAfter applying \\(U_f\\), the state becomes:\n\\[\\frac{1}{2}[(-1)^{f(0)}\\ket{0}+(-1)^{f(1)}\\ket{1}](\\ket{0}-\\ket{1})\\]\nThe final Hadamard on the first qubit gives:\n\\[\\frac{1}{2}[(-1)^{f(0)}+(-1)^{f(1)}]\\ket{0} + \\frac{1}{2}[(-1)^{f(0)}-(-1)^{f(1)}]\\ket{1}\\]\nFor constant functions, \\(f(0)=f(1)\\), leading to a measurement of \\(\\ket{0}\\). For balanced functions, \\(f(0)\\neq f(1)\\), leading to a measurement of \\(\\ket{1}\\).\nThis elegant algorithm demonstrates how quantum interference can extract global properties of a function (constant vs. balanced) with fewer queries than classically possible.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quantum Computing Algorithms</span>"
    ]
  },
  {
    "objectID": "basic_algorithms.html#deutschjozsa-algorithm",
    "href": "basic_algorithms.html#deutschjozsa-algorithm",
    "title": "4  Quantum Computing Algorithms",
    "section": "4.2 Deutsch–Jozsa Algorithm",
    "text": "4.2 Deutsch–Jozsa Algorithm\nThe Deutsch-Jozsa algorithm, published in 1992  [2], generalizes Deutsch’s algorithm to handle functions with n-bit inputs. It provides one of the first examples of an exponential speedup over classical deterministic algorithms, though for a somewhat artificial problem.\n\n4.2.1 The Problem Statement\nConsider a black box function \\(f: \\{0,1\\}^n \\rightarrow \\{0,1\\}\\) that takes n bits as input and returns a single bit. We are promised that \\(f\\) is either:\n\nConstant: returns the same value (0 or 1) for all inputs\nBalanced: returns 0 for exactly half of the inputs and 1 for the other half\n\nThe task is to determine whether \\(f\\) is constant or balanced.\n\n\n\n\n\n\nClassical vs. Quantum Complexity\n\n\n\nClassically, in the worst case, we need to evaluate \\(f(x)\\) for \\(2^{n-1} + 1\\) different inputs to be certain of the answer. This is because we might need to check more than half the possible inputs before finding two different outputs. The Deutsch-Jozsa algorithm solves this problem with just one quantum query!\n\n\n\n\n4.2.2 Quantum Implementation\nThe quantum circuit requires:\n\nn qubits for the input register, initialized to \\(\\ket{0}^{\\otimes n}\\)\nOne auxiliary qubit initialized to \\(\\ket{1}\\)\n\n\n\n\n\n\n\n\nFig. 4.1: The implementation of the Deutsch-Jozsa Algorithm for four bits.\n\n\n\nThe Deutsch-Jozsa algorithm can be summarized as follows:\n\nApply Hadamard gates to all input qubits and the auxiliary qubit.\nApply the quantum oracle \\(U_f\\).\nApply Hadamard gates to the input qubits.\nMeasure the input qubits.\n\nTo understand the algorithm more deeply, let’s analyze each step mathematically.\n\n\n4.2.3 Mathematical Analysis\n\nInitialization and Hadamard Transform:\nWe begin with the state \\(\\ket{0}^{\\otimes n}\\ket{1}\\). Applying Hadamard gates to all \\(n+1\\) qubits transforms the state as follows:\n\\[\\ket{0}^{\\otimes n}\\ket{1} \\xrightarrow{H^{\\otimes (n+1)}} \\frac{1}{\\sqrt{2^n}}\\sum_{x\\in\\{0,1\\}^n}\\ket{x}\\otimes\\frac{1}{\\sqrt{2}}(\\ket{0}-\\ket{1})\\]\nApplication of the Quantum Oracle:\nThe quantum oracle \\(U_f\\) is applied, which implements the transformation:\n\\[\\ket{x}\\ket{y} \\rightarrow \\ket{x}\\ket{y \\oplus f(x)}\\]\nThis transforms the state to:\n\\[\n\\frac{1}{\\sqrt{2^n}}\\sum_{x\\in\\{0,1\\}^n}\\ket{x}\\otimes\\frac{1}{\\sqrt{2}}(\\ket{f(x)}-\\ket{\\overline{f(x)}})\n\\]\nwhere \\(\\overline{f(x)}\\) represents the complement of \\(f(x)\\). This can be rewritten via phase kickback as:\n\\[\n\\frac{1}{\\sqrt{2^n}}\\sum_{x\\in\\{0,1\\}^n}(-1)^{f(x)}\\ket{x}\\otimes\\frac{1}{\\sqrt{2}}(\\ket{0}-\\ket{1})\n\\]\nFinal Hadamard Transform:\nHadamard gates are applied to the \\(n\\) input qubits. To see the effect, we apply the Hadamard transform to each qubit. Recall that \\(H\\ket{x} = \\frac{1}{\\sqrt{2}}\\sum_{z \\in \\{0,1\\}} (-1)^{x \\cdot z} \\ket{z}\\). Applying this to all \\(n\\) qubits, we get:\n\\[\nH^{\\otimes n} \\ket{x} = \\frac{1}{\\sqrt{2^n}} \\sum_{z \\in \\{0,1\\}^n} (-1)^{x \\cdot z} \\ket{z}\n\\]\nwhere \\(x \\cdot z = x_1z_1 \\oplus x_2z_2 \\oplus \\dots \\oplus x_nz_n\\). Therefore, the state becomes:\n\\[\n\\frac{1}{\\sqrt{2^n}}\\sum_{x\\in\\{0,1\\}^n} (-1)^{f(x)} \\left( \\frac{1}{\\sqrt{2^n}} \\sum_{z \\in \\{0,1\\}^n} (-1)^{x \\cdot z} \\ket{z} \\right) \\otimes \\frac{1}{\\sqrt{2}}(\\ket{0}-\\ket{1})\n\\]\nRearranging the summation, we have:\n\\[\n\\frac{1}{2^n}\\sum_{z\\in\\{0,1\\}^n} \\left( \\sum_{x\\in\\{0,1\\}^n} (-1)^{f(x) + x \\cdot z} \\right) \\ket{z} \\otimes \\frac{1}{\\sqrt{2}}(\\ket{0}-\\ket{1})\n\\]\nConstant Function Case:\nIf \\(f(x)\\) is a constant function, meaning \\(f(x) = c\\) for all \\(x\\), the state simplifies to:\n\\[\n\\pm \\ket{0}^{\\otimes n}\\otimes\\frac{1}{\\sqrt{2}}(\\ket{0}-\\ket{1})\n\\]\nThe sign depends on the value of \\(c\\). Measuring the first \\(n\\) qubits will yield \\(\\ket{0}^{\\otimes n}\\) with certainty.\nBalanced Function Case:\nIf \\(f(x)\\) is a balanced function, the interference is such that the amplitude of the \\(\\ket{0}^{\\otimes n}\\) state becomes zero. Therefore, when measuring the first \\(n\\) qubits, the probability of obtaining \\(\\ket{0}^{\\otimes n}\\) is 0. This means we are guaranteed to measure a state other than \\(\\ket{0}^{\\otimes n}\\).\nMeasurement:\nFinally, we measure the \\(n\\) input qubits. If the measurement result is \\(\\ket{0}^{\\otimes n}\\), the function is constant. Otherwise, if any of the qubits are measured to be \\(\\ket{1}\\), the function is balanced.\n\n\n\n\n\n\n\nSuperposition from Product of Plus States\n\n\n\nApplying a Hadamard gate to each qubit in the \\(\\ket{0}^{\\otimes n}\\) state creates a superposition of all possible \\(n\\)-bit strings. This is because:\n\\[\n\\begin{aligned}\nH^{\\otimes n}\\ket{0}^{\\otimes n} & = H\\ket{0} \\otimes H\\ket{0} \\otimes \\dots \\otimes H\\ket{0} \\\\ & = \\ket{+}^{\\otimes n} \\\\ & = \\frac{1}{\\sqrt{2^n}}\\sum_{x\\in\\{0,1\\}^n}\\ket{x}\n\\end{aligned}\n\\]\nEach qubit is in an equal superposition of \\(\\ket{0}\\) and \\(\\ket{1}\\), and since the qubits are independent, the overall state is a superposition of all \\(2^n\\) possible combinations of \\(\\ket{0}\\) and \\(\\ket{1}\\).\nFor \\(n=1\\):\n\\[H\\ket{0} = \\frac{\\ket{0} + \\ket{1}}{\\sqrt{2}} = \\frac{1}{\\sqrt{2}}\\sum_{x\\in\\{0,1\\}}\\ket{x}\\]\nFor \\(n=2\\):\n\\[\n\\begin{aligned}\nH^{\\otimes 2}\\ket{00} & = H\\ket{0} \\otimes H\\ket{0} \\\\\n& = \\frac{\\ket{0} + \\ket{1}}{\\sqrt{2}} \\otimes \\frac{\\ket{0} + \\ket{1}}{\\sqrt{2}} \\\\\n& = \\frac{\\ket{00} + \\ket{01} + \\ket{10} + \\ket{11}}{2} \\\\\n& = \\frac{1}{2}\\sum_{x\\in\\{0,1\\}^2}\\ket{x}\n\\end{aligned}\n\\]\nFor \\(n=3\\):\n\\[\n\\begin{aligned}\nH^{\\otimes 3}\\ket{000} & = H\\ket{0} \\otimes H\\ket{0} \\otimes H\\ket{0} \\\\\n& = \\frac{\\ket{0} + \\ket{1}}{\\sqrt{2}} \\otimes \\frac{\\ket{0} + \\ket{1}}{\\sqrt{2}} \\otimes \\frac{\\ket{0} + \\ket{1}}{\\sqrt{2}} \\\\\n& = \\frac{\\ket{000} + \\ket{001} + \\ket{010} + \\ket{011}}{2\\sqrt{2}} \\\\\n& \\;\\;\\; + \\frac{\\ket{100} + \\ket{101} + \\ket{110} + \\ket{111}}{2\\sqrt{2}} \\\\\n& = \\frac{1}{2\\sqrt{2}}\\sum_{x\\in\\{0,1\\}^3}\\ket{x}\n\\end{aligned}\n\\]\n\n\nThe amplitude of the \\(\\ket{0}^{\\otimes n}\\) state after the final Hadamard transform is given by:\n\\[\n\\frac{1}{2^n}\\sum_{x\\in\\{0,1\\}^n}(-1)^{f(x)}\n\\]\nThis sum evaluates to:\n\n\\(\\pm 1\\) if \\(f(x)\\) is a constant function.\n\\(0\\) if \\(f(x)\\) is a balanced function.\n\nIf the sum is \\(\\pm 1\\), this means that the amplitude of the \\(\\ket{0}^{\\otimes n}\\) state is non-zero, and when we measure the qubits, we will obtain the \\(\\ket{0}^{\\otimes n}\\) state with certainty (or its opposite, depending on the sign). Conversely, if the sum is \\(0\\), the amplitude of the \\(\\ket{0}^{\\otimes n}\\) state is zero, meaning that when we measure the qubits, we are guaranteed not to obtain the \\(\\ket{0}^{\\otimes n}\\) state. This implies that at least one of the qubits must be in the \\(\\ket{1}\\) state.\n\n\n\n\n\n\nIllustrating Quantum Parallelism\n\n\n\nThe unitary operator \\(U_f\\) performs: \\[\\ket{x}\\ket{y} \\rightarrow \\ket{x}\\ket{y \\oplus f(x)}\\]\nWhen applied to a superposition of all possible inputs: \\[\\frac{1}{\\sqrt{2^n}}\\sum_{x}\\ket{x}\\ket{-} \\rightarrow \\frac{1}{\\sqrt{2^n}}\\sum_{x} (-1)^{f(x)}\\ket{x}\\ket{-}\\]\nThis single operation effectively computes \\(f(x)\\) for all \\(2^n\\) inputs simultaneously! This is a key feature of quantum computation.\n\n\n\n\n4.2.4 Key Insights\n\nQuantum Parallelism: The algorithm processes all possible inputs simultaneously through superposition.\nInterference: The final Hadamard transforms create interference patterns that distinguish between constant and balanced functions.\nPromise Problem: The algorithm’s exponential speedup relies crucially on the promise that \\(f\\) is either constant or balanced. Without this promise, the quantum advantage disappears.\n\n\n\n\n\n\n\nExample with n=2\n\n\n\nFor n=2, the classical algorithm needs to evaluate \\(f(00)\\), \\(f(01)\\), and possibly \\(f(10)\\) to determine if \\(f\\) is constant or balanced. The quantum algorithm still requires just one query regardless of n.\nConsider a balanced function \\(f(00)=f(01)=0\\) and \\(f(10)=f(11)=1\\):\n\nInitial state after Hadamards: \\(\\frac{1}{2}(\\ket{00}+\\ket{01}+\\ket{10}+\\ket{11})(\\ket{0}-\\ket{1})\\)\nAfter oracle: \\(\\frac{1}{2}(\\ket{00}+\\ket{01}-\\ket{10}-\\ket{11})(\\ket{0}-\\ket{1})\\)\nFinal state after Hadamards: \\(\\ket{\\psi}\\otimes\\frac{1}{\\sqrt{2}}(\\ket{0}-\\ket{1})\\) where \\(\\ket{\\psi}\\) has zero amplitude for \\(\\ket{00}\\): \\[\n\\ket{\\psi} = \\frac{1}{2}(\\ket{00}+\\ket{01}-\\ket{10}-\\ket{11})\n\\] \\[\nH^{\\otimes 2}\\ket{\\psi} = \\ket{10}\n\\]\n\n\n\nThe Deutsch-Jozsa algorithm, while solving an artificial problem, demonstrates the potential power of quantum computation and introduces techniques that appear in many more practical quantum algorithms.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quantum Computing Algorithms</span>"
    ]
  },
  {
    "objectID": "basic_algorithms.html#bernsteinvazirani-algorithm",
    "href": "basic_algorithms.html#bernsteinvazirani-algorithm",
    "title": "4  Quantum Computing Algorithms",
    "section": "4.3 Bernstein–Vazirani Algorithm",
    "text": "4.3 Bernstein–Vazirani Algorithm\nBuilding upon the Deutsch and Deutsch-Jozsa algorithms, the Bernstein-Vazirani algorithm  [3] tackles a different problem: instead of determining a global property of a function (like whether it’s constant or balanced), it aims to learn a hidden string encoded within the function’s behavior. While the Deutsch-Jozsa algorithm distinguishes between constant and balanced functions, the Bernstein-Vazirani algorithm identifies a specific string \\(s\\) that defines the function \\(f(x) = s \\cdot x \\pmod{2}\\). This algorithm showcases how quantum computation can be used to extract specific information from a function with just a single query, offering an exponential speedup compared to classical approaches.\n\n4.3.1 Problem Statement\nThe Bernstein-Vazirani algorithm is designed to solve the following problem:\nGiven a hidden string \\(s \\in \\{0, 1\\}^n\\), and a function \\(f: \\{0, 1\\}^n \\rightarrow \\{0, 1\\}\\) such that \\(f(x) = s \\cdot x \\pmod{2}\\), where \\(s \\cdot x\\) is the bitwise dot product of \\(s\\) and \\(x\\), the goal is to find the hidden string \\(s\\).\nClassically, determining \\(s\\) requires \\(n\\) queries to the function \\(f\\). The Bernstein-Vazirani algorithm can find \\(s\\) with just one quantum query.\n\n\n4.3.2 Quantum Implementation\nThe quantum circuit consists of:\n\n\\(n\\) input qubits initialized to \\(\\ket{0}^{\\otimes n}\\)\nOne auxiliary qubit initialized to \\(\\ket{1}\\)\n\nThe algorithm proceeds as follows:\n\nApply Hadamard gates to all \\(n\\) input qubits and the auxiliary qubit.\nApply the quantum oracle \\(U_f\\), defined as \\(\\ket{x}\\ket{y} \\rightarrow \\ket{x}\\ket{y \\oplus f(x)}\\).\nApply Hadamard gates to the \\(n\\) input qubits.\nMeasure the \\(n\\) input qubits. The measurement outcome will be the hidden string \\(s\\).\n\n\n\n4.3.3 Step-by-step state evolution with Hadamard gates\nLet’s break down how the quantum state evolves as Hadamard gates are applied. This will give you a clearer picture of how the algorithm works.\n\nInitialization: We start with \\(n\\) qubits in the \\(\\ket{0}\\) state and one auxiliary qubit in the \\(\\ket{1}\\) state: \\[\n\\ket{\\psi_0} = \\ket{0}^{\\otimes n} \\ket{1} = \\ket{00...0}\\otimes \\ket{1}\n\\]\nApplying Hadamards: We apply Hadamard gates to all \\(n+1\\) qubits. Recall that the Hadamard gate transforms \\(\\ket{0}\\) to \\(\\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1})\\) and \\(\\ket{1}\\) to \\(\\frac{1}{\\sqrt{2}}(\\ket{0} - \\ket{1})\\). Applying \\(H^{\\otimes n}\\) to the first \\(n\\) qubits transforms \\(\\ket{0}^{\\otimes n}\\) into an equal superposition of all possible \\(n\\)-bit strings: \\[\nH^{\\otimes n}\\ket{0}^{\\otimes n} = \\frac{1}{\\sqrt{2^n}} \\sum_{x \\in \\{0, 1\\}^n} \\ket{x}\n\\] Applying a Hadamard gate to the auxiliary qubit transforms \\(\\ket{1}\\) to \\(\\frac{1}{\\sqrt{2}}(\\ket{0} - \\ket{1})\\). Therefore, after applying the Hadamard gates, the state becomes: \\[\n\\begin{aligned}\n\\ket{\\psi_1} &= \\frac{1}{\\sqrt{2^n}} \\sum_{x \\in \\{0, 1\\}^n} \\ket{x} \\otimes \\frac{1}{\\sqrt{2}}(\\ket{0} - \\ket{1}) \\\\\n&= \\frac{1}{\\sqrt{2^{n+1}}} \\sum_{x \\in \\{0, 1\\}^n} \\ket{x}(\\ket{0} - \\ket{1})\n\\end{aligned}\n\\]\nApplying the Quantum Oracle: The quantum oracle \\(U_f\\) acts as \\(\\ket{x}\\ket{y} \\rightarrow \\ket{x}\\ket{y \\oplus f(x)}\\). Applying \\(U_f\\) to \\(\\ket{\\psi_1}\\) gives: \\[\n\\ket{\\psi_2} = \\frac{1}{\\sqrt{2^{n+1}}} \\sum_{x \\in \\{0, 1\\}^n} \\ket{x}\\ket{f(x) \\oplus 1}\n\\] Since \\(f(x) = s \\cdot x \\pmod{2}\\), we can rewrite this as: \\[\n\\ket{\\psi_2} = \\frac{1}{\\sqrt{2^{n+1}}} \\sum_{x \\in \\{0, 1\\}^n} \\ket{x}\\ket{s \\cdot x \\oplus 1}\n\\] We can rewrite \\(\\ket{s \\cdot x \\oplus 1}\\) as \\((-1)^{s \\cdot x}\\ket{1}\\), so the state becomes: \\[\n\\ket{\\psi_2} = \\frac{1}{\\sqrt{2^{n+1}}} \\sum_{x \\in \\{0, 1\\}^n} (-1)^{s \\cdot x}\\ket{x}(\\ket{0} - \\ket{1})\n\\tag{4.1}\\]\nApplying Hadamards Again: We apply Hadamard gates to the first \\(n\\) qubits again. Let’s consider what happens if we apply \\(H^{\\otimes n}\\) to the state \\(\\ket{s}\\). \\[\nH^{\\otimes n}\\ket{s} = \\frac{1}{\\sqrt{2^n}} \\sum_{y \\in \\{0, 1\\}^n} (-1)^{s \\cdot y} \\ket{y}\n\\] Notice that this is Eq. 4.1, and since \\(H^2 = I\\), we can invert this to see that \\[\n\\ket{s} \\otimes \\ket{-}= \\frac{1}{\\sqrt{2^n}} H^{\\otimes n}\\sum_{x \\in \\{0, 1\\}^n} (-1)^{s \\cdot x} \\ket{x} \\ket{-}\n\\]\nMeasurement: Measuring the first \\(n\\) qubits yields the hidden string \\(s\\) with certainty. The auxiliary qubit is left in the state \\(\\frac{1}{\\sqrt{2}}(\\ket{0} - \\ket{1})\\), which we can ignore after the measurement.\n\nIn summary, the algorithm cleverly uses Hadamard gates and the quantum oracle to transform the initial state into a state where measuring the first \\(n\\) qubits directly reveals the hidden string \\(s\\). The key is the interference caused by the Hadamard gates and the phase kickback from the oracle, which amplifies the amplitude of the state corresponding to the hidden string.\n\n\n\n\n\n\nClassical vs. Quantum Speed\n\n\n\nThe Bernstein-Vazirani algorithm showcases a significant speedup for this specific problem compared to its classical counterpart. Classically, determining the hidden string \\(s\\) would require \\(n\\) queries to the function \\(f(x)\\), while the quantum algorithm achieves the same result with just a single query to the quantum oracle \\(U_f\\). This demonstrates an exponential speedup highlighting the power of quantum computation for specific tasks.\n\n\n\n\n\n\n\n\nBernstein-Vazirani Algorithm Example (n=2, s=10)\n\n\n\nLet’s consider the Bernstein-Vazirani algorithm for \\(n=2\\) with the hidden string \\(s = 10\\). The function \\(f(x)\\) computes the dot product of \\(x\\) and \\(s\\) modulo 2: \\(f(x) = (s \\cdot x) \\pmod{2}\\). In our case, \\(f(x) = (10 \\cdot x) \\pmod{2}\\).\n\nInitialization: We begin with a three-qubit state, with the first two qubits in state \\(\\ket{0}\\) and the auxiliary qubit in state \\(\\ket{1}\\): \\[\n\\ket{\\psi_0} = \\ket{001} = \\ket{0} \\otimes \\ket{0} \\otimes \\ket{1}\n\\]\nApply Hadamard Gates: Apply Hadamard gates to each qubit. Recall that \\(H\\ket{0} = \\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1})\\) and \\(H\\ket{1} = \\frac{1}{\\sqrt{2}}(\\ket{0} - \\ket{1})\\). Applying \\(H^{\\otimes 3}\\) to \\(\\ket{\\psi_0}\\): \\[\n\\begin{aligned}\n\\ket{\\psi_1} &= H^{\\otimes 3} \\ket{001} \\\\\n&= (H \\otimes H \\otimes H) (\\ket{0} \\otimes \\ket{0} \\otimes \\ket{1}) \\\\\n&= (H\\ket{0}) \\otimes (H\\ket{0}) \\otimes (H\\ket{1}) \\\\\n&= \\left[ \\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1}) \\right] \\otimes \\left[ \\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1}) \\right] \\otimes \\left[ \\frac{1}{\\sqrt{2}}(\\ket{0} - \\ket{1}) \\right] \\\\\n&= \\frac{1}{\\sqrt{8}} (\\ket{0} + \\ket{1}) (\\ket{0} + \\ket{1}) (\\ket{0} - \\ket{1}) \\\\\n&= \\frac{1}{\\sqrt{8}} (\\ket{00} + \\ket{01} + \\ket{10} + \\ket{11}) (\\ket{0} - \\ket{1})\n\\end{aligned}\n\\]\nApply Quantum Oracle (Uf): Apply the quantum oracle \\(U_f\\) which acts as \\(\\ket{x}\\ket{y} \\rightarrow \\ket{x}\\ket{y \\oplus f(x)}\\). We use phase kickback by initializing the auxiliary qubit to \\(\\ket{-} = H\\ket{1} = \\frac{1}{\\sqrt{2}}(\\ket{0} - \\ket{1})\\). Thus, the oracle effectively applies a phase \\((-1)^{f(x)}\\) to the computational basis states of the input qubits: \\(\\ket{x} \\rightarrow (-1)^{f(x)} \\ket{x}\\). For \\(s = 10\\), we have: \\(f(00) = (10) \\cdot (00) = 0\\) \\(f(01) = (10) \\cdot (01) = 0\\) \\(f(10) = (10) \\cdot (10) = 1\\) \\(f(11) = (10) \\cdot (11) = 1\\) Applying the oracle \\(U_f\\) to \\(\\ket{\\psi_1}\\) and utilizing phase kickback, we get: \\[\n\\begin{aligned}\n\\ket{\\psi_2} &= U_f \\ket{\\psi_1} \\\\\n&= \\frac{1}{\\sqrt{8}} \\left[ (-1)^{f(00)}\\ket{00} + (-1)^{f(01)}\\ket{01} + (-1)^{f(10)}\\ket{10} + (-1)^{f(11)}\\ket{11} \\right] (\\ket{0} - \\ket{1}) \\\\\n&= \\frac{1}{\\sqrt{8}} \\left[ \\ket{00} + \\ket{01} - \\ket{10} - \\ket{11} \\right] (\\ket{0} - \\ket{1})\n\\end{aligned}\n\\]\nApply Hadamard Gates Again: Apply Hadamard gates to the first two qubits (input qubits) only, \\(H^{\\otimes 2} \\otimes I\\) to \\(\\ket{\\psi_2}\\): \\[\n\\begin{aligned}\n\\ket{\\psi_3} &= (H^{\\otimes 2} \\otimes I) \\ket{\\psi_2} \\\\\n&= (H \\otimes H \\otimes I) \\left[ \\frac{1}{\\sqrt{8}} (\\ket{00} + \\ket{01} - \\ket{10} - \\ket{11}) (\\ket{0} - \\ket{1}) \\right] \\\\\n&= \\ket{10} \\otimes \\left( \\frac{\\ket{0} - \\ket{1}}{\\sqrt{2}} \\right)\n\\end{aligned}\n\\]\nMeasurement: Measuring the first two qubits in the computational basis will yield the state \\(\\ket{10}\\) with probability 1. This directly reveals the hidden string \\(s = 10\\). The auxiliary qubit is left in the state \\(\\frac{1}{\\sqrt{2}}(\\ket{0} - \\ket{1}) = \\ket{-}\\), but we are only interested in the measurement outcome of the first two qubits.\n\n\n\n\n\n4.3.4 Connection to Deutsch-Jozsa Algorithm\nThe Bernstein-Vazirani algorithm can be seen as a generalization of the Deutsch-Jozsa algorithm. While Deutsch-Jozsa distinguishes between constant and balanced functions, Bernstein-Vazirani identifies a specific hidden string. If we consider the Deutsch-Jozsa problem as determining whether the dot product \\(s \\cdot x\\) is always 0 (constant function) or not (balanced function), Bernstein-Vazirani extends this to find the specific string \\(s\\) that defines this dot product. Both algorithms leverage the power of quantum parallelism and interference to achieve an exponential speedup over classical algorithms for specific problems related to function evaluation.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quantum Computing Algorithms</span>"
    ]
  },
  {
    "objectID": "basic_algorithms.html#simons-algorithm",
    "href": "basic_algorithms.html#simons-algorithm",
    "title": "4  Quantum Computing Algorithms",
    "section": "4.4 Simon’s Algorithm",
    "text": "4.4 Simon’s Algorithm\nSimon’s algorithm, introduced by Daniel Simon in 1994  [4], solves a problem that exhibits an exponential speedup over the best-known classical algorithm. It distinguishes itself as one of the early quantum algorithms demonstrating a significant advantage, albeit for a specific problem.\n\n4.4.1 Problem Statement\nConsider a function \\(f: \\{0, 1\\}^n \\rightarrow \\{0, 1\\}^n\\) with the following promise:\n\nThere exists a secret string \\(s \\in \\{0, 1\\}^n\\) such that for all \\(x, y \\in \\{0, 1\\}^n\\), \\(f(x) = f(y)\\) if and only if \\(x \\oplus y = 0^n\\) or \\(x \\oplus y = s\\), where \\(\\oplus\\) denotes bitwise XOR.\n\nIn simpler terms, \\(f\\) is two-to-one, and it maps \\(x\\) and \\(x \\oplus s\\) to the same value. The goal is to find the hidden string \\(s\\).\nClassically, solving this problem requires \\(O(2^{n/2})\\) queries to \\(f\\) using a collision-finding algorithm. Simon’s algorithm solves it in polynomial time with \\(O(n)\\) queries.\n\n\n4.4.2 Quantum Implementation\n\n\n\n\nThe Simon’s algorithm reveals an \\(y\\) such that \\(s\\cdot y = 0\\).\n\n\nThe quantum circuit for Simon’s algorithm involves the following steps:\n\nInitialization: Start with two registers of \\(n\\) qubits each, both initialized to \\(\\ket{0}^{\\otimes n}\\).\n\\[\n\\ket{\\psi_0} = \\ket{0}^{\\otimes n} \\ket{0}^{\\otimes n}\n\\]\nSuperposition: Apply a Hadamard gate to each qubit in the first register. This creates an equal superposition of all possible \\(n\\)-bit strings.\n\\[\n\\ket{\\psi_1} = \\frac{1}{\\sqrt{2^n}} \\sum_{x \\in \\{0, 1\\}^n} \\ket{x} \\ket{0}^{\\otimes n}\n\\]\nQuery the Oracle: Apply the quantum oracle \\(U_f\\) that implements the function \\(f\\): \\(\\ket{x}\\ket{y} \\rightarrow \\ket{x}\\ket{y \\oplus f(x)}\\).\n\\[\n\\ket{\\psi_2} = \\frac{1}{\\sqrt{2^n}} \\sum_{x \\in \\{0, 1\\}^n} \\ket{x} \\ket{f(x)}\n\\]\nMeasure the Second Register: Measure the second register. This yields a value \\(f(x_0)\\) for some \\(x_0 \\in \\{0, 1\\}^n\\). Due to the property of \\(f\\), we know that \\(f(x_0) = f(x_0 \\oplus s)\\). Therefore, the first register collapses to an equal superposition of \\(\\ket{x_0}\\) and \\(\\ket{x_0 \\oplus s}\\):\n\\[\n\\ket{\\psi_3} = \\frac{1}{\\sqrt{2}} (\\ket{x_0} + \\ket{x_0 \\oplus s}) \\ket{f(x_0)}\n\\]\nWe can ignore the second register from now on, as it is no longer needed. Consider only the first register, which is now in the state:\n\\[\n\\ket{\\psi_3'} = \\frac{1}{\\sqrt{2}} (\\ket{x_0} + \\ket{x_0 \\oplus s})\n\\]\nApply Hadamard Transform: Apply a Hadamard gate to each qubit in the first register.\n\\[\n\\ket{\\psi_4} =  H^{\\otimes n} \\left[ \\frac{1}{\\sqrt{2}} (\\ket{x_0} + \\ket{x_0 \\oplus s}) \\right]\n\\]\nRecall that \\(H^{\\otimes n} \\ket{x} = \\frac{1}{\\sqrt{2^n}} \\sum_{y \\in \\{0, 1\\}^n} (-1)^{x \\cdot y} \\ket{y}\\). Therefore:\n\\[\n\\ket{\\psi_4} = \\frac{1}{\\sqrt{2^{n+1}}} \\sum_{y \\in \\{0, 1\\}^n} \\left[ (-1)^{x_0 \\cdot y} + (-1)^{(x_0 \\oplus s) \\cdot y} \\right] \\ket{y}\n\\]\nSimplifying the exponent, we have \\((x_0 \\oplus s) \\cdot y = (x_0 \\cdot y) \\oplus (s \\cdot y)\\). Thus:\n\\[\n\\ket{\\psi_4} = \\frac{1}{\\sqrt{2^{n+1}}} \\sum_{y \\in \\{0, 1\\}^n} (-1)^{x_0 \\cdot y} \\left[ 1 + (-1)^{s \\cdot y} \\right] \\ket{y}\n\\]\nNotice that if \\(s \\cdot y = 1\\), then the term in the brackets becomes \\(1 + (-1) = 0\\). Therefore, we only get non-zero amplitudes for \\(y\\) such that \\(s \\cdot y = 0\\).\nMeasure the First Register: Measure the first register. The measurement outcome \\(y\\) will satisfy the equation \\(s \\cdot y = 0 \\pmod{2}\\).\nRepeat: Repeat steps 2-6 \\(O(n)\\) times to obtain \\(n-1\\) linearly independent equations of the form \\(s \\cdot y_i = 0 \\pmod{2}\\).\nSolve the System of Equations: Solve the system of linear equations to find the hidden string \\(s\\). This can be done efficiently using classical Gaussian elimination.\n\n\n\n\n\n\n\nExample\n\n\n\nLet’s work through an example of Simon’s algorithm for \\(n=3\\) qubits. Suppose the hidden string is \\(s = 110\\) (though we don’t know this yet).\nFor a hidden string \\(s = 110\\), the valid measurements that satisfy \\(s \\cdot y = 0 \\pmod{2}\\) are \\(y \\in \\{001, 110, 111\\}\\).\nAfter running steps 2-6 of Simon’s algorithm once, we might measure \\(y_1 = 001\\) in the first register. This gives us our first equation: \\[s \\cdot y_1 = 0 \\pmod{2}\\]\nSubstituting \\(y_1 = 001\\), we get: \\[s_1 \\cdot 0 + s_2 \\cdot 0 + s_3 \\cdot 1 = 0 \\pmod{2}\\] \\[s_3 = 0\\]\nSo we’ve learned that the third bit of our hidden string is 0.\nRunning the algorithm a second time, we might measure \\(y_2 = 110\\). This gives us our second equation: \\[s \\cdot y_2 = 0 \\pmod{2}\\]\nSubstituting \\(y_2 = 110\\), we get: \\[s_1 \\cdot 1 + s_2 \\cdot 1 + s_3 \\cdot 0 = 0 \\pmod{2}\\] \\[s_1 + s_2 = 0 \\pmod{2}\\]\nSince \\(s_1 + s_2 = 0 \\pmod{2}\\), either both \\(s_1\\) and \\(s_2\\) are 0, or both are 1. Given that \\(s \\neq 000\\) (by the promise that \\(f\\) is two-to-one) and \\(s_3 = 0\\), we must have \\(s_1 = s_2 = 1\\).\nTherefore, \\(s = 110\\), which is indeed our hidden string.\nThis example demonstrates how Simon’s algorithm allows us to efficiently determine the hidden string by collecting and solving a system of linear equations.\n\n\n\n\n\n\n\n\nSimon’s Secret: How Identical Outputs Reveal the Hidden String\n\n\n\nSimon’s algorithm cleverly exploits the function’s special property: \\(f(x) = f(x \\oplus s)\\).\n\nSuperposition: The initial Hadamard gates create a superposition of all possible inputs: \\[\\frac{1}{\\sqrt{2^n}}\\sum_{x\\in\\{0,1\\}^n}\\ket{x}\\]\nOracle’s Role: The oracle maps each input to its corresponding output: \\[\\frac{1}{\\sqrt{2^n}}\\sum_{x\\in\\{0,1\\}^n}\\ket{x}\\ket{f(x)}\\]\nThe Magic: Because \\(f(x) = f(x \\oplus s)\\), measuring the second register (the output) entangles pairs of inputs (\\(x\\) and \\(x \\oplus s\\)) that produce the same output. This entanglement creates a special interference pattern in the first register that, after more steps, allows us to extract the hidden string \\(s\\).\n\n\n\n\n\n4.4.3 Quantum Speedup\nSimon’s algorithm provides an exponential speedup over classical algorithms for finding the hidden string \\(s\\). The classical algorithm requires \\(O(2^{n/2})\\) queries, while Simon’s algorithm requires only \\(O(n)\\) quantum queries and polynomial classical post-processing. This demonstrates the potential of quantum computers to solve certain problems much more efficiently than their classical counterparts.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quantum Computing Algorithms</span>"
    ]
  },
  {
    "objectID": "basic_algorithms.html#quantum-phase-estimation",
    "href": "basic_algorithms.html#quantum-phase-estimation",
    "title": "4  Quantum Computing Algorithms",
    "section": "4.5 Quantum Phase Estimation",
    "text": "4.5 Quantum Phase Estimation\nQuantum Phase Estimation (QPE) is a crucial quantum algorithm used to estimate the eigenvalue (or phase) of an eigenvector of a unitary operator. It serves as a building block for many other quantum algorithms, including Shor’s algorithm for factoring and algorithms for simulating quantum systems.\n\n4.5.1 Problem Statement\nGiven a unitary operator \\(U\\) and an eigenstate \\(\\ket{\\psi}\\) such that \\(U\\ket{\\psi} = e^{2\\pi i \\theta} \\ket{\\psi}\\), the goal of QPE is to estimate the value of \\(\\theta\\). Here, \\(\\theta\\) is the phase we want to estimate, and it lies in the range \\([0, 1)\\).\n\n\n4.5.2 Quantum Implementation\n\n\n\n\nQPE circuit with 3 qubits in the control register (for 3 digit accuracy)\n\n\nThe QPE algorithm uses two registers:\n\nThe Control Register: This register consists of \\(t\\) qubits, initialized to \\(\\ket{0}^{\\otimes t}\\). The number of qubits \\(t\\) determines the precision of the phase estimation.\nThe Eigenstate Register: This register holds the eigenstate \\(\\ket{\\psi}\\) of the unitary operator \\(U\\).\n\nThe algorithm proceeds as follows:\n\nInitialization: Prepare the control register in the state \\(\\ket{0}^{\\otimes t}\\) and the eigenstate register in the state \\(\\ket{\\psi}\\).\n\\[\n\\ket{\\psi_0} = \\ket{0}^{\\otimes t} \\ket{\\psi}\n\\]\nSuperposition: Apply a Hadamard gate to each qubit in the control register to create an equal superposition.\n\\[\n\\ket{\\psi_1} = \\frac{1}{\\sqrt{2^t}} \\sum_{x=0}^{2^t-1} \\ket{x} \\ket{\\psi}\n\\]\nControlled Unitary Operations: Apply controlled-\\(U\\) operations, where \\(U\\) is applied \\(2^j\\) times conditioned on the \\(j\\)-th qubit (counting from 0) of the control register. This means applying \\(U^{2^j}\\) when the \\(j\\)-th qubit is \\(\\ket{1}\\).\n\\[\n\\ket{\\psi_2} = \\frac{1}{\\sqrt{2^t}} \\sum_{x=0}^{2^t-1} \\ket{x} U^x \\ket{\\psi} = \\frac{1}{\\sqrt{2^t}} \\sum_{x=0}^{2^t-1} \\ket{x} e^{2\\pi i \\theta x} \\ket{\\psi}\n\\]\nWe can rewrite this as:\n\\[\n\\ket{\\psi_2} = \\frac{1}{\\sqrt{2^t}} \\left( \\sum_{x=0}^{2^t-1} e^{2\\pi i \\theta x} \\ket{x} \\right) \\ket{\\psi}\n\\]\nInverse Quantum Fourier Transform (QFT†): Apply the inverse Quantum Fourier Transform (QFT†) to the control register. The QFT† transforms the state:\n\\[\n\\text{QFT}^\\dagger \\ket{x} = \\frac{1}{\\sqrt{2^t}} \\sum_{y=0}^{2^t-1} e^{-2\\pi i xy / 2^t} \\ket{y}\n\\]\nApplying QFT† to the control register of \\(\\ket{\\psi_2}\\) yields:\n\\[\n\\ket{\\psi_3} = \\frac{1}{2^t} \\sum_{x=0}^{2^t-1} \\sum_{y=0}^{2^t-1} e^{2\\pi i \\theta x} e^{-2\\pi i xy / 2^t} \\ket{y} \\ket{\\psi}\n\\]\nThe amplitude of each state \\(\\ket{y}\\) in the control register is:\n\\[\n\\alpha_y = \\frac{1}{2^t} \\sum_{x=0}^{2^t-1} e^{2\\pi i x (\\theta - y/2^t)}\n\\]\nThis amplitude is large when \\(y/2^t\\) is close to \\(\\theta\\).\nMeasurement: Measure the control register in the computational basis. The measurement outcome \\(y\\) provides an estimate of \\(\\theta\\) as \\(\\tilde{\\theta} = y/2^t\\).\n\n\n\n\n\n\n\nQuantum Fourier Transform (QFT) and Factorization\n\n\n\nThe Quantum Fourier Transform (QFT) is the quantum analogue of the discrete Fourier transform (DFT) and is a crucial component in many quantum algorithms, including Shor’s algorithm and quantum phase estimation. The QFT transforms a quantum state from the computational basis to the Fourier basis and vice versa. A key feature of the QFT is that it can be factored into a product of single-qubit rotations, enabling its efficient implementation on a quantum computer.\nMathematically, the QFT is defined as the following transformation on a quantum state \\(\\ket{x}\\) with \\(N\\) basis states, where \\(N = 2^n\\) for \\(n\\) qubits:\n\\[\n\\text{QFT} \\ket{x} = \\frac{1}{\\sqrt{N}} \\sum_{y=0}^{N-1} e^{2\\pi i xy / N} \\ket{y}\n\\]\nLet’s express \\(x\\) and \\(y\\) in their binary representations: \\(x = x_1 x_2 ... x_n\\) and \\(y = y_1 y_2 ... y_n\\), where \\(x_i\\) and \\(y_i\\) are the \\(i\\)-th bits of \\(x\\) and \\(y\\), respectively. Then we can rewrite the QFT as:\n\\[\n\\text{QFT} \\ket{x_1 x_2 ... x_n} = \\frac{1}{\\sqrt{N}} \\sum_{y_1=0}^{1} \\sum_{y_2=0}^{1} ... \\sum_{y_n=0}^{1} e^{2\\pi i x (\\sum_{k=1}^{n} y_k 2^{-k})} \\ket{y_1 y_2 ... y_n}\n\\]\n\\[\n= \\frac{1}{\\sqrt{N}} \\sum_{y_1=0}^{1} \\sum_{y_2=0}^{1} ... \\sum_{y_n=0}^{1}  \\prod_{k=1}^{n} e^{2\\pi i x  y_k 2^{-k}} \\ket{y_1 y_2 ... y_n}\n\\]\n\\[\n= \\frac{1}{\\sqrt{N}}  \\bigotimes_{k=1}^{n} \\sum_{y_k=0}^{1}   e^{2\\pi i x  y_k 2^{-k}} \\ket{y_k}\n\\]\n\\[\n=  \\frac{1}{\\sqrt{N}}  \\bigotimes_{k=1}^{n}  \\left( \\ket{0} + e^{2\\pi i x   2^{-k}} \\ket{1} \\right)\n\\]\n\\[\n= \\frac{1}{2^{n/2}} \\left( \\ket{0} + e^{2\\pi i x 2^{-1}} \\ket{1} \\right) \\left( \\ket{0} + e^{2\\pi i x 2^{-2}} \\ket{1} \\right) ... \\left( \\ket{0} + e^{2\\pi i x 2^{-n}} \\ket{1} \\right)\n\\]\nThis factorization shows that the QFT can be implemented by applying a series of single-qubit rotations conditioned on the values of other qubits. Specifically, the \\(k\\)-th qubit is rotated by an angle that depends on the values of the qubits \\(x_1, x_2, ..., x_n\\). This decomposition is crucial for constructing the QFT circuit efficiently.\nKey Properties and Implications:\n\nUnitary Transformation: The QFT is a unitary transformation, meaning it preserves the norm of quantum states and can be implemented as a quantum circuit.\nEfficient Implementation: The QFT can be implemented on a quantum computer using \\(O(n^2)\\) quantum gates, where \\(n\\) is the number of qubits. Note that unlike a classical FFT, direct readout of the quantum state does not give the full Fourier transform due to the nature of quantum measurement.\nPeriod Finding: The QFT is particularly useful for finding periodic patterns in quantum states, which is a key step in Shor’s algorithm for factoring integers.\nPhase Estimation: The QFT is used in the quantum phase estimation algorithm to accurately estimate the eigenvalues of unitary operators.\n\nThe inverse Quantum Fourier Transform (QFT†) reverses the transformation:\n\\[\n\\text{QFT}^\\dagger \\ket{x} = \\frac{1}{\\sqrt{N}} \\sum_{y=0}^{N-1} e^{-2\\pi i xy / N} \\ket{y}\n\\]\nIt also has an efficient implementation based on a similar factorization.\n\n\n\n\n\n\n\n\nUnpacking the Quantum Fourier Transform: Controlled Phase Shifts\n\n\n\nThe Quantum Fourier Transform (QFT) relies on a series of controlled phase shift gates to create interference patterns.\n\nControlled Phase Shift Gates: These gates apply a phase shift to a target qubit, conditioned on the state of a control qubit. The amount of the phase shift is different for each gate. For example:\n\n\\(R_2\\) gate: Adds a phase shift of \\(\\pi/2\\) (90 degrees).\n\\(R_3\\) gate: Adds a phase shift of \\(\\pi/4\\) (45 degrees).\nIn general, \\(R_k\\) gate: Adds a phase shift of \\(\\pi/2^{k-1}\\) radians.\n\nBinary Representation Analogy: Think of these phase shifts as encoding information in binary. Each qubit represents a “digit” in the binary representation of a frequency. The earlier qubits in the circuit represent the more significant bits, and later qubits represent the less significant bits.\nCreating Interference: By carefully controlling these phase shifts, the QFT creates a complex interference pattern that allows us to extract the frequency components of a quantum state. This is crucial for algorithms like Shor’s algorithm, where we need to find the period of a function.\n\n\n\n\n\n4.5.3 Accuracy\nThe accuracy of the phase estimation depends on the number of qubits \\(t\\) in the control register. If \\(\\theta\\) can be written exactly as \\(j/2^t\\) for some integer \\(j\\), then the measurement outcome will be exactly \\(j\\) with probability 1. Otherwise, the measurement will yield an approximation \\(\\tilde{\\theta}\\) of \\(\\theta\\). With high probability, the estimated phase \\(\\tilde{\\theta}\\) satisfies \\(|\\theta - \\tilde{\\theta}| \\leq 2^{-t}\\). Therefore, to achieve an accuracy of \\(2^{-n}\\), we need \\(t = n + O(\\log(1/\\epsilon))\\) qubits in the control register to succeed with probability at least \\(1 - \\epsilon\\).\n\n\n4.5.4 Example\nSuppose \\(U\\ket{\\psi} = e^{2\\pi i (1/4)} \\ket{\\psi}\\), so \\(\\theta = 1/4 = 0.25\\). Let’s use \\(t=2\\) qubits in the control register. The possible measurement outcomes are \\(00, 01, 10, 11\\), corresponding to estimates \\(0/4 = 0\\), \\(1/4 = 0.25\\), \\(2/4 = 0.5\\), and \\(3/4 = 0.75\\). The algorithm will ideally measure \\(\\ket{01}\\) with high probability, giving the correct estimate \\(\\tilde{\\theta} = 0.25\\).\n\n\n4.5.5 Applications\nQPE is a fundamental algorithm with numerous applications:\n\nShor’s Algorithm: Used to find the order of an element, which is a crucial step in factoring integers.\nQuantum Simulation: Used to estimate the energy levels of quantum systems.\nEstimating Eigenvalues: Used in various quantum machine learning algorithms.\n\nQPE showcases the power of quantum computation by efficiently estimating the phase of an eigenvalue, a task that can be difficult or impossible for classical computers in certain scenarios.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quantum Computing Algorithms</span>"
    ]
  },
  {
    "objectID": "basic_algorithms.html#grovers-algorithm",
    "href": "basic_algorithms.html#grovers-algorithm",
    "title": "4  Quantum Computing Algorithms",
    "section": "4.6 Grover’s Algorithm",
    "text": "4.6 Grover’s Algorithm\nGrover’s algorithm  [5] is a quantum search algorithm for finding a specific item in an unsorted database of \\(N\\) items with only \\(O(\\sqrt{N})\\) queries to the database, offering a quadratic speedup over classical search. The key idea is to use a quantum oracle to mark the target item and then apply a diffusion operator to amplify the probability of measuring the target. We can understand the power of Grover’s algorithm by considering the geometric interpretation of the oracle and diffusion operators as rotations on a Bloch sphere.\n\n4.6.1 The Unstructured Search Problem\nSuppose we have a function \\(f(x)\\) that takes an input \\(x\\) from a set of \\(N\\) items, where \\(f(x) = 1\\) if \\(x\\) is the item we are searching for (the “target”) and \\(f(x) = 0\\) otherwise. Our goal is to find the value of \\(x\\) such that \\(f(x) = 1\\). Classically, in the worst case, we might have to check every item in the database, requiring \\(O(N)\\) queries.\n\n\n\n\n\n\nRelating number of elements to qubits\n\n\n\nFor a database of \\(N\\) items, the number of qubits required to represent each item is \\(n = \\lceil \\log_2 N \\rceil\\).\n\n\n\n\n4.6.2 Quantum Oracle\nThe quantum oracle, \\(O\\), is a unitary operator that marks the target state. If the target state is \\(|w\\rangle\\), the oracle acts as:\n\\[\nO|x\\rangle = \\begin{cases}\n-|x\\rangle & \\text{if } x = w \\\\\n|x\\rangle & \\text{if } x \\neq w\n\\end{cases}\n\\]\nThis can be written more generally as \\(O = I - 2|w\\rangle\\langle w|\\), where \\(I\\) is the identity operator. Geometrically, the oracle \\(O\\) reflects the state about the hyperplane orthogonal to \\(|w\\rangle\\).\n\n\n4.6.3 The Diffusion Operator\nThe diffusion operator, \\(D\\), is defined as:\n\\[\nD = 2|\\psi\\rangle\\langle\\psi| - I\n\\]\nwhere \\(|\\psi\\rangle\\) is the uniform superposition over all states:\n\\[\n|\\psi\\rangle = \\frac{1}{\\sqrt{N}} \\sum_{x=0}^{N-1} |x\\rangle\n\\]\nThe diffusion operator \\(D\\) reflects the state about the mean amplitude.\n\n\n\n\n\n\nDemystifying the Grover Diffusion Operator: “Inversion About the Mean”\n\n\n\nThe Grover diffusion operator (\\(D = 2|\\psi\\rangle\\langle\\psi| - I\\)) might seem mysterious, but it’s essentially an “inversion about the mean” of the amplitudes. Here’s how to think about it:\n\nCalculate the Mean Amplitude: Imagine all the amplitudes of the quantum states as numbers. Calculate the average (mean) of these numbers. Since we start with a uniform superposition, this mean is initially close to zero.\nInvert Around the Mean: For each state’s amplitude:\n\nCalculate the difference between the amplitude and the mean.\nSubtract this difference again from the mean. This “inverts” the amplitude around the mean. Mathematically, if \\(a_i\\) is the amplitude of state \\(\\ket{i}\\) and \\(\\bar{a}\\) is the mean amplitude, the new amplitude \\(a_i'\\) is calculated as: \\[a_i' = \\bar{a} - (a_i - \\bar{a}) = 2\\bar{a} - a_i\\]\n\n\nVisual Analogy: Imagine a seesaw balanced at the mean amplitude (\\(\\bar{a}\\)). The diffusion operator flips each amplitude to the opposite side of the seesaw, relative to the balance point. This has the effect of decreasing the amplitudes of the majority of states and increasing the amplitude of the marked state(s).\nWhy this works: The marked state gets a larger “boost” because its amplitude is initially negative (due to the oracle’s phase flip), making it lower than the mean. This process, repeated multiple times, amplifies the marked state until it dominates the superposition.\n\n\n\n\n4.6.4 Grover Iteration as a Rotation\nThe Grover iteration \\(G = D \\cdot O\\) can be understood as a rotation within the two-dimensional subspace spanned by the target state \\(|w\\rangle\\) and the superposition of non-target states. Let’s define \\(|\\psi_\\perp\\rangle\\) as the normalized superposition of all states orthogonal to the target state \\(|w\\rangle\\). If the uniform superposition is \\(|\\psi\\rangle = \\frac{1}{\\sqrt{N}} \\sum_{x=0}^{N-1} |x\\rangle\\) and the target state is \\(|w\\rangle\\), we can express \\(|\\psi\\rangle\\) in terms of \\(|w\\rangle\\) and \\(|\\psi_\\perp\\rangle\\). \\[\n\\ket{\\psi} =  \\frac1{\\sqrt{N}}\\ket{w} + \\sqrt{1-\\frac1N}\\ket{\\psi_\\perp}.\n\\] Notice that there is a low chance \\(1/N\\) of getting \\(w\\) from this wavefunction as it currently stands.\nIn the basis \\(\\{|\\psi_\\perp\\rangle, |w\\rangle\\}\\), the Grover operator \\(G\\) takes the form of a rotation matrix:\n\\[\nG = \\begin{bmatrix}\n1 - \\frac{2}{N} & \\frac{2\\sqrt{N-1}}{N} \\\\\n-\\frac{2\\sqrt{N-1}}{N} & 1 - \\frac{2}{N}\n\\end{bmatrix}\n\\] This matrix represents a rotation by an unknown angle \\(\\theta\\) on the Bloch sphere. If we let \\(\\sin(\\theta/2) = \\frac{2\\sqrt{N-1}}{N}\\), then \\[\nG = \\begin{bmatrix} \\cos(\\theta/2) & \\sin(\\theta/2) \\\\ -\\sin(\\theta/2) & \\cos(\\theta/2) \\end{bmatrix}\n\\] The goal is to rotate the initial state \\(|\\psi\\rangle\\) as close as possible to the target state \\(|w\\rangle\\). After \\(k\\) iterations, the state is:\n\\[\nG^k |\\psi_\\perp\\rangle = \\cos(k\\theta/2) |\\psi_\\perp \\rangle + \\sin(k\\theta/2) |w\\rangle\n\\]\nTo maximize the probability of measuring \\(|w\\rangle\\), we want \\(\\sin(k\\theta)\\) to be as close to 1 as possible, which means \\(k\\theta \\approx \\pi\\).\nSince \\(\\sin(\\theta/2) = \\frac{2\\sqrt{N-1}}{N} \\approx \\frac{2\\sqrt{N}}{N} = \\frac{2}{\\sqrt{N}}\\) for large \\(N\\), we have \\(\\theta/2 \\approx \\frac{2}{\\sqrt{N}}\\), so \\(\\theta \\approx \\frac{4}{\\sqrt{N}}\\).\nTherefore, \\(k \\approx \\frac{\\pi}{\\theta} \\approx \\frac{\\pi}{4} \\sqrt{N}\\).\nThus, the optimal number of iterations is approximately \\(\\frac{\\pi}{4} \\sqrt{N}\\).\n\n\n4.6.5 Measurement\nAfter applying the Grover iteration approximately \\(\\frac{\\pi}{4} \\sqrt{N}\\) times, measuring the state will yield the target state \\(|w\\rangle\\) with high probability.\n\n\n4.6.6 Quantum Speedup\nGrover’s algorithm achieves a quadratic speedup compared to classical search. While a classical search requires \\(O(N)\\) queries in the worst case, Grover’s algorithm finds the target with \\(O(\\sqrt{N})\\) quantum queries. This speedup demonstrates the power of quantum computation for solving search problems.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quantum Computing Algorithms</span>"
    ]
  },
  {
    "objectID": "basic_algorithms.html#shors-algorithm-high-level-overview",
    "href": "basic_algorithms.html#shors-algorithm-high-level-overview",
    "title": "4  Quantum Computing Algorithms",
    "section": "4.7 Shor’s Algorithm (High-Level Overview)",
    "text": "4.7 Shor’s Algorithm (High-Level Overview)\nShor’s algorithm is a quantum algorithm for factoring large integers  [6]. It has exponential speedup compared to the best-known classical factoring algorithm. Factoring large numbers is a computationally hard problem that underlies the security of many public-key cryptosystems, such as RSA. Shor’s algorithm combines classical number theory with quantum computation to efficiently find the prime factors of an integer.\nThe algorithm consists of two main parts:\n\nClassical Pre-processing: This involves reducing the factoring problem to the problem of finding the period of a function. This step leverages number-theoretic results but is executed on a classical computer.\nQuantum Period Finding: This is the core quantum part of the algorithm. It uses the quantum Fourier transform (QFT) to efficiently find the period of the function defined in the classical pre-processing step. The quantum period finding provides an exponential speedup compared to classical period-finding algorithms.\nClassical Post-processing: Once the period is found using the quantum computation, a classical computer performs some post-processing steps, using number theory, to deduce the factors of the original integer.\n\nThe quantum part of Shor’s algorithm relies on the following key quantum computing concepts:\n\nQuantum Fourier Transform (QFT): The QFT is used to find the period of a function by identifying the dominant frequencies in its Fourier transform. The QFT can be implemented efficiently on a quantum computer.\nSuperposition: Superposition is used to evaluate the function at multiple points simultaneously.\nQuantum Measurement: Measurement is used to extract the period information from the quantum state.\n\nIn summary, Shor’s algorithm leverages the QFT to perform period finding exponentially faster than any known classical algorithm, which allows us to factor large integers efficiently. The combination of classical pre- and post-processing with the quantum period-finding routine makes Shor’s algorithm a powerful tool with significant implications for cryptography.\n\n4.7.1 Quantum Period Finding in Shor’s Algorithm\nThe quantum period-finding algorithm is the heart of Shor’s algorithm, providing the exponential speedup over classical methods. Here’s a breakdown of how it works:\n\nProblem Setup: We are given an integer \\(N\\) that we want to factor. We choose a random number \\(a\\) such that \\(1 &lt; a &lt; N\\) and \\(\\text{gcd}(a, N) = 1\\). We define a function \\(f(x) = a^x \\mod N\\). The goal is to find the period \\(r\\) of this function, which is the smallest positive integer such that \\(f(x + r) = f(x)\\) for all \\(x\\). In other words, \\(a^r \\equiv 1 \\pmod{N}\\).\nQuantum Registers: We use two quantum registers:\n\nRegister 1 (input register): This register consists of \\(n\\) qubits, where \\(n\\) is chosen such that \\(N^2 \\le 2^n &lt; 2N^2\\). This register will hold the input values \\(x\\) for the function \\(f(x)\\). It is initialized to \\(\\ket{0}^{\\otimes n}\\).\nRegister 2 (output register): This register consists of \\(m\\) qubits, where \\(m\\) is large enough to store the possible values of \\(f(x)\\). It is initialized to \\(\\ket{0}^{\\otimes m}\\).\n\nSuperposition: Apply a Hadamard gate to each qubit in Register 1 to create an equal superposition of all possible input values:\n\\[\n\\ket{\\psi_0} = \\frac{1}{\\sqrt{2^n}} \\sum_{x=0}^{2^n-1} \\ket{x} \\ket{0}^{\\otimes m}\n\\]\nFunction Evaluation (Quantum Oracle): Apply a quantum oracle \\(U_f\\) that performs the modular exponentiation: \\(\\ket{x}\\ket{0} \\rightarrow \\ket{x}\\ket{f(x)}\\). This creates the entangled state:\n\\[\n\\ket{\\psi_1} = \\frac{1}{\\sqrt{2^n}} \\sum_{x=0}^{2^n-1} \\ket{x} \\ket{f(x)}\n\\]\nQuantum Fourier Transform (QFT): Apply the QFT to Register 1. This transforms the state as follows:\n\\[\n\\ket{\\psi_2} = \\frac{1}{\\sqrt{2^n}} \\sum_{x=0}^{2^n-1} \\left( \\frac{1}{\\sqrt{2^n}} \\sum_{y=0}^{2^n-1} e^{2\\pi i xy / 2^n} \\ket{y} \\right) \\ket{f(x)}\n\\]\nRearranging the summation, we get:\n\\[\n\\ket{\\psi_2} = \\frac{1}{2^n} \\sum_{y=0}^{2^n-1} \\sum_{x=0}^{2^n-1} e^{2\\pi i xy / 2^n} \\ket{y} \\ket{f(x)}\n\\]\nMeasurement: Measure Register 2. This collapses the superposition to a specific value \\(f(x_0)\\). The state of Register 1 becomes a superposition of states \\(|x\\rangle\\) such that \\(f(x) = f(x_0)\\). Since \\(f(x)\\) is periodic with period \\(r\\), the register 1 will contain a superposition of states \\(|x_0\\rangle, |x_0 + r\\rangle, |x_0 + 2r\\rangle, ...\\)\nSecond Measurement: Measure Register 1. The measurement result \\(y\\) will be close to an integer multiple of \\(2^n/r\\). That is, \\(y \\approx c \\cdot \\frac{2^n}{r}\\) for some integer \\(c\\).\nClassical Post-processing (Continued Fractions): Use the continued fractions algorithm to find the best rational approximation of \\(y/2^n\\). This gives us a candidate for the period \\(r\\).\nVerification: Check if the candidate \\(r\\) is indeed the period by verifying that \\(a^r \\equiv 1 \\pmod{N}\\). If it is not, repeat the algorithm.\nFactoring: If \\(r\\) is even, compute \\(\\text{gcd}(a^{r/2} + 1, N)\\) and \\(\\text{gcd}(a^{r/2} - 1, N)\\). These are likely to be non-trivial factors of \\(N\\). If the factors are trivial or \\(r\\) is odd, go back to step 1 and choose a different random \\(a\\).\n\nThe QFT step is crucial because it transforms the periodic function \\(f(x)\\) into a state where the period can be efficiently extracted through measurement and classical post-processing. The exponential speedup arises from the ability of the QFT to identify the period in a single quantum computation, whereas classical period-finding algorithms would require exponentially many evaluations of the function.\n\n\n\n\n\n\nWhy Modular Exponentiation?\n\n\n\nModular exponentiation (computing \\(a^x \\mod N\\)) is crucial because:\n\nIt’s periodic: For some period \\(r\\), \\(a^{x+r} \\equiv a^x \\pmod{N}\\)\nThis period \\(r\\) is related to the factors of \\(N\\)\nThe quantum computer can find \\(r\\) efficiently using the Quantum Fourier Transform (QFT)\n\nKey insight: We don’t need to know all values of \\(a^x \\mod N\\), we just need to find how often they repeat!\nExample: For \\(N = 15\\), \\(a = 7\\)\n\n\\(7^1 \\mod 15 = 7\\)\n\\(7^2 \\mod 15 = 4\\)\n\\(7^3 \\mod 15 = 13\\)\n\\(7^4 \\mod 15 = 1\\) ← Period found!",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quantum Computing Algorithms</span>"
    ]
  },
  {
    "objectID": "basic_algorithms.html#hhl-algorithm",
    "href": "basic_algorithms.html#hhl-algorithm",
    "title": "4  Quantum Computing Algorithms",
    "section": "4.8 HHL Algorithm",
    "text": "4.8 HHL Algorithm\nThe HHL algorithm, named after Harrow, Hassidim, and Lloyd, is a quantum algorithm that solves linear systems of equations  [7]. Given a matrix \\(A\\) and a vector \\(\\vec{b}\\), the goal is to find the vector \\(\\vec{x}\\) such that \\(A\\vec{x} = \\vec{b}\\). While solving linear systems is a ubiquitous task in classical computing, the HHL algorithm offers a potential exponential speedup under certain conditions, making it a landmark result in quantum algorithm design.\n\n4.8.1 The Linear Systems Problem\nIn its most general form, a linear system of equations is represented as:\n\\[\nA\\vec{x} = \\vec{b}\n\\]\nwhere:\n\n\\(A\\) is an \\(N \\times N\\) matrix.\n\\(\\vec{x}\\) is an \\(N\\)-dimensional vector we want to find.\n\\(\\vec{b}\\) is an \\(N\\)-dimensional vector.\n\nClassically, solving this problem typically requires \\(O(N^3)\\) time using Gaussian elimination or \\(O(N^{2.373})\\) using more advanced algorithms. For large \\(N\\), these algorithms can be computationally expensive.\n\n\n4.8.2 Quantum Solution Approach\nThe HHL algorithm provides a quantum solution to this problem with a runtime complexity of \\(O(\\text{log}(N))\\), under certain assumptions. Here’s a high-level overview of the algorithm:\n\nState Preparation: The input vector \\(\\vec{b}\\) is loaded into a quantum state \\(|\\vec{b}\\rangle\\). This step assumes that we have a way to efficiently prepare the state, which is a crucial requirement for the algorithm’s speedup.\nHamiltonian Simulation: The matrix \\(A\\) is represented as a Hamiltonian, and we perform Hamiltonian simulation to implement the time evolution operator \\(e^{iAt}\\) for some time \\(t\\). This step requires \\(A\\) to be Hermitian. If \\(A\\) is not Hermitian, it can be transformed into a Hermitian matrix by considering the augmented system:\n\\[\n\\begin{bmatrix}\n0 & A \\\\\nA^\\dagger & 0\n\\end{bmatrix}\n\\]\nQuantum Phase Estimation (QPE): QPE is applied to estimate the eigenvalues of \\(A\\). This involves applying the time evolution operator \\(e^{iAt}\\) multiple times and using the quantum Fourier transform to extract the eigenvalues. The result is a quantum state where the eigenvalues are stored in a separate register.\nControlled Rotation: A controlled rotation is performed based on the estimated eigenvalues. This rotation effectively multiplies each eigenvector component by the inverse of its corresponding eigenvalue.\nUncomputation: The QPE is uncomputed to remove the eigenvalue register, leaving the solution in the original register.\nMeasurement: Finally, we measure the quantum state to obtain the solution vector \\(\\vec{x}\\).\n\n\n\n4.8.3 Mathematical Details\nLet’s break down the key steps with some mathematical details:\n\nEigenvalue Decomposition: Assume \\(A\\) is Hermitian and has the eigenvalue decomposition:\n\\[\nA = \\sum_{j=1}^N \\lambda_j |u_j\\rangle \\langle u_j|\n\\]\nwhere \\(\\lambda_j\\) are the eigenvalues and \\(|u_j\\rangle\\) are the corresponding eigenvectors.\nInput State: The input state \\(|\\vec{b}\\rangle\\) can be expressed in terms of the eigenvectors of \\(A\\):\n\\[\n|\\vec{b}\\rangle = \\sum_{j=1}^N b_j |u_j\\rangle\n\\]\nwhere \\(b_j = \\langle u_j | \\vec{b} \\rangle\\) are the coefficients.\nSolution State: The solution vector \\(\\vec{x}\\) can also be expressed in terms of the eigenvectors:\n\\[\n|\\vec{x}\\rangle = A^{-1} |\\vec{b}\\rangle = \\sum_{j=1}^N \\frac{b_j}{\\lambda_j} |u_j\\rangle\n\\]\nThe goal of the HHL algorithm is to prepare this state \\(|\\vec{x}\\rangle\\).\nQuantum Phase Estimation: QPE allows us to estimate the eigenvalues \\(\\lambda_j\\). After QPE, we have a state like:\n\\[\n\\sum_{j=1}^N b_j |\\lambda_j\\rangle |u_j\\rangle\n\\]\nwhere \\(|\\lambda_j\\rangle\\) is a quantum register holding an estimate of the eigenvalue \\(\\lambda_j\\).\nControlled Rotation: We then perform a controlled rotation. This rotation is applied to an ancilla qubit conditioned on the estimated eigenvalue \\(|\\lambda_j\\rangle\\). The state becomes:\n\\[\n\\sum_{j=1}^N b_j |\\lambda_j\\rangle \\left( C \\frac{1}{\\lambda_j} |0\\rangle + S |1\\rangle \\right) |u_j\\rangle\n\\]\nHere, \\(|0\\rangle\\) and \\(|1\\rangle\\) represent the states of the ancilla qubit, and \\(C\\) and \\(S\\) are chosen such that \\(C^2/\\lambda_j^2 + S^2 = 1\\), ensuring normalization. The crucial point is that the amplitude of the \\(|0\\rangle\\) state is proportional to \\(1/\\lambda_j\\). Measuring the ancilla qubit in the \\(|0\\rangle\\) state projects the system (approximately) onto the desired solution:\n\\[\n\\sum_{j=1}^N \\frac{b_j}{\\lambda_j} |u_j\\rangle \\propto |\\vec{x}\\rangle\n\\]\n\n\n\n4.8.4 Assumptions and Limitations\nThe HHL algorithm’s exponential speedup comes with several caveats:\n\nSparse Matrix: The matrix \\(A\\) must be sparse, meaning it has a small number of non-zero elements per row. This is necessary for efficient Hamiltonian simulation.\nState Preparation: Efficiently preparing the input state \\(|\\vec{b}\\rangle\\) is crucial. If this step is classically hard, the overall algorithm will not provide a speedup.\nCondition Number: The condition number of \\(A\\), denoted as \\(\\kappa(A)\\), affects the algorithm’s runtime. A large condition number indicates that \\(A\\) is ill-conditioned, which can lead to numerical instability and increased runtime. The complexity scales as \\(O(\\kappa \\text{log}(N))\\).\nLogarithmic Dependence: The algorithm’s runtime depends logarithmically on the size of the system, \\(N\\). This is where the exponential speedup comes from compared to classical algorithms that scale polynomially with \\(N\\). However, the logarithmic speedup is only advantageous for sufficiently large \\(N\\).\nOutput: The HHL algorithm outputs a quantum state \\(|\\vec{x}\\rangle\\), not the explicit values of the solution vector \\(\\vec{x}\\). Extracting specific elements of \\(\\vec{x}\\) requires additional measurements, which can affect the overall runtime.\n\n\n\n4.8.5 Applications\nDespite its limitations, the HHL algorithm has potential applications in various fields:\n\nFinite Element Analysis: Solving partial differential equations using finite element methods often involves solving large, sparse linear systems.\nFluid Dynamics: Simulating fluid flow can require solving linear systems to determine the velocity and pressure fields.\nCircuit Analysis: Analyzing electrical circuits involves solving linear systems to determine the currents and voltages in the circuit.\nMachine Learning: Some machine learning algorithms, such as linear regression and support vector machines, involve solving linear systems.\n\n\n\n4.8.6 Conclusion\nThe HHL algorithm  [7] is a significant achievement in quantum algorithm design, demonstrating the potential for exponential speedups in solving linear systems of equations. While it has limitations and requires specific conditions to be met, it opens up new possibilities for tackling computationally challenging problems in science and engineering. Understanding its assumptions and limitations is crucial for assessing its applicability to specific problems and for developing future quantum algorithms that can overcome these challenges.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quantum Computing Algorithms</span>"
    ]
  },
  {
    "objectID": "basic_algorithms.html#hybrid-quantum-classical-algorithms",
    "href": "basic_algorithms.html#hybrid-quantum-classical-algorithms",
    "title": "4  Quantum Computing Algorithms",
    "section": "4.9 Hybrid Quantum-Classical Algorithms",
    "text": "4.9 Hybrid Quantum-Classical Algorithms\n\n4.9.1 Variational Quantum Eigensolver (VQE)\nThe Variational Quantum Eigensolver (VQE) is a hybrid quantum-classical algorithm used to find the ground state (minimum energy) of a quantum system. Many problems in quantum chemistry, materials science, and condensed matter physics involve finding the ground state energy of a molecule or material, which is classically intractable for large systems. VQE leverages a quantum computer to prepare a trial wave function (called an “ansatz”) \\(|\\psi(\\theta)\\rangle\\) and measure its energy \\(\\langle \\psi(\\theta) | H | \\psi(\\theta) \\rangle\\), where \\(H\\) is the Hamiltonian of the system, and \\(\\theta\\) represents a set of adjustable parameters. A classical optimization algorithm then adjusts the parameters \\(\\theta\\) of the ansatz to minimize the energy. The key idea is to variationally find the eigenvector corresponding to the smallest eigenvalue, which represents the ground state.\n\n\n4.9.2 Quantum Approximate Optimization Algorithm (QAOA)\nThe Quantum Approximate Optimization Algorithm (QAOA) is another hybrid quantum-classical algorithm designed to find approximate solutions to combinatorial optimization problems. These are problems where the goal is to find the best solution from a finite set of possibilities (e.g., the traveling salesman problem, graph partitioning). QAOA uses a quantum computer to explore the solution space and a classical computer to optimize the parameters that control the quantum evolution. The algorithm alternates between applying operators related to the problem’s cost function and a mixing operator, with the goal of converging to a state that encodes a good solution. Like VQE, QAOA relies on variational techniques, where the parameters of a quantum circuit are optimized using classical methods.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quantum Computing Algorithms</span>"
    ]
  },
  {
    "objectID": "basic_algorithms.html#overview-and-comparison-with-classical",
    "href": "basic_algorithms.html#overview-and-comparison-with-classical",
    "title": "4  Quantum Computing Algorithms",
    "section": "4.10 Overview and comparison with classical",
    "text": "4.10 Overview and comparison with classical\nHere’s a table summarizing the classical and quantum complexities of the algorithms discussed, along with whether they are deterministic or probabilistic. These can all be more precisely defined by number of gates and other factors not mentioned here, for more details see the Quantum Algorithm Zoo:\n\n\n\n\n\n\n\n\n\n\nAlgorithm\nClassical Complexity (Deterministic)\nClassical Complexity (Probabilistic)\nQuantum Complexity\nDeterministic or Probabilistic\n\n\n\n\nDeutsch’s Algorithm\n2 queries\nN/A\n1 query\nDeterministic\n\n\nDeutsch-Jozsa Algorithm\n\\(\\mathcal{O}(2^{n-1})\\)\n1 query\n\\(\\mathcal{O}(1)\\)\nDeterministic\n\n\nBernstein-Vazirani Algorithm\nn queries\nN/A\n1 query\nDeterministic\n\n\nSimon’s Algorithm\n\\(\\mathcal{O}(2^{n/2})\\)\nN/A\n\\(\\mathcal{O}(n)\\)\nProbabilistic\n\n\nQuantum Phase Estimation (QPE)\nExponential (worst-case)\nExponential (worst-case)\n\\(\\mathcal{O}(m)\\) controlled operations for m bits\nProbabilistic\n\n\nGrover’s Algorithm\n\\(\\mathcal{O}(N)\\)\nN/A\n\\(\\mathcal{O}(\\sqrt{N})\\)\nProbabilistic\n\n\nShor’s Algorithm\n\\(\\mathcal{O}(\\text{exp}(N))\\)\n\\(\\mathcal{O}(\\text{exp}(N))\\)\n\\(\\mathcal{O}(\\text{poly}(N))\\)\nProbabilistic\n\n\nHHL Algorithm\n\\(\\mathcal{O}(N^3)\\) or \\(\\mathcal{O}(N^\\omega)\\)\nN/A\n\\(\\mathcal{O}(\\text{log}(N))\\)\nProbabilistic\n\n\n\nNotes:\n\nN: Input size (e.g., number of items in a database for Grover’s, number to be factored for Shor’s, dimension of the matrix for HHL).\nn: Number of qubits.\nt: Number of qubits in the control register for QPE, related to desired accuracy.\nexp(N): Exponential in N.\npoly(N): Polynomial in N.\nHHL Conditions: The HHL algorithm’s exponential speedup is contingent on several factors: the matrix \\(A\\) being sparse, efficient state preparation of \\(\\ket{b}\\), and a low condition number.\nProbabilistic vs. Deterministic: Deterministic algorithms always produce the correct answer. Probabilistic algorithms have a chance of error, but the probability of error can be made arbitrarily small by repeating the algorithm.\nSpeedup: This column indicates the type of speedup the quantum algorithm offers compared to the best-known classical algorithm.\n\nThis table provides a general overview. The precise complexities and speedups can vary depending on the specific implementation and problem instance.\n\n\n\n\n[1] D. Deutsch, Quantum theory, the Church–Turing principle and the universal quantum computer, Proceedings of the Royal Society of London. A. Mathematical and Physical Sciences 400, 97 (1985).\n\n\n[2] D. Deutsch and R. Jozsa, Rapid solution of problems by quantum computation, Proceedings of the Royal Society of London. Series A: Mathematical and Physical Sciences 439, 553 (1992).\n\n\n[3] E. Bernstein and U. Vazirani, Quantum Complexity Theory, SIAM Journal on Computing 26, 1411 (1997).\n\n\n[4] D. R. Simon, On the Power of Quantum Computation, SIAM Journal on Computing 26, 1474 (1997).\n\n\n[5] L. K. Grover, A Fast Quantum Mechanical Algorithm for Database Search, in Proceedings of the Twenty-Eighth Annual ACM Symposium on Theory of Computing - STOC ’96 (ACM Press, Philadelphia, Pennsylvania, United States, 1996), pp. 212–219.\n\n\n[6] P. W. Shor, Algorithms for Quantum Computation: Discrete Logarithms and Factoring, in Proceedings 35th Annual Symposium on Foundations of Computer Science (IEEE Comput. Soc. Press, Santa Fe, NM, USA, 1994), pp. 124–134.\n\n\n[7] A. W. Harrow, A. Hassidim, and S. Lloyd, Quantum Algorithm for Linear Systems of Equations, Physical Review Letters 103, 150502 (2009).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quantum Computing Algorithms</span>"
    ]
  },
  {
    "objectID": "interlude.html",
    "href": "interlude.html",
    "title": "Interlude: Hardwire requirements",
    "section": "",
    "text": "DiVincenzo’s Criteria for Quantum Computation\nBefore we hop into the platforms where we might be able to perform these algorithms to solve problems, we need to specify what we want.\nIn 2000, David DiVincenzo outlined a set of criteria  [1] that any physical system must meet to be considered a viable quantum computer. These criteria serve as a benchmark for evaluating different quantum computing platforms and guiding research efforts. The criteria can be summarized as follows:\nIn addition to these five criteria, DiVincenzo also proposed two criteria for quantum communication:\nMeeting these criteria is a significant challenge, and different quantum computing platforms are at various stages of development with respect to each criterion. Superconducting qubits, trapped ions, neutral atoms, quantum dots, and topological qubits are among the leading candidates for building practical quantum computers. Each platform has its own strengths and weaknesses, and ongoing research is focused on overcoming the challenges associated with each approach  [2].",
    "crumbs": [
      "Interlude: Hardwire requirements"
    ]
  },
  {
    "objectID": "interlude.html#divincenzos-criteria-for-quantum-computation",
    "href": "interlude.html#divincenzos-criteria-for-quantum-computation",
    "title": "Interlude: Hardwire requirements",
    "section": "",
    "text": "Scalable qubits: A practical quantum computer must be able to scale to a large number of qubits. The number of qubits required depends on the complexity of the problem being solved, but fault-tolerant quantum computation generally requires thousands or even millions of qubits.\nInitialization: The ability to initialize the qubits to a known state, such as \\(\\ket{0}^{\\otimes n}\\), is crucial. This provides a well-defined starting point for quantum algorithms.\nLong coherence times: Qubits must maintain their quantum coherence for a sufficiently long time to allow complex quantum operations to be performed. Decoherence, the loss of quantum information to the environment, is a major obstacle to quantum computation. Coherence times must be much longer than the gate operation times.\nUniversal gate set: A universal set of quantum gates is required to perform arbitrary quantum computations. A universal gate set is a small set of gates that can be combined to approximate any other quantum gate. Examples include the Hadamard gate, the CNOT gate, and single-qubit rotation gates.\nMeasurement: The ability to accurately measure the state of the qubits is essential for extracting the results of a quantum computation. Measurements must be reliable and have high fidelity.\n\n\n\nInterconvertible quantum and classical bits: The ability to convert quantum information into classical information and vice versa is important for interfacing with classical computers and communication networks.\nFaithful transmission of qubits: The ability to transmit qubits reliably between different locations is essential for building distributed quantum computers and quantum networks.",
    "crumbs": [
      "Interlude: Hardwire requirements"
    ]
  },
  {
    "objectID": "interlude.html#measurement-based-quantum-computation",
    "href": "interlude.html#measurement-based-quantum-computation",
    "title": "Interlude: Hardwire requirements",
    "section": "Measurement-Based Quantum Computation",
    "text": "Measurement-Based Quantum Computation\nIt’s worth noting that some quantum computing platforms employ a different paradigm called measurement-based quantum computation (MBQC). Unlike the gate-based approach we’ve primarily discussed, MBQC relies on creating a highly entangled resource state, often a cluster state, and then performing computation by making a series of single-qubit measurements. The specific measurements performed and their order determine the quantum algorithm being executed. While the underlying physics and qubit requirements are similar, the programming and control aspects of MBQC differ significantly from gate-based quantum computation.",
    "crumbs": [
      "Interlude: Hardwire requirements"
    ]
  },
  {
    "objectID": "interlude.html#magic-state-distillation",
    "href": "interlude.html#magic-state-distillation",
    "title": "Interlude: Hardwire requirements",
    "section": "Magic State Distillation",
    "text": "Magic State Distillation\nAchieving a universal gate set is crucial for implementing arbitrary quantum algorithms. While some quantum computing platforms can directly implement a universal gate set, others have a limited set of native gates. In such cases, additional resources and techniques are required to achieve universality. One common approach is to use magic state distillation.\n\nThe Need for Magic States\nA restricted gate set, such as those that are Clifford gates, can perform a limited set of quantum computations efficiently. Clifford gates consist of Hadamard, CNOT, and phase gates. The Gottesman-Knill theorem states that quantum circuits consisting only of Clifford gates, preparation of computational basis states (e.g., \\(\\ket{0}\\)), and measurement in the computational basis can be efficiently simulated on a classical computer. Therefore, to achieve true quantum supremacy, we need non-Clifford gates.\nMagic state distillation is a technique used to create high-fidelity magic states, which can then be used along with Clifford gates to implement non-Clifford gates, such as the \\(T\\) gate (also known as the \\(\\pi/8\\) gate). The \\(T\\) gate adds a phase of \\(\\pi/4\\) to the \\(\\ket{1}\\) state:\n\\[\nT = \\begin{pmatrix}\n1 & 0 \\\\\n0 & e^{i\\pi/4}\n\\end{pmatrix}\n\\]\nA magic state, often denoted as \\(\\ket{A}\\), is a specific quantum state that, when combined with Clifford gates through a process called state injection, allows for the implementation of non-Clifford gates.\nBy adding the T gate to the Clifford gates, we obtain a universal gate set.\n\n\nResource Overhead and Error Correction\nMagic state distillation introduces significant resource overhead in terms of the number of physical qubits and quantum gates required. Generating high-fidelity magic states is a computationally intensive process, often requiring multiple rounds of distillation and significant post-selection to obtain the desired fidelity. This overhead can be a limiting factor in the overall performance and scalability of quantum algorithms.\nFurthermore, magic state distillation is often intertwined with quantum error correction. Since the distillation process itself is susceptible to errors, robust error correction schemes are necessary to protect the fragile quantum information during distillation. The interplay between magic state distillation and error correction adds another layer of complexity and resource requirements.\nDespite these challenges, for many quantum computing platforms with restricted native gate sets, magic state distillation remains the most viable path to achieving universality and unlocking the full potential of fault-tolerant quantum computation. Ongoing research focuses on developing more efficient distillation protocols and error correction codes to reduce the resource overhead and improve the overall performance of quantum algorithms.\n\n\n\n\n[1] D. P. DiVincenzo, Topics in Quantum Computers, in Mesoscopic Electron Transport, edited by L. L. Sohn, L. P. Kouwenhoven, and G. Schön (Springer Netherlands, Dordrecht, 1997), pp. 657–677.\n\n\n[2] N. P. De Leon, K. M. Itoh, D. Kim, K. K. Mehta, T. E. Northup, H. Paik, B. S. Palmer, N. Samarth, S. Sangtawesin, and D. W. Steuerman, Materials challenges and opportunities for quantum computing hardware, Science 372, eabb2823 (2021).",
    "crumbs": [
      "Interlude: Hardwire requirements"
    ]
  },
  {
    "objectID": "superconducting_qubits.html",
    "href": "superconducting_qubits.html",
    "title": "5  Superconducting qubits",
    "section": "",
    "text": "5.1 What are superconducting qubits?\nSuperconducting qubits represent one of the most promising and widely pursued platforms for quantum computing. These qubits leverage the unique properties of superconducting circuits to create controllable quantum systems to realize the quantum computing ideas we’ve explored in previous chapters.\nSuperconducting qubits are artificial quantum systems built from electrical circuits that include Josephson junctions - superconducting materials separated by a thin insulating barrier. When cooled to extremely low temperatures (typically below 100 mK), these circuits exhibit quantum behavior, allowing them to serve as qubits.\nUnlike natural quantum systems such as atoms or ions, superconducting qubits are macroscopic objects - their physical dimensions can be on the order of hundreds of micrometers, making them visible to the naked eye. This macroscopic nature offers both advantages and challenges: they can be fabricated using modified integrated circuit technology, but are also more susceptible to environmental noise and decoherence.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Superconducting qubits</span>"
    ]
  },
  {
    "objectID": "superconducting_qubits.html#what-are-superconducting-qubits",
    "href": "superconducting_qubits.html#what-are-superconducting-qubits",
    "title": "5  Superconducting qubits",
    "section": "",
    "text": "5.1.1 Types of superconducting qubits\nThere are several varieties of superconducting qubits, each with distinct characteristics and enabled by the amount of control these circuits have:\n\nTransmon qubits: A modified charge qubit designed to reduce sensitivity to charge noise, currently the most widely used superconducting qubit design.\nFlux qubits: Encode information in the direction of current flow, offering high anharmonicity.\n\nOther designs include fluxonium and 0-\\(\\pi\\) qubits.\nIn this chapter, we’ll explore how these qubits work, how they’re controlled and measured, and how they implement the abstract quantum operations we’ve studied in previous chapters. We’ll particularly focus on the transmon qubit, which has become the workhorse of many superconducting quantum processors due to its improved coherence properties.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Superconducting qubits</span>"
    ]
  },
  {
    "objectID": "superconducting_qubits.html#from-electric-circuits-to-a-quantum-harmonic-oscillator",
    "href": "superconducting_qubits.html#from-electric-circuits-to-a-quantum-harmonic-oscillator",
    "title": "5  Superconducting qubits",
    "section": "5.2 From electric circuits to a quantum harmonic oscillator",
    "text": "5.2 From electric circuits to a quantum harmonic oscillator\nOne of the key insights to develop our superconducting qubit is to make a connection with LC circuits and the harmonic oscillator. This allows us to develop out the quantum version of these circuits which we can explore in detail.\n\n5.2.1 The LC circuit\n\n\n\n\nA simple LC circuit showing the inductor L, capacitor C, and their respective voltage drops.\n\n\nConsider a simple LC circuit composed of an inductor \\(L\\) and a capacitor \\(C\\). Suppose we start by giving the capacitor some initial charge \\(Q_0\\). This initial charge causes a voltage across the capacitor plates, given approximately by \\(V_C = \\tfrac{Q}{C}\\). With time, this charge flows through the inductor; as current builds, it creates a magnetic field in the inductor, thereby storing energy in that field. Eventually, the capacitor’s voltage nears zero (the capacitor becomes discharged), but the current through the inductor continues due to its stored magnetic energy. This current then recharges the capacitor in the opposite polarity, and the energy flows between the capacitor’s electric field and the inductor’s magnetic field.\nThis back-and-forth exchange of energy repeats, creating an oscillation—just like a mass on a spring. In an LC circuit, the voltage drop across the inductor (given by \\(L dI/dt\\)) must match the voltage on the capacitor (\\(Q/C\\)). By summing these drops to zero around the loop, we arrive at the differential equation \\[\nL \\frac{dI}{dt} + \\frac{Q}{C} = 0,\n\\] where \\(I = \\tfrac{dQ}{dt}\\). Switching from the capacitor’s charge to an analogous “position” variable (the charge \\(Q\\)) and identifying the current with its time derivative, we recover the classic second-order differential equation and see the parallel between an LC circuit and the mass-spring system. \\[\n\\frac{d^2 Q}{dt^2} = -\\frac1{LC} Q,\n\\] where now \\(\\omega^2 = \\frac1{LC}\\), and if we solve this differential equation, we can use the standard approach for second-order linear differential equations with constant coefficients. The general solution has the form:\n\\[\nQ(t) = A \\cos(\\omega t) + B \\sin(\\omega t),\n\\]\nwhere \\(A\\) and \\(B\\) are constants determined by the initial conditions. If we assume that at \\(t=0\\), the charge is \\(Q(0) = Q_0\\) and the current is \\(I(0) = 0\\) (meaning the capacitor is initially charged but no current is flowing), then:\n\\[\nQ(0) = A = Q_0\n\\]\nAnd since \\(I(t) = \\frac{dQ}{dt}\\):\n\\[\nI(0) = \\omega B = 0 \\implies B = 0\n\\]\nTherefore, the solution becomes:\n\\[\nQ(t) = Q_0 \\cos(\\omega t)\n\\]\nThis represents a simple harmonic oscillation of the charge with angular frequency \\(\\omega = \\frac{1}{\\sqrt{LC}}\\). The current can be found by taking the time derivative:\n\\[\nI(t) = \\frac{dQ}{dt} = -Q_0 \\omega \\sin(\\omega t) = -\\frac{Q_0}{\\sqrt{LC}} \\sin(\\omega t)\n\\]\nThese equations show that the charge and current oscillate sinusoidally, with the current lagging the charge by a phase of \\(\\pi/2\\), exactly as we would expect in a classical harmonic oscillator.\n\n\n\n\n\n\nHistorical Note: Circuit Analogies in Physics\n\n\n\nThe analogy between LC circuits and mechanical oscillators has a rich history dating back to the late 19th century. James Clerk Maxwell and Oliver Heaviside were among the first to formalize these connections. In the 1940s and 1950s, analog computers built from electrical circuits were used to simulate complex mechanical and fluid systems, solving differential equations that were otherwise intractable. These “electronic differential analyzers” could model everything from vibrating structures to nuclear reactions. The RLC circuit (adding resistance) became particularly important as it could simulate damped oscillators with friction. This tradition of using circuits as analog models continues today in the field of neuromorphic computing, where circuits mimic neural dynamics, and of course, in quantum computing with superconducting circuits.\n\n\n\n\n5.2.2 Quantum Mechanical Analogy\nTo make the connection to quantum mechanics more explicit, we can identify the analogous variables between the LC circuit and the quantum harmonic oscillator:\n\nThe charge \\(Q\\) on the capacitor corresponds to the position \\(x\\) of the quantum oscillator\nThe magnetic flux \\(\\Phi = LI\\) through the inductor corresponds to the momentum \\(p\\) of the oscillator\n\nThis mapping becomes clear when we examine the energy stored in the circuit:\n\\[\nE_{LC} = \\frac{Q^2}{2C} + \\frac{\\Phi^2}{2L} = \\frac{Q^2}{2C} + \\frac{L I^2}{2}\n\\]\nThe first term represents the electrostatic energy stored in the capacitor, while the second term represents the magnetic energy stored in the inductor.\nCompare this to the energy of a quantum harmonic oscillator:\n\\[\nE_{oscillator} = \\frac{1}{2}m\\omega^2 x^2 + \\frac{p^2}{2m}\n\\]\nThe correspondence becomes:\n\\[\n\\frac{Q^2}{2C} \\leftrightarrow \\frac{1}{2}m\\omega^2 x^2 \\quad \\text{(potential energy)}\n\\]\n\\[\n\\frac{L I^2}{2} \\leftrightarrow \\frac{p^2}{2m} \\quad \\text{(kinetic energy)}\n\\]\nFrom these relations, we can identify:\n\n\\(Q \\leftrightarrow x\\)\n\\(\\Phi = LI \\leftrightarrow p\\)\n\\(C \\leftrightarrow \\frac{1}{m\\omega^2}\\)\n\\(L \\leftrightarrow m\\)\n\nThis mapping allows us to translate the quantum harmonic oscillator formalism directly to the LC circuit, which becomes crucial when we quantize the circuit to create superconducting qubits. The commutation relation \\([\\hat{x},\\hat{p}] = i\\hbar\\) in quantum mechanics translates to \\([\\hat{Q},\\hat{\\Phi}] = i\\hbar\\) for the LC circuit variables.\n\n\n\n\n\n\nUnderstanding the Quantum Commutator\n\n\n\nThe commutation relation \\([\\hat{Q},\\hat{\\Phi}] = i\\hbar\\) is fundamental to the quantum behavior of the LC circuit. Let’s explore what this means:\n\nDefinition: The commutator \\([\\hat{Q},\\hat{\\Phi}] = \\hat{Q}\\hat{\\Phi} - \\hat{\\Phi}\\hat{Q}\\) measures the failure of these operators to commute.\nPhysical meaning: In classical physics, variables like position and momentum can be measured simultaneously with arbitrary precision. In quantum mechanics, the non-zero commutator implies that \\(\\hat{Q}\\) and \\(\\hat{\\Phi}\\) cannot be precisely known simultaneously - this is a manifestation of Heisenberg’s uncertainty principle.\nOperator perspective: When \\(Q\\) and \\(\\Phi\\) become quantum operators, they act on the circuit’s wavefunction. The charge operator \\(\\hat{Q}\\) can be expressed as \\(\\hat{Q} = i\\sqrt{\\frac{\\hbar}{2}}\\left(\\frac{C}{L}\\right)^{1/4}(\\hat{a}^\\dagger - \\hat{a})\\), while the flux operator \\(\\hat{\\Phi}\\) becomes \\(\\hat{\\Phi} = \\sqrt{\\frac{\\hbar}{2}}\\left(\\frac{L}{C}\\right)^{1/4}(\\hat{a}^\\dagger + \\hat{a})\\), where \\(\\hat{a}\\) and \\(\\hat{a}^\\dagger\\) are the lowering and raising operators.\nUncertainty relation: This commutation relation directly leads to the uncertainty principle: \\(\\Delta Q \\cdot \\Delta \\Phi \\geq \\frac{\\hbar}{2}\\), meaning that the more precisely we know the charge, the less precisely we can know the flux, and vice versa.\n\nThis quantum behavior is what allows us to create superposition states in superconducting circuits, forming the basis for superconducting qubits.\n\n\n\n\n\n\n\n\nNotation: Quantum Operators and the “Hat” Symbol\n\n\n\nThroughout our discussion of quantum circuits, we use the “hat” notation (e.g., \\(\\hat{Q}\\), \\(\\hat{\\Phi}\\)) to distinguish quantum operators from classical variables. This distinction is important:\n\nA variable without a hat (e.g., \\(Q\\), \\(\\Phi\\)) represents a classical quantity with a definite value\nA variable with a hat (e.g., \\(\\hat{Q}\\), \\(\\hat{\\Phi}\\)) represents a quantum operator that acts on wavefunctions\n\nQuantum operators correspond to observable quantities but, unlike classical variables, generally don’t have definite values until measured. Instead, they represent the mathematical operations we perform on quantum states to calculate measurement probabilities and expectation values.\n\n\nNow that we’ve established the quantum operators for our circuit, we can write down the quantum Hamiltonian:\n\\[\n\\hat{H} = \\frac{\\hat{Q}^2}{2C} + \\frac{\\hat{\\Phi}^2}{2L}\n\\]\nThis Hamiltonian is analogous to the quantum harmonic oscillator. We can rewrite it in terms of the raising and lowering operators \\(\\hat{a}^\\dagger\\) and \\(\\hat{a}\\). Recall that: \\[\n\\hat{Q} = i\\sqrt{\\frac{\\hbar}{2}}\\left(\\frac{C}{L}\\right)^{1/4}(\\hat{a}^\\dagger - \\hat{a})\n\\]\n\\[\n\\hat{\\Phi} = \\sqrt{\\frac{\\hbar}{2}}\\left(\\frac{L}{C}\\right)^{1/4}(\\hat{a}^\\dagger + \\hat{a})\n\\]\nSubstituting these expressions into our Hamiltonian:\n\\[\n\\begin{align}\n\\hat{H} &= \\frac{1}{2C}\\left(i\\sqrt{\\frac{\\hbar}{2}}\\left(\\frac{C}{L}\\right)^{1/4}(\\hat{a}^\\dagger - \\hat{a})\\right)^2 + \\frac{1}{2L}\\left(\\sqrt{\\frac{\\hbar}{2}}\\left(\\frac{L}{C}\\right)^{1/4}(\\hat{a}^\\dagger + \\hat{a})\\right)^2 \\\\\n&= -\\frac{\\hbar}{4C}\\left(\\frac{C}{L}\\right)^{1/2}(\\hat{a}^\\dagger - \\hat{a})^2 + \\frac{\\hbar}{4L}\\left(\\frac{L}{C}\\right)^{1/2}(\\hat{a}^\\dagger + \\hat{a})^2 \\\\\n\\end{align}\n\\]\nAfter algebraic manipulation and using the commutation relation \\([\\hat{a},\\hat{a}^\\dagger] = 1\\), we arrive at:\n\\[\n\\hat{H} = \\hbar\\omega\\left(\\hat{a}^\\dagger\\hat{a} + \\frac{1}{2}\\right)\n\\]\nwhere \\(\\omega = \\frac{1}{\\sqrt{LC}}\\) is the resonant frequency of the circuit.\n\n\n\n\n\n\nCommutation Relation for Raising and Lowering Operators\n\n\n\nThe commutation relation for the raising and lowering operators \\(\\hat{a}^\\dagger\\) and \\(\\hat{a}\\) can be derived from the commutation relation between \\(\\hat{Q}\\) and \\(\\hat{\\Phi}\\):\n\\[\n[\\hat{a}, \\hat{a}^\\dagger] = ?\n\\]\nStarting with the expressions for \\(\\hat{Q}\\) and \\(\\hat{\\Phi}\\) in terms of \\(\\hat{a}\\) and \\(\\hat{a}^\\dagger\\):\n\\[\n\\hat{Q} = i\\sqrt{\\frac{\\hbar}{2}}\\left(\\frac{C}{L}\\right)^{1/4}(\\hat{a}^\\dagger - \\hat{a})\n\\]\n\\[\n\\hat{\\Phi} = \\sqrt{\\frac{\\hbar}{2}}\\left(\\frac{L}{C}\\right)^{1/4}(\\hat{a}^\\dagger + \\hat{a})\n\\]\nWe can solve for \\(\\hat{a}\\) and \\(\\hat{a}^\\dagger\\):\n\\[\n\\hat{a} = \\frac{1}{2}\\left[\\left(\\frac{L}{C}\\right)^{1/4}\\frac{\\hat{\\Phi}}{\\sqrt{\\frac{\\hbar}{2}}} - i\\left(\\frac{L}{C}\\right)^{-1/4}\\frac{\\hat{Q}}{i\\sqrt{\\frac{\\hbar}{2}}}\\right]\n\\]\n\\[\n\\hat{a}^\\dagger = \\frac{1}{2}\\left[\\left(\\frac{L}{C}\\right)^{1/4}\\frac{\\hat{\\Phi}}{\\sqrt{\\frac{\\hbar}{2}}} + i\\left(\\frac{L}{C}\\right)^{-1/4}\\frac{\\hat{Q}}{i\\sqrt{\\frac{\\hbar}{2}}}\\right]\n\\]\nNow we compute the commutator: \\[\n\\begin{aligned}\n[\\hat{a}, \\hat{a}^\\dagger] &= \\hat{a}\\hat{a}^\\dagger - \\hat{a}^\\dagger\\hat{a} \\\\\n&= \\frac{1}{4}\\left[\\left(\\left(\\frac{L}{C}\\right)^{1/4}\\frac{\\hat{\\Phi}}{\\sqrt{\\frac{\\hbar}{2}}} - i\\left(\\frac{L}{C}\\right)^{-1/4}\\frac{\\hat{Q}}{i\\sqrt{\\frac{\\hbar}{2}}}\\right)\\left(\\left(\\frac{L}{C}\\right)^{1/4}\\frac{\\hat{\\Phi}}{\\sqrt{\\frac{\\hbar}{2}}} + i\\left(\\frac{L}{C}\\right)^{-1/4}\\frac{\\hat{Q}}{i\\sqrt{\\frac{\\hbar}{2}}}\\right) \\right. \\\\\n&\\quad \\left. - \\left(\\left(\\frac{L}{C}\\right)^{1/4}\\frac{\\hat{\\Phi}}{\\sqrt{\\frac{\\hbar}{2}}} + i\\left(\\frac{L}{C}\\right)^{-1/4}\\frac{\\hat{Q}}{i\\sqrt{\\frac{\\hbar}{2}}}\\right)\\left(\\left(\\frac{L}{C}\\right)^{1/4}\\frac{\\hat{\\Phi}}{\\sqrt{\\frac{\\hbar}{2}}} - i\\left(\\frac{L}{C}\\right)^{-1/4}\\frac{\\hat{Q}}{i\\sqrt{\\frac{\\hbar}{2}}}\\right)\\right] \\\\\n\\end{aligned}\n\\]\nLet’s define simpler variables to make this calculation more manageable: \\[\n\\begin{aligned}\nA &= \\left(\\frac{L}{C}\\right)^{1/4}\\frac{\\hat{\\Phi}}{\\sqrt{\\frac{\\hbar}{2}}} \\\\\nB &= \\left(\\frac{L}{C}\\right)^{-1/4}\\frac{\\hat{Q}}{i\\sqrt{\\frac{\\hbar}{2}}}\n\\end{aligned}\n\\]\nThen our commutator becomes: \\[\n\\begin{aligned}\n[\\hat{a}, \\hat{a}^\\dagger] &= \\frac{1}{4}[(A - iB)(A + iB) - (A + iB)(A - iB)] \\\\\n&= \\frac{1}{4}[A^2 + iAB - iBA + B^2 - A^2 - iAB + iBA - B^2] \\\\\n&= \\frac{1}{4}[2i(BA - AB)] \\\\\n&= \\frac{i}{2}[\\hat{B}, \\hat{A}] \\\\\n&= \\frac{i}{2} \\cdot \\left(\\frac{L}{C}\\right)^{-1/4} \\cdot \\left(\\frac{L}{C}\\right)^{1/4} \\cdot \\frac{1}{\\frac{\\hbar}{2}} \\cdot \\frac{1}{i} \\cdot [\\hat{Q}, \\hat{\\Phi}] \\\\\n&= \\frac{i}{2} \\cdot \\frac{2}{\\hbar} \\cdot \\frac{1}{i} \\cdot (i\\hbar) \\\\\n&= \\frac{i}{2} \\cdot \\frac{2}{\\hbar} \\cdot \\hbar \\\\\n&= 1\n\\end{aligned}\n\\]\nTherefore, \\([\\hat{a}, \\hat{a}^\\dagger] = 1\\), which is the canonical commutation relation for raising and lowering operators.\n\n\n\n\n5.2.3 Solving the Quantum LC Circuit\nTo solve this system, we use the energy eigenstates of the harmonic oscillator, denoted as \\(|n\\rangle\\), where \\(n = 0, 1, 2, ...\\). These states have the following properties:\n\n\\(\\hat{a}^\\dagger|n\\rangle = \\sqrt{n+1}|n+1\\rangle\\) (raising operator)\n\\(\\hat{a}|n\\rangle = \\sqrt{n}|n-1\\rangle\\) (lowering operator)\n\\(\\hat{a}^\\dagger\\hat{a}|n\\rangle = n|n\\rangle\\) (number operator)\n\nThese properties can be derived using the commutation relation \\([\\hat{a}, \\hat{a}^\\dagger] = 1\\). The energy eigenvalues are:\n\\[\nE_n = \\hbar\\omega\\left(n + \\frac{1}{2}\\right)\n\\]\nThis means the energy levels of our quantum LC circuit are:\n\nGround state (\\(n=0\\)): \\(E_0 = \\frac{\\hbar\\omega}{2}\\) (zero-point energy)\nFirst excited state (\\(n=1\\)): \\(E_1 = \\frac{3\\hbar\\omega}{2}\\)\nSecond excited state (\\(n=2\\)): \\(E_2 = \\frac{5\\hbar\\omega}{2}\\)\n…\n\nAnd so on, with each subsequent energy level following the pattern \\(E_n = \\hbar\\omega(n + \\frac{1}{2})\\).\nAnd so on, with equal spacing of \\(\\hbar\\omega\\) between adjacent levels.\nThe wavefunctions in the charge basis can be expressed as:\n\\[\n\\psi_n(Q) = \\frac{1}{\\sqrt{2^n n!}}\\left(\\frac{C\\omega}{\\pi\\hbar}\\right)^{1/4} e^{-\\frac{CQ^2}{2\\hbar}} H_n\\left(Q\\sqrt{\\frac{C\\omega}{\\hbar}}\\right)\n\\]\nwhere \\(H_n\\) are the Hermite polynomials.\nTo make the connection to superconducting qubits clearer, we can rewrite our quantum LC oscillator Hamiltonian in terms of more physically relevant quantities: the charging energy and the reduced flux.\n\n\n5.2.4 Charging Energy and Reduced Flux\nThe Hamiltonian of our quantum LC circuit is:\n\\[\n\\hat{H} = \\frac{\\hat{Q}^2}{2C} + \\frac{\\hat{\\Phi}^2}{2L}\n\\]\nLet’s introduce the following quantities:\n\nCharging Energy: \\(E_C = \\frac{e^2}{2C}\\), where \\(e\\) is the elementary charge. This represents the energy needed to add a single electron to the capacitor.\nFlux Quantum: \\(\\Phi_0 = \\frac{h}{2e}\\), the superconducting flux quantum.\nReduced Flux: \\(\\hat{\\varphi} = \\frac{2\\pi\\hat{\\Phi}}{\\Phi_0}\\), a dimensionless quantity.\nNumber Operator: \\(\\hat{n} = \\frac{\\hat{Q}}{2e}\\), which counts the number of Cooper pairs.\n\nWith these definitions, we can rewrite our operators:\n\\[\n\\hat{Q} = 2e\\hat{n}\n\\]\n\\[\n\\hat{\\Phi} = \\frac{\\Phi_0}{2\\pi}\\hat{\\varphi}\n\\]\nSubstituting these into our Hamiltonian:\n\\[\n\\begin{aligned}\n\\hat{H} &= \\frac{(2e\\hat{n})^2}{2C} + \\frac{\\left(\\frac{\\Phi_0}{2\\pi}\\hat{\\varphi}\\right)^2}{2L} \\\\\n&= \\frac{4e^2\\hat{n}^2}{2C} + \\frac{\\Phi_0^2\\hat{\\varphi}^2}{8\\pi^2L} \\\\\n&= 4E_C\\hat{n}^2 + \\frac{\\Phi_0^2}{8\\pi^2L}\\hat{\\varphi}^2\n\\end{aligned}\n\\]\nWe can further define the inductive energy \\(E_L = \\frac{\\Phi_0^2}{4\\pi^2L}\\), which gives us:\n\\[\n\\hat{H} = 4E_C\\hat{n}^2 + \\frac{E_L}{2}\\hat{\\varphi}^2\n\\]\nThis form of the Hamiltonian is particularly useful because:\n\nIt expresses the energy in terms of discrete Cooper pairs (\\(\\hat{n}\\))\nIt uses the reduced flux (\\(\\hat{\\varphi}\\)), which has a direct physical interpretation in superconducting circuits\nThe energy scales \\(E_C\\) and \\(E_L\\) can be engineered by circuit design\n\nThe commutation relation between these operators becomes:\n\\[\n[\\hat{\\varphi}, \\hat{n}] = i\n\\]\nThis formulation helps us understand the quantum LC circuit in terms of charge and flux quanta, which is essential for developing superconducting qubits. The harmonic oscillator energy levels in this notation are:\n\\[\nE_n = \\hbar\\omega\\left(n + \\frac{1}{2}\\right) = \\sqrt{8E_CE_L}\\left(n + \\frac{1}{2}\\right)\n\\]\nwhere \\(\\omega = \\frac{1}{\\sqrt{LC}} = \\sqrt{\\frac{8E_CE_L}{\\hbar^2}}\\).\n\n\n5.2.5 The Need for Anharmonicity\nThis infinite ladder of equally spaced energy levels is characteristic of harmonic oscillators. While this system is quantum mechanical, it’s unsuitable for quantum computing because we cannot selectively address just two energy levels. If we tried to use the lowest two levels (\\(\\ket{0}\\) and \\(\\ket{1}\\)) as our qubit states, any operation that excites \\(\\ket{0}\\) to \\(\\ket{1}\\) would also excite \\(\\ket{1}\\) to \\(\\ket{2}\\), \\(\\ket{2}\\) to \\(\\ket{3}\\), and so on, making it impossible to maintain a two-level system.\nWhat we need is anharmonicity - unequal spacing between energy levels - so that the transition energy \\(E_{0\\rightarrow 1}\\) (from \\(\\ket{0}\\) to \\(\\ket{1}\\)) differs from \\(E_{1\\rightarrow 2}\\) (from \\(\\ket{1}\\) to \\(\\ket{2}\\)). This allows us to selectively address only the \\(\\ket{0}\\) and \\(\\ket{1}\\) states with appropriately tuned control pulses.\nTo achieve this anharmonicity, we must introduce a nonlinear element into our circuit - which is precisely what the Josephson junction provides, as we’ll explore in the next section.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Superconducting qubits</span>"
    ]
  },
  {
    "objectID": "superconducting_qubits.html#the-artificial-atom",
    "href": "superconducting_qubits.html#the-artificial-atom",
    "title": "5  Superconducting qubits",
    "section": "5.3 The artificial atom",
    "text": "5.3 The artificial atom\nTo create a qubit from our quantum circuit, we need to transform the harmonic oscillator into an artificial atom with discrete, addressable energy levels. This requires introducing anharmonicity - unequal spacing between energy levels - into our system. In the following sections, we’ll explore how the Josephson junction provides the necessary nonlinearity to achieve this anharmonicity. By incorporating this element into our circuit, we can engineer an artificial atom with customizable properties, where the lowest two energy levels can be isolated and controlled as a qubit. This approach leverages the macroscopic quantum behavior of superconducting circuits to create a scalable platform for quantum information processing.\n\n\n\n\n\n\nThe Dual Role of Superconductivity\n\n\n\nSuperconductivity plays two crucial roles in our quantum circuits:\n\nZero Resistance: Superconducting materials conduct electricity with absolutely no resistance, allowing quantum states to persist without energy dissipation. This property is essential for maintaining quantum coherence in our circuits.\nJosephson Effect: Superconductivity enables the Josephson effect, which occurs when two superconductors are separated by a thin insulating barrier. Cooper pairs can tunnel through this barrier coherently, creating a nonlinear element that’s essential for introducing anharmonicity into our quantum system.\n\nWithout superconductivity, we would neither have the low-loss environment needed for quantum operations nor the nonlinear element (Josephson junction) required to create addressable energy levels for our qubit.\n\n\n\n5.3.1 The Josephson Junction\nTo create our artificial atom, we need to introduce nonlinearity into our quantum circuit. This is achieved through the Josephson junction - a superconducting device consisting of two superconductors separated by a thin insulating barrier.\nThe Josephson junction is governed by two key relations:\n\nThe DC Josephson effect, relating the supercurrent through the junction to the phase difference: \\[I = I_c \\sin\\varphi\\] where \\(I_c\\) is the critical current and \\(\\varphi\\) is the phase difference across the junction.\nThe AC Josephson effect, relating the voltage across the junction to the rate of change of the phase: \\[V = \\frac{\\Phi_0}{2\\pi}\\frac{d\\varphi}{dt}\\]\n\nThe energy stored in a Josephson junction is given by: \\[E_J(\\varphi) = -E_J\\cos\\varphi\\] where \\(E_J = \\frac{\\Phi_0 I_c}{2\\pi}\\) is the Josephson energy.\n\n\n\n\n\n\nDeriving the Josephson Junction Energy\n\n\n\nWe can derive the energy stored in a Josephson junction by considering the work done when a current flows through it:\n\\[W = \\int P dt = \\int VI dt = \\int V \\frac{dQ}{dt} dt = \\int V dQ\\]\nUsing the AC Josephson relation, \\(V = \\frac{\\Phi_0}{2\\pi}\\frac{d\\varphi}{dt}\\), we can substitute:\n\\[W = \\int \\frac{\\Phi_0}{2\\pi}\\frac{d\\varphi}{dt} dQ\\]\nSince \\(I = \\frac{dQ}{dt}\\) and \\(I = I_c \\sin\\varphi\\) from the DC Josephson relation:\n\\[W = \\int \\frac{\\Phi_0}{2\\pi}\\frac{d\\varphi}{dt} \\cdot I_c \\sin\\varphi \\cdot dt = \\frac{\\Phi_0 I_c}{2\\pi} \\int \\sin\\varphi \\, d\\varphi\\]\nIntegrating, we get:\n\\[W = -\\frac{\\Phi_0 I_c}{2\\pi} \\cos\\varphi + \\text{constant}\\]\nThe energy stored in the junction is therefore:\n\\[E_J(\\varphi) = -E_J\\cos\\varphi\\]\nwhere \\(E_J = \\frac{\\Phi_0 I_c}{2\\pi}\\) is the Josephson energy. This nonlinear energy-phase relationship is what gives the Josephson junction its crucial anharmonic properties.\n\n\n\n\n5.3.2 The Transmon Qubit\nBy replacing the inductor in our LC circuit with a Josephson junction, we create a nonlinear oscillator. The Hamiltonian becomes:\n\\[\\hat{H} = 4E_C\\hat{n}^2 - E_J\\cos\\hat{\\varphi}\\]\nThis is fundamentally different from the harmonic oscillator because the \\(\\cos\\hat{\\varphi}\\) term introduces anharmonicity. We can expand this cosine term:\n\\[\\cos\\hat{\\varphi} \\approx 1 - \\frac{\\hat{\\varphi}^2}{2} + \\frac{\\hat{\\varphi}^4}{24} - ...\\]\nSubstituting this into our Hamiltonian:\n\\[\\hat{H} \\approx 4E_C\\hat{n}^2 - E_J\\left(1 - \\frac{\\hat{\\varphi}^2}{2} + \\frac{\\hat{\\varphi}^4}{24} - ...\\right)\\]\nRearranging:\n\\[\\hat{H} \\approx -E_J + 4E_C\\hat{n}^2 + \\frac{E_J}{2}\\hat{\\varphi}^2 - \\frac{E_J}{24}\\hat{\\varphi}^4 + ...\\]\nThe first term is just a constant energy offset. The second and third terms resemble our harmonic oscillator Hamiltonian. The fourth term introduces anharmonicity - it makes the energy levels unequally spaced.\nIn practice, the ratio between the Josephson energy \\(E_J\\) and the charging energy \\(E_C\\) plays a crucial role in determining the properties of superconducting qubits. The superconducting qubit community has converged toward circuit designs with \\(E_J \\gg E_C\\) for several important reasons.\n\n5.3.2.1 The \\(E_J/E_C\\) Ratio and Charge Sensitivity\nWhen \\(E_J \\leq E_C\\), as in the earlier Cooper-pair box charge qubit designs, the qubit becomes highly sensitive to charge noise. This sensitivity leads to shorter coherence times and less reliable qubit operation. In contrast, operating in the \\(E_J \\gg E_C\\) regime significantly reduces this charge sensitivity.\n\n\n5.3.2.2 Charge Dispersion and Energy Levels\nTo understand why the \\(E_J \\gg E_C\\) regime is advantageous, we need to examine how the energy levels depend on the offset charge \\(n_g\\). The offset charge represents the effect of the electrostatic environment on the qubit, including stray charges that can fluctuate over time.\nThe Hamiltonian with an offset charge \\(n_g\\) is:\n\\[\\hat{H} = 4E_C(\\hat{n} - n_g)^2 - E_J\\cos\\hat{\\varphi}\\]\nIn the charge basis, we can compute the energy eigenvalues by diagonalizing this Hamiltonian. The resulting energy bands \\(E_m(n_g)\\) depend on both the quantum number \\(m\\) and the offset charge \\(n_g\\).\nFor a Cooper-pair box (where \\(E_J \\lesssim E_C\\)), the energy levels as a function of \\(n_g\\) look like:\n\nWhen \\(E_J \\ll E_C\\): The energy bands are approximately parabolas centered at integer values of \\(n_g\\), with small anticrossings at half-integer values.\nWhen \\(E_J \\approx E_C\\): The bands flatten somewhat, but still show significant dependence on \\(n_g\\).\n\nIn both cases, the energy difference between the ground and first excited states varies significantly with \\(n_g\\), making the qubit frequency highly sensitive to charge fluctuations.\nAs we increase the ratio \\(E_J/E_C\\), the dependence of energy levels on \\(n_g\\) becomes exponentially suppressed. The energy bands flatten out, and the variation in energy with \\(n_g\\) (called charge dispersion) decreases exponentially:\n\\[\\epsilon_m \\approx (\\text{some factors}) \\times e^{-\\sqrt{8E_J/E_C}}\\]\nThis equation shows that the charge sensitivity decreases exponentially as the ratio \\(E_J/E_C\\) increases. The important takeaway is that making \\(E_J\\) much larger than \\(E_C\\) dramatically reduces the qubit’s sensitivity to charge noise.\nThis exponential suppression of charge sensitivity comes with a trade-off, however. As we increase the \\(E_J/E_C\\) ratio by reducing \\(E_C\\) (typically by adding a larger shunt capacitor), the anharmonicity\n\\[\\alpha \\approx -E_C + (\\text{constant}) \\frac{E_C^2}{E_J} + \\cdots \\]\nalso decreases in magnitude. This creates a fundamental design tension:\n\nHigher \\(E_J/E_C\\) → Better charge noise immunity → Lower anharmonicity\nLower \\(E_J/E_C\\) → Worse charge noise immunity\n\nSince the anharmonicity determines how well we can selectively address the \\(|0\\rangle\\) to \\(|1\\rangle\\) transition without exciting higher energy levels, it cannot be too small without risking leakage out of the computational subspace during control operations. In practice, transmon designs typically aim for an anharmonicity of around 200-300 MHz, which is sufficient for selective control while maintaining good charge noise immunity with \\(E_J/E_C\\) ratios of 50-100.\nThis exponential suppression of charge sensitivity is the key advantage of the transmon regime. By operating with \\(E_J/E_C \\approx 50-100\\), we can reduce charge noise sensitivity by several orders of magnitude compared to the Cooper-pair box, while still maintaining sufficient anharmonicity for qubit operations.\n\n\n5.3.2.3 Definition of the Transmon Qubit\nThe transmon (transmission-line shunted plasma oscillation qubit) is a type of superconducting qubit that consists of a Josephson junction shunted by a large capacitor. This design specifically operates in the regime where \\(E_J \\gg E_C\\), typically with ratios between 50 and 100. The large shunting capacitor \\(C_s \\gg C_J\\) reduces the charging energy \\(E_C\\), making the qubit exponentially less sensitive to charge noise while maintaining sufficient anharmonicity to operate as a qubit.\nTo access the \\(E_J \\gg E_C\\) regime, the preferred approach is to make the charging energy \\(E_C\\) small by shunting the Josephson junction with a large capacitor, \\(C_s \\gg C_J\\). This design is the foundation of the transmon qubit. In this limit, the superconducting phase \\(\\varphi\\) becomes approximately a good quantum number, meaning the quantum fluctuations of \\(\\varphi\\) represented by the wavefunction are small.\n\n\n\n\n\n\nEnergy Level Discreteness and the \\(E_J/E_C\\) Balance\n\n\n\nWhile operating in the \\(E_J \\gg E_C\\) regime reduces charge sensitivity, it’s important to note that the energy level spacing still depends on \\(E_C\\). As \\(E_J/E_C\\) increases, the phase \\(\\varphi\\) becomes a better quantum number, but the energy levels also become more closely spaced (since \\(\\alpha \\approx -E_C\\)).\nThis creates a careful balancing act in transmon design: we want \\(E_J/E_C\\) large enough to suppress charge noise, but not so large that the energy levels become too closely spaced to distinguish and address individually. If the anharmonicity becomes too small, it becomes difficult to selectively drive transitions between only two levels without exciting higher states, compromising our ability to treat the system as a qubit.\nTypical transmon designs strike this balance with \\(E_J/E_C\\) ratios between 50 and 100, providing sufficient charge noise insensitivity while maintaining adequate level separation for reliable qubit operations.\n\n\n\n\n5.3.2.4 Anharmonicity in the Transmon\nThe negative coefficient of the quartic term in our expanded Hamiltonian indicates that the anharmonicity \\(\\alpha = E_{12} - E_{01}\\) (the difference between consecutive energy level spacings) is negative. This means that the energy required to excite from the first excited state to the second excited state is less than that required to excite from the ground state to the first excited state.\nIn practical transmon designs, the anharmonicity \\(\\alpha \\approx -E_C\\) is usually engineered to be around 100-300 MHz. The qubit frequency \\(\\omega_q = \\sqrt{8E_J E_C}/h - E_C/h\\) typically falls in the range of 3-6 GHz. To effectively suppress charge sensitivity, the energy ratio is made sufficiently large, with \\(E_J/E_C \\geq 50\\) being common.\n\n\n5.3.2.5 The Transmon as a Weakly Anharmonic Oscillator\nDue to this design, the transmon qubit is fundamentally a weakly anharmonic oscillator (AHO). While we often treat it as a quantum two-level system for simplicity, it’s important to remember that higher energy levels physically exist and can be accessed. In fact, these higher levels have proven useful in implementing more efficient gate operations in some quantum computing protocols. ### The Duffing Oscillator Representation\nThe transmon Hamiltonian can be rewritten in a form that makes its nature as a weakly anharmonic oscillator more explicit. Using the creation and annihilation operators from the harmonic oscillator formalism, we can express the transmon Hamiltonian as a Duffing oscillator:\n\\[\\hat{H} = \\hbar\\omega_q \\hat{a}^\\dagger\\hat{a} + \\frac{\\alpha}{2}\\hat{a}^\\dagger\\hat{a}^\\dagger\\hat{a}\\hat{a}\\]\nHere, \\(\\omega_q\\) is the qubit frequency (approximately \\(\\sqrt{8E_J E_C}/\\hbar - E_C/\\hbar\\)), and \\(\\alpha\\) is the anharmonicity (approximately \\(-E_C/\\hbar\\)). The first term represents the harmonic part of the oscillator, while the second term introduces the anharmonicity that makes the energy levels unequally spaced.\nThis representation clearly shows that the transmon is essentially a harmonic oscillator with a perturbation that shifts the energy levels. The negative anharmonicity means that as we climb the energy ladder, each successive transition requires slightly less energy than the previous one.\n\n\n\n5.3.3 Effective Two-Level System Hamiltonian\nAlthough the transmon is a multi-level system, when we restrict our focus to the lowest two energy levels (ground state \\(|0\\rangle\\) and first excited state \\(|1\\rangle\\)), we can represent it as an effective two-level system or qubit. In this subspace, the Hamiltonian takes the form:\n\\[\\hat{H}_\\text{qubit} = -\\frac{\\hbar\\omega_q}{2}Z\\]\nwhere \\(\\hat{\\sigma}_z\\) is the Pauli-Z operator. This is the standard form for a qubit Hamiltonian in the energy eigenbasis, with the energy difference between the \\(|0\\rangle\\) and \\(|1\\rangle\\) states being \\(\\hbar\\omega_q\\).\nIt’s important to note that this two-level approximation is valid only when:\n\nThe control pulses used to manipulate the qubit are sufficiently selective in frequency to avoid exciting higher energy levels\nThe pulse shapes are designed to minimize leakage to higher states\nThe system temperature is low enough that thermal excitation to higher states is negligible\n\nThe presence of higher energy levels in the transmon, while often ignored in the two-level approximation, can lead to effects like leakage errors during gate operations. Advanced control techniques must account for these higher levels to achieve high-fidelity quantum operations.\n\n\n5.3.4 Tunable qubits\nOne of the most powerful features we can add to a transmon qubit is the ability to tune its frequency. This tunability gives us precise control over how qubits interact with each other, which is crucial for quantum computing.\n\n\n\n\n\n\nWhat Does “In Resonance” Mean?\n\n\n\nIn quantum mechanics, two systems are “in resonance” when they have the same energy difference between their states. Think of two musical tuning forks - when they have the same frequency, striking one can cause the other to vibrate. Similarly, when two qubits are in resonance, they can exchange quantum information efficiently.\nBeing able to control when qubits are in resonance is crucial because:\n\nWe can bring qubits into resonance when we want them to work together\nWe can take them out of resonance when we want them to work independently\nWe can prevent unwanted interactions between multiple qubits by giving them different frequencies\n\n\n\nThe most common way to make a tunable transmon is to replace its single Josephson junction with two junctions in parallel, forming a loop. This structure is called a DC SQUID (Superconducting QUantum Interference Device). By applying a magnetic field through this loop, we can control how the device behaves.\nWhen we use two identical junctions, the phases across them (\\(\\varphi_1\\) and \\(\\varphi_2\\)) are related to the magnetic flux \\(\\Phi\\) through the loop by:\n\\[\\varphi_1 - \\varphi_2 + 2\\pi k = 2\\pi\\frac{\\Phi}{\\Phi_0},\\]\nfor an integer \\(k\\). Here, \\(\\Phi_0 = h/2e\\) is the magnetic flux quantum - a fundamental constant in superconductivity that appears frequently in these systems.\nThis arrangement changes the effective Josephson energy of our circuit. Instead of being fixed, it now depends on the magnetic flux:\n\\[E_J(\\Phi) = 2E_{J}\\left|\\cos\\left(\\pi\\frac{\\Phi}{\\Phi_0}\\right)\\right|\\]\nwhere \\(E_{J}\\) is the Josephson energy of each individual junction. This leads to a modified transmon Hamiltonian:\n\\[\\hat{H} = 4E_C\\hat{n}^2 - 2E_{J}\\left|\\cos\\left(\\pi\\frac{\\Phi}{\\Phi_0}\\right)\\right|\\cos\\hat{\\varphi}\\]\nAs a result, we can tune the qubit’s frequency by changing the magnetic flux:\n\\[\\omega_q(\\Phi) \\approx \\sqrt{\\frac{8E_C}{\\hbar^2}2E_{J}\\left|\\cos\\left(\\pi\\frac{\\Phi}{\\Phi_0}\\right)\\right|} - \\frac{E_C}{\\hbar}\\]\nWhile this tunability is valuable, it comes with a drawback: sensitivity to fluctuations in the magnetic field, called flux noise. We can measure this sensitivity by looking at how much the frequency changes when we slightly change the flux:\n\\[\\left|\\frac{\\partial\\omega_q}{\\partial\\Phi}\\right|\\]\nThe qubit is most stable when the flux is a whole number multiple of \\(\\Phi_0\\), where small changes in flux have minimal effect on the frequency. However, we often need to operate at other flux values where the qubit becomes more sensitive to noise.\nA Better Design: The Asymmetric SQUID: To address this problem, we can make one junction larger than the other in our SQUID. This asymmetric design changes the effective Josephson energy to:\n\\[E_J(\\Phi) = E_{J\\Sigma}\\sqrt{d^2 + (1-d^2)\\cos^2\\left(\\pi\\frac{\\Phi}{\\Phi_0}\\right)}\\]\nHere, \\(E_{J\\Sigma} = E_{J1} + E_{J2}\\) is the total Josephson energy of both junctions, and \\(d = (E_{J1} - E_{J2})/(E_{J1} + E_{J2})\\) measures how different the junctions are. This design makes the qubit less sensitive to flux noise while still allowing us to tune its frequency.\nWhen we have multiple qubits on the same chip, we need to carefully manage their frequencies to prevent unwanted interactions. This becomes especially important when performing two-qubit operations like the controlled-phase gate, where we deliberately bring two qubits into resonance. We’ll explore these quantum operations and the precise timing and frequency control they require in later sections.\n\n\n5.3.5 The Flux Qubit and Fluxonium\nWhile we’ve focused on using charge as our quantum variable in the transmon, we could alternatively use flux. Recall our quantum LC oscillator - the flux and charge variables were conjugate to each other, much like position and momentum. Just as we can encode quantum information in charge states, we can encode it in persistent currents flowing clockwise or counterclockwise in a superconducting loop.\nThis alternative approach becomes particularly interesting when we consider the limitations of the transmon. While the transmon’s reduced charge sensitivity makes it robust against noise, its relatively small negative anharmonicity (typically around -200 MHz) can lead to unwanted excitations to higher energy states during operations.\n\n\n\n\n\n\nAnharmonicity and Control Speed\n\n\n\nWith limited anharmonicity, we face a fundamental trade-off in qubit control. Fast control pulses have broad frequency content that can inadvertently excite transitions to higher states (\\(|2\\rangle\\), \\(|3\\rangle\\), etc.). To avoid this, we must use longer, gentler pulses that are more frequency-selective. However, these slower pulses mean our quantum operations take more time. Even with careful pulse shaping, some small leakage to higher states may be unavoidable due to the uncertainty principle - very short pulses must have some frequency spread. This balance between operation speed and unwanted excitations is a key consideration in qubit design.\n\n\nThe flux qubit offers a different approach. In its basic form, it consists of a superconducting loop interrupted by three Josephson junctions - one smaller junction with Josephson energy \\(E_J\\) and two larger junctions, each with energy \\(\\alpha E_J\\) where \\(\\alpha &gt; 1\\). The approximate Hamiltonian is:\n\\[\n\\hat{H} = 4E_C\\hat{n}^2 - E_J(\\cos(2\\hat{\\varphi}+2\\pi f) + 2\\alpha\\cos(\\hat{\\varphi}))\n\\]\nwhere \\(f = \\Phi/\\Phi_0\\) is the reduced flux through the loop. To minimize flux noise sensitivity, we typically operate at \\(f = 1/2 + k\\).\nThe potential energy landscape of this system can exhibit either single-well or double-well behavior, depending on the parameter \\(\\alpha\\):\n\nDouble-Well Regime (\\(\\alpha &gt; 2\\)): This creates the “persistent-current flux qubit”. The two lowest energy states correspond to clockwise and counterclockwise persistent currents in the loop. These states have minimal overlap, leading to very large anharmonicity (often several GHz) and potentially longer relaxation times.\nSingle-Well Regime (\\(\\alpha &lt; 2\\)): Similar to the transmon but with positive anharmonicity, making it less susceptible to leakage to higher states during operations. This is often implemented as the “capacitively shunted flux qubit”.\n\nThe fluxonium qubit takes this concept further by adding an array of many larger Josephson junctions (typically N ≈ 50-100 junctions) in series with the small junction. These larger junctions act together as a “superinductance” - effectively a very large inductor with low dissipation. When we add this array, we get an additional inductive energy term in our Hamiltonian:\n\\[\n\\hat{H} = 4E_C\\hat{n}^2 + \\frac{1}{2}E_L\\hat{\\varphi}^2 - E_J\\cos(\\hat{\\varphi} + 2\\pi f)\n\\]\nLet’s break down what each term means physically:\n\nThe first term (\\(4E_C\\hat{n}^2\\)) is our familiar charging energy from before\nThe middle term (\\(\\frac{1}{2}E_L\\hat{\\varphi}^2\\)) is the inductive energy from our junction array\nThe last term (\\(-E_J\\cos(\\hat{\\varphi} + 2\\pi f)\\)) is the Josephson energy of the small junction\n\nThe inductive energy \\(E_L\\) comes from the array of N junctions acting together. Each junction in the array has a Josephson energy \\(\\alpha E_J\\) (where \\(\\alpha &gt; 1\\)) larger than our small junction energy \\(E_J\\). When we connect N of them in series, the effective inductive energy becomes \\(E_L = \\frac{\\alpha E_J}{N}\\). This linear scaling with N allows us to create very large inductances by using many junctions in series, hence the term “superinductance”.\n\n\n\n\n\n\nPlasmon vs Fluxon States\n\n\n\nThe fluxonium exhibits two types of excitations:\n\nPlasmon states: Small oscillations within a potential well, similar to LC oscillator states\nFluxon states: Quantum tunneling between different wells, corresponding to different numbers of flux quanta threading the loop\n\nThe junction array provides a large kinetic inductance, which helps protect against charge noise while maintaining strong anharmonicity. This makes the fluxonium particularly promising for achieving long coherence times.\n\n\nThe fluxonium combines advantages of both charge-based and flux-based qubits: it inherits protection against charge noise from its superinductance (the junction array) while maintaining the strong anharmonicity characteristic of flux qubits. This makes it an increasingly attractive option for quantum computing applications, though its more complex structure presents additional engineering challenges.\nTo better understand the fluxonium’s behavior, let’s expand the potential term in the Hamiltonian around \\(\\varphi = 0\\) (with \\(f=1/2\\) for simplicity):\n\\[\n-E_J\\cos(\\hat{\\varphi} + \\pi) = E_J\\cos(\\hat{\\varphi}) = E_J\\left(1 - \\frac{\\hat{\\varphi}^2}{2} + \\frac{\\hat{\\varphi}^4}{24} - ...\\right)\n\\]\nThe total potential energy, including both the inductive and Josephson terms, becomes:\n\\[\nV(\\hat{\\varphi}) = \\frac{1}{2}E_L\\hat{\\varphi}^2 + E_J\\left(1 - \\frac{\\hat{\\varphi}^2}{2} + \\frac{\\hat{\\varphi}^4}{24} - ...\\right)\n\\]\nCollecting terms up to fourth order:\n\\[\nV(\\hat{\\varphi}) \\approx E_J + \\frac{1}{2}(E_L - E_J)\\hat{\\varphi}^2 + \\frac{E_J}{24}\\hat{\\varphi}^4\n\\]\nThis fourth-order expansion reveals the competition between the quadratic term (which determines the well shape) and the quartic term (which introduces anharmonicity). The behavior depends on the relative magnitudes of \\(E_L\\) and \\(E_J\\):\n\nWhen \\(E_L - E_J &gt; 0\\), the quadratic term is positive, resulting in a single-well potential\nWhen \\(E_L - E_J &lt; 0\\), the quadratic term is negative while the quartic term remains positive, creating a double-well potential\n\nThe anharmonicity can be estimated by treating the quartic term as a perturbation. For the single-well case, the unperturbed states are harmonic oscillator states with frequency \\(\\omega_0 = \\sqrt{(E_L - E_J)/E_C}\\). The first-order correction to the energy levels due to the quartic term gives an anharmonicity of approximately:\n\\[\n\\alpha = (E_{12} - E_{01}) \\approx \\frac{E_J}{24}\\left(\\frac{E_C}{E_L - E_J}\\right)^{1/2}\n\\]\nThis shows that the fluxonium can achieve substantial anharmonicity (comparable to or exceeding that of the transmon) while maintaining protection against both charge and flux noise through appropriate choice of \\(E_L\\), \\(E_J\\), and \\(E_C\\).\n\n\n\n\n\n\nSimilar Analysis for Flux Qubits\n\n\n\nA similar potential analysis can be performed for the flux qubit, which has a Hamiltonian of the form:\n\\[\n\\hat{H} = 4E_C\\hat{n}^2 - E_J\\cos(2\\hat{\\varphi} + 2\\pi f) - 2E_J\\alpha\\cos(\\hat{\\varphi})\n\\]\nwhere \\(\\alpha\\) is the ratio of the Josephson energies of the two junctions. Expanding around \\(f=1/2\\) and \\(\\varphi=0\\) yields:\n\\[\nV(\\hat{\\varphi}) \\approx \\text{const} - E_J(2-\\alpha)\\hat{\\varphi}^2 - \\left( \\frac{2}{3} - \\frac{\\alpha}{12}\\right)\\hat{\\varphi}^4\n\\]\nThis reveals how the double-well potential emerges when \\(\\alpha &gt; 2\\), with the barrier height controlled by \\(\\alpha\\). The key difference from the fluxonium is that the flux qubit lacks the inductive energy term, making it more susceptible to flux noise.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Superconducting qubits</span>"
    ]
  },
  {
    "objectID": "superconducting_qubits.html#coupling-qubits",
    "href": "superconducting_qubits.html#coupling-qubits",
    "title": "5  Superconducting qubits",
    "section": "5.4 Coupling Qubits",
    "text": "5.4 Coupling Qubits\nTo perform quantum computations, we need our qubits to interact with each other in controlled ways - this is how we create quantum gates. Let’s explore the two main ways we can manipulate superconducting qubits.\n\n5.4.1 Direct Coupling Between Qubits\nJust like classical circuits can be connected through components, superconducting qubits can be coupled through:\n\nCapacitive Coupling: Connecting qubits through capacitors allows them to interact via electric fields\nInductive Coupling: Using inductors or shared magnetic flux lines creates magnetic coupling\nDirect Junction Coupling: Sharing Josephson junctions between qubits\n\nThe interaction Hamiltonian typically takes the form:\n\\[\nH_{\\text{int}} = g(\\hat{a}_1^\\dagger\\hat{a}_2 + \\hat{a}_1\\hat{a}_2^\\dagger)\n\\]\nwhere \\(g\\) is the coupling strength and \\(\\hat{a}_i\\) are the qubit operators.\n\n\n5.4.2 Microwave Control: “Driving” the Qubits\nWe can also manipulate qubits using carefully designed microwave pulses. This is like playing a very precise musical instrument:\n\\[\nH_{\\text{drive}}(t) = \\Omega(t)\\cos(\\omega t + \\phi)(\\hat{a} + \\hat{a}^\\dagger)\n\\]\nwhere:\n\n\\(\\Omega(t)\\) is the pulse amplitude (how strong)\n\\(\\omega\\) is the frequency (what note)\n\\(\\phi\\) is the phase (timing)\n\n\n\n\n\n\n\nCommon Pulse Sequences\n\n\n\n\nπ-pulse: Flips a qubit from |0⟩ to |1⟩ (or vice versa)\nπ/2-pulse: Creates superposition states\nDRAG pulses: Specially shaped pulses that reduce leakage to unwanted states\n\n\n\n\n\n5.4.3 Creating Gates Through Pulse Engineering\nModern quantum computers use both coupling and pulses to create gates:\n\nSingle-Qubit Gates:\n\nImplemented using microwave pulses\nExample: X gate = single π-pulse\nExample: H gate = π/2-pulse with specific phase\n\nTwo-Qubit Gates:\n\nUse combination of coupling and pulses\nExample: CNOT = coupling + specific pulse sequence\nExample: iSWAP = natural evolution under coupling + control pulses\n\n\nThe Art of Pulse Sequences Think of quantum gates like a choreographed dance:\n\nStart with basic “moves” (primitive gates)\nCombine them in specific sequences\nOptimize timing and shapes\nAccount for real hardware constraints\n\n\n\n\n\n\n\nKey Considerations for Pulse Design\n\n\n\n\nBandwidth: Pulses must fit within system limitations\nCrosstalk: Avoid affecting neighboring qubits\nDecoherence: Complete operations before quantum information is lost\nCalibration: Regular tuning of pulse parameters\n\n\n\n\n\n\n\n\n\nSection Under Construction\n\n\n\nThis section on coupling qubits is currently under development and may be incomplete or subject to revision.\n\n\n\n\n5.4.4 Capacitive Coupling Between Qubits\nAnother fundamental coupling mechanism between superconducting qubits is capacitive coupling, where the interaction arises from the voltage difference between the qubits. The interaction energy for two qubits coupled through a capacitance \\(C_g\\) is:\n\\[\nE_{\\text{int}} = C_gV_1V_2\n\\]\nSince the voltage operators are proportional to the charge operators (\\(\\hat{V} = \\frac{2e}{C}\\hat{n}\\)), this leads to an interaction Hamiltonian of the form:\n\\[\nH_{\\text{int}} = \\frac{4e^2C_g}{C_1C_2}\\hat{n}_1\\hat{n}_2\n\\]\nThe full Hamiltonian for two capacitively coupled qubits becomes:\n\\[\n\\begin{aligned}\nH &= H_1 + H_2 + H_{\\text{int}} \\\\\n&= 4E_{C1}\\hat{n}_1^2 + 4E_{C2}\\hat{n}_2^2 + \\frac{1}{2}E_{L1}\\hat{\\varphi}_1^2 + \\frac{1}{2}E_{L2}\\hat{\\varphi}_2^2 \\\\\n&\\quad - E_{J1}\\cos(\\hat{\\varphi}_1) - E_{J2}\\cos(\\hat{\\varphi}_2) + \\frac{4e^2C_g}{C_1C_2}\\hat{n}_1\\hat{n}_2\n\\end{aligned}\n\\]\nTransformation to Creation/Annihilation Operators We can express the charge and phase operators in terms of creation and annihilation operators:\n\\[\n\\begin{aligned}\n\\hat{n}_j &= in_{\\text{zpf},j}(a_j^\\dagger - a_j) \\\\\n\\hat{\\varphi}_j &= \\varphi_{\\text{zpf},j}(a_j^\\dagger + a_j)\n\\end{aligned}\n\\]\nwhere \\(n_{\\text{zpf},j}\\) and \\(\\varphi_{\\text{zpf},j}\\) are the zero-point fluctuations. Substituting these into the interaction term:\n\\[\nH_{\\text{int}} = \\frac{4e^2C_g}{C_1C_2}n_{\\text{zpf},1}n_{\\text{zpf},2}(a_1^\\dagger - a_1)(a_2^\\dagger - a_2)\n\\]\n\n5.4.4.1 Projection onto the Qubit Subspace\nWhen we project the interaction Hamiltonian onto the computational basis states \\(|0\\rangle\\) and \\(|1\\rangle\\) of each qubit, we can express it in terms of Pauli operators. Let’s work through this projection:\nFor a single qubit, the creation and annihilation operators have the following matrix elements in the {\\(|0\\rangle\\), \\(|1\\rangle\\)} basis:\n\\[\na = \\begin{pmatrix}\n0 & 1 \\\\\n0 & 0\n\\end{pmatrix}, \\quad\na^\\dagger = \\begin{pmatrix}\n0 & 0 \\\\\n1 & 0\n\\end{pmatrix}\n\\]\nTherefore, the combination \\((a^\\dagger - a)\\) gives:\n\\[\n(a^\\dagger - a) = \\begin{pmatrix}\n0 & -1 \\\\\n1 & 0\n\\end{pmatrix} = iY\n\\]\nThe interaction term \\((a_1^\\dagger - a_1)(a_2^\\dagger - a_2)\\) thus becomes:\n\\[\nH_{\\text{int}} = g(iY^{(1)})(iY^{(2)}) = -gY^{(1)}Y^{(2)}\n\\]\nwhere \\(g = \\frac{4e^2C_g}{C_1C_2}n_{\\text{zpf},1}n_{\\text{zpf},2}\\) is the coupling strength.\nUsing the relation \\(Y = \\frac{1}{i}(\\sigma_+ - \\sigma_-)\\), we can rewrite this as:\n\\[\nH_{\\text{int}} = g(\\sigma_1^+\\sigma_2^- + \\sigma_1^-\\sigma_2^+)\n\\]\nThis is the familiar “flip-flop” interaction that conserves the total excitation number, allowing excitations to be exchanged between the qubits.\n\n\n\n\n\n\nInductive Coupling and XX Interactions\n\n\n\nWhile capacitive coupling gives rise to YY interactions between qubits, inductive coupling naturally produces XX interactions. This is because the current operator is proportional to X rather than Y. The interaction Hamiltonian takes the form:\n\\[\nH_{\\text{int}} = gX^{(1)}X^{(2)}\n\\]\nwhere \\(g\\) is proportional to the mutual inductance. Having access to both XX and YY interactions through different coupling mechanisms provides greater flexibility in quantum gate implementation and allows for the engineering of various types of qubit-qubit interactions.\n\n\n\n\n5.4.4.2 Coupling Through a Resonator\nRather than directly coupling qubits, we can engineer interactions by coupling qubits to a common resonator. The Jaynes-Cummings Hamiltonian for each qubit-resonator system is:\n\\[\nH = \\omega_r a^\\dagger a + \\frac{\\omega_q}{2}\\sigma^z + g(a^\\dagger\\sigma^- + a\\sigma^+)\n\\]\nIn the dispersive limit where \\(|\\Delta| = |\\omega_q - \\omega_r| \\gg g\\), we can eliminate the direct qubit-resonator coupling through a unitary transformation, yielding an effective qubit-qubit interaction:\n\\[\nH_{\\text{eff}} \\approx \\frac{g_1g_2}{\\Delta}(\\sigma_1^+\\sigma_2^- + \\sigma_1^-\\sigma_2^+)\n\\]\nThis cavity-mediated coupling allows us to couple qubits separated by macroscopic distances (~1 cm) while maintaining strong interaction strengths, a significant advantage over direct coupling methods that require physical proximity (~1 mm).\n\n\n\n5.4.5 Inductive Coupling Between Qubits\nThe coupling between superconducting qubits can be achieved through various mechanisms, with inductive coupling being one of the most fundamental and versatile approaches. This coupling mechanism relies on the interaction between currents flowing through the qubits and their mutual inductance.\n\n5.4.5.1 Mutual Inductance and Kinetic Inductance\nWhen two circuits are placed in proximity, a current flowing in one circuit induces a magnetic flux in the other through mutual inductance \\(M\\). The interaction energy is given by:\n\\[\nE_{\\text{int}} = MI_{\\text{i}}I_{\\text{ii}}\n\\]\nIn superconducting circuits, we benefit from an additional contribution to inductance known as kinetic inductance. Unlike geometric inductance, which arises from magnetic field energy storage, kinetic inductance stems from the kinetic energy of Cooper pairs. The total inductance is:\n\\[\nL_{\\text{total}} = L_{\\text{geometric}} + L_{\\text{kinetic}}\n\\]\nThis kinetic inductance can be significantly larger than geometric inductance in thin superconducting films, providing stronger coupling strengths than would be possible with purely electromagnetic interactions. The kinetic inductance contribution scales as:\n\\[\nL_{\\text{kinetic}} \\propto \\frac{m}{n_{\\text{s}}e^2}\n\\]\nwhere \\(n_s\\) is the Cooper pair density.\n\n\n5.4.5.2 Coupled Fluxonium Hamiltonian\nFor two inductively coupled fluxonium qubits, the interaction Hamiltonian arises from the mutual inductance between the currents:\n\\[\nH_{int} = MI_1I_2 = M\\left(\\frac{\\Phi_0}{2\\pi}\\right)^2\\sin(\\hat{\\varphi}_1)\\sin(\\hat{\\varphi}_2)\n\\]\nThe full Hamiltonian for the coupled system is:\n\\[\n\\begin{aligned}\nH &= H_1 + H_2 + H_{int} \\\\\n&= 4E_{C1}\\hat{n}_1^2 + 4E_{C2}\\hat{n}_2^2 + \\frac{1}{2}E_{L1}\\hat{\\varphi}_1^2 + \\frac{1}{2}E_{L2}\\hat{\\varphi}_2^2 \\\\\n&\\quad - E_{J1}\\cos(\\hat{\\varphi}_1) - E_{J2}\\cos(\\hat{\\varphi}_2) + M\\left(\\frac{\\Phi_0}{2\\pi}\\right)^2\\sin(\\hat{\\varphi}_1)\\sin(\\hat{\\varphi}_2)\n\\end{aligned}\n\\]\n\n\n5.4.5.3 Energy Level Structure and Coupling\nIn the fluxonium regime where \\(E_L \\ll E_J\\), the potential forms a deep well around \\(\\varphi = 0\\). For small oscillations, we can expand the sine terms:\n\\[\n\\sin(\\hat{\\varphi}) \\approx \\hat{\\varphi} - \\frac{\\hat{\\varphi}^3}{6}\n\\]\nThe interaction term becomes:\n\\[\nH_{int} \\approx M\\left(\\frac{\\Phi_0}{2\\pi}\\right)^2(\\hat{\\varphi}_1 - \\frac{\\hat{\\varphi}_1^3}{6})(\\hat{\\varphi}_2 - \\frac{\\hat{\\varphi}_2^3}{6})\n\\]\nWhen projected onto the two lowest energy states of each fluxonium, the phase operator \\(\\hat{\\varphi}\\) has diagonal matrix elements due to the asymmetry of the wavefunctions in the anharmonic potential:\n\\[\n\\langle g|\\hat{\\varphi}|g\\rangle = -\\langle e|\\hat{\\varphi}|e\\rangle\n\\]\nThis leads naturally to the longitudinal coupling:\n\\[\nH_{int} \\approx \\hbar g_{12}\\sigma_z^{(1)}\\sigma_z^{(2)}\n\\]\nwhere \\(g_{12}\\) is proportional to the mutual inductance \\(M\\) and the matrix elements of \\(\\hat{\\varphi}\\) in the qubit basis.\n\n\n\n\n\n\nOperating Point for Longitudinal Coupling\n\n\n\nWhile the fluxonium operates in a regime with deep wells (\\(E_L \\ll E_J\\)), it’s crucial to note that pure longitudinal coupling requires a small but non-zero flux bias away from \\(\\varphi = 0\\). This is because:\n\nAt exactly \\(\\varphi = 0\\), the ground and excited states have symmetric wavefunctions, making \\(\\langle g|\\hat{\\varphi}|g\\rangle = \\langle e|\\hat{\\varphi}|e\\rangle = 0\\)\nA small flux bias breaks this symmetry, creating distinct average flux states\nDue to the deep well regime, even a small bias (\\(\\varphi \\sim 0.1\\)) is sufficient to achieve significant coupling\nThe states remain well-localized due to the large \\(E_J\\), maintaining coherence\n\nThis subtle but essential tuning enables the desired \\(\\sigma_z^{(1)}\\sigma_z^{(2)}\\) coupling while preserving the qubit’s favorable noise properties.\n\n\n\n\n5.4.5.4 Advantages and Applications\nThis coupling mechanism offers several benefits:\n\nPure Phase Coupling: Enables entanglement without energy exchange\nQuantum Annealing: Natural implementation of Ising-type interactions \\[H_{Ising} = \\sum_{i,j} J_{ij}\\sigma_z^{(i)}\\sigma_z^{(j)}\\]\nDecoherence Resistance: Less susceptible to charge noise\nScalability: Compatible with circuit QED architectures\n\n\n\n5.4.5.5 Tunable Coupling via Mediator Qubit\nThe coupling strength can be made tunable by introducing an intermediate rf-SQUID between the qubits. The effective coupling becomes:\n\\[\ng_{eff} = g_{12}(\\Phi_x) = g_0\\cos(\\pi\\Phi_x/\\Phi_0)\n\\]\nwhere \\(\\Phi_x\\) is the external flux through the mediator SQUID.\nTrade-offs of this approach include:\n\nEnhanced coupling control\nAdditional control line complexity\nPotential decoherence through the mediator\nIncreased circuit footprint\n\n\n\n\n\n\n\nUnder Construction\n\n\n\nThis section is currently under construction. More content will be added in future updates.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Superconducting qubits</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "[1] F.\nArute et al., Quantum supremacy using\na programmable superconducting processor, Nature\n574, 505 (2019).\n\n\n[2] Google Quantum AI and Collaborators et al., Quantum error\ncorrection below the surface code threshold, Nature (2024).\n\n\n[3] E.\nPednault, J. A. Gunnels, G. Nannicini, L. Horesh, and R. Wisnieff, Leveraging\nSecondary Storage to Simulate Deep 54-qubit\nSycamore Circuits, arXiv:1910.09534 (2019).\n\n\n[4] F.\nPan, K. Chen, and P. Zhang, Solving the\nSampling Problem of the Sycamore Quantum\nCircuits, Physical Review Letters 129,\n090502 (2022).\n\n\n[5] M.\nA. Nielsen and I. L. Chuang, Quantum Computation and\nQuantum Information: 10th Anniversary\nEdition, Anniversary edition (Cambridge University Press,\nCambridge ; New York, 2011).\n\n\n[6] A.\nM. Turing, On\nComputable Numbers, with an Application to the\nEntscheidungsproblem, Proceedings of the London\nMathematical Society s2-42, 230 (1937).\n\n\n[7] L.\nHoddeson, The\nDiscovery of the Point-Contact Transistor,\nHistorical Studies in the Physical Sciences 12, 41\n(1981).\n\n\n[8] S.\nBravyi and A. Kitaev, Universal quantum\ncomputation with ideal Clifford gates and noisy\nancillas, Physical Review A 71, 022316\n(2005).\n\n\n[9] R.\nP. Feynman, Simulating\nphysics with computers, International Journal of Theoretical Physics\n21, 467 (1982).\n\n\n[10] D.\nDeutsch, Quantum\ntheory, the Church–Turing principle and the\nuniversal quantum computer, Proceedings of the Royal Society of\nLondon. A. Mathematical and Physical Sciences 400, 97\n(1985).\n\n\n[11] D.\nDeutsch and R. Jozsa, Rapid solution of problems\nby quantum computation, Proceedings of the Royal Society of London.\nSeries A: Mathematical and Physical Sciences 439, 553\n(1992).\n\n\n[12] E.\nBernstein and U. Vazirani, Quantum\nComplexity Theory, SIAM Journal on Computing\n26, 1411 (1997).\n\n\n[13] D.\nR. Simon, On the\nPower of Quantum Computation, SIAM Journal\non Computing 26, 1474 (1997).\n\n\n[14] P.\nW. Shor, Algorithms for Quantum\nComputation: Discrete Logarithms and Factoring, in\nProceedings 35th Annual Symposium on\nFoundations of Computer Science (IEEE\nComput. Soc. Press, Santa Fe, NM, USA, 1994), pp. 124–134.\n\n\n[15] L.\nK. Grover, A Fast\nQuantum Mechanical Algorithm for Database Search, in\nProceedings of the Twenty-Eighth Annual ACM Symposium\non Theory of Computing - STOC ’96 (ACM\nPress, Philadelphia, Pennsylvania, United States, 1996), pp.\n212–219.\n\n\n[16] W.\nK. Wootters and W. H. Zurek, A single quantum cannot be\ncloned, Nature 299, 802 (1982).\n\n\n[17] M.\nM. Wilde, Quantum Information Theory, 2nd ed (Cambridge\nuniversity press, Cambridge, 2017).\n\n\n[18] A.\nEinstein, B. Podolsky, and N. Rosen, Can\nQuantum-Mechanical Description of Physical Reality Be\nConsidered Complete?, Physical Review 47,\n777 (1935).\n\n\n[19] E.\nSchrödinger, Discussion of\nProbability Relations between Separated\nSystems, Mathematical Proceedings of the Cambridge\nPhilosophical Society 31, 555 (1935).\n\n\n[20] J.\nS. Bell, On the\nEinstein Podolsky Rosen paradox, Physics Physique\nFizika 1, 195 (1964).\n\n\n[21] S.\nJ. Freedman and J. F. Clauser, Experimental\nTest of Local Hidden-Variable Theories,\nPhysical Review Letters 28, 938 (1972).\n\n\n[22] A.\nAspect, J. Dalibard, and G. Roger, Experimental\nTest of Bell’s Inequalities Using Time-\nVarying Analyzers, Physical Review Letters\n49, 1804 (1982).\n\n\n[23] M.\nF. Pusey, J. Barrett, and T. Rudolph, On the reality of the quantum\nstate, Nature Physics 8, 475 (2012).\n\n\n[24] N.\nD. Mermin, Bringing home the\natomic world: Quantum mysteries for anybody, American\nJournal of Physics 49, 940 (1981).\n\n\n[25] R.\nHorodecki, M. Horodecki, and K. Horodecki, Quantum\nentanglement, Reviews of Modern Physics 81, 865\n(2009).\n\n\n[26] W.\nWootters, Entanglement of formation and concurrence, Quantum Information\nand Computation 1, 27 (2001).\n\n\n[27] D.\nM. Greenberger, M. A. Horne, A. Shimony, and A. Zeilinger, Bell’s theorem without\ninequalities, American Journal of Physics 58, 1131\n(1990).\n\n\n[28] W.\nDür, G. Vidal, and J. I. Cirac, Three qubits can be\nentangled in two inequivalent ways, Physical Review A\n62, 62314 (2000).\n\n\n[29] N.\nP. De Leon, K. M. Itoh, D. Kim, K. K. Mehta, T. E. Northup, H. Paik, B.\nS. Palmer, N. Samarth, S. Sangtawesin, and D. W. Steuerman, Materials challenges and\nopportunities for quantum computing hardware, Science\n372, eabb2823 (2021).\n\n\n[30] A.\nW. Harrow, A. Hassidim, and S. Lloyd, Quantum\nAlgorithm for Linear Systems of\nEquations, Physical Review Letters\n103, 150502 (2009).\n\n\n[31] D.\nP. DiVincenzo, Topics in\nQuantum Computers, in Mesoscopic\nElectron Transport, edited by L. L. Sohn, L. P.\nKouwenhoven, and G. Schön (Springer Netherlands, Dordrecht, 1997), pp.\n657–677.",
    "crumbs": [
      "References"
    ]
  }
]